.SH rclone serve ftp
Serve remote:path over FTP.
Run a basic FTP server to serve a remote over FTP protocol.
This can be viewed with a FTP client or you can make a remote of type
FTP to read and write it.
.SS Server options
Use --addr to specify which IP address and port the server should listen
on, e.g.
--addr 1.2.3.4:8000 or --addr :8080 to listen to all IPs.
By default it only listens on localhost.
You can use port :0 to let the OS choose an available port.
.PP
If you set --addr to listen on a public or LAN accessible IP address
then using Authentication is advised - see the next section for info.
.SS Authentication
.PP
By default this will serve files without needing a login.
.PP
You can set a single username and password with the --user and --pass
flags.
.SS Auth Proxy
.PP
If you supply the parameter \f[V]--auth-proxy /path/to/program\f[R] then
rclone will use that program to generate backends on the fly which then
are used to authenticate incoming requests.
This uses a simple JSON based protocol with input on STDIN and output on
STDOUT.
.PP
\f[B]PLEASE NOTE:\f[R] \f[V]--auth-proxy\f[R] and
\f[V]--authorized-keys\f[R] cannot be used together, if
\f[V]--auth-proxy\f[R] is set the authorized keys option will be
ignored.
.PP
There is an example program
bin/test_proxy.py (https://github.com/rclone/rclone/blob/master/bin/test_proxy.py)
in the rclone source code.
.PP
The program\[aq]s job is to take a \f[V]user\f[R] and \f[V]pass\f[R] on
the input and turn those into the config for a backend on STDOUT in JSON
format.
This config will have any default parameters for the backend added, but
it won\[aq]t use configuration from environment variables or command
line options - it is the job of the proxy program to make a complete
config.
.PP
This config generated must have this extra parameter
.IP \[bu] 2
\f[V]_root\f[R] - root to use for the backend
.PP
And it may have this parameter
.IP \[bu] 2
\f[V]_obscure\f[R] - comma separated strings for parameters to obscure
.PP
If password authentication was used by the client, input to the proxy
process (on STDIN) would look similar to this:
{
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]pass\[dq]: \[dq]mypassword\[dq]
}
\f[R]
.fi
.PP
If public-key authentication was used by the client, input to the proxy
process (on STDIN) would look similar to this:
.IP
.nf
\f[C]
{
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]public_key\[dq]: \[dq]AAAAB3NzaC1yc2EAAAADAQABAAABAQDuwESFdAe14hVS6omeyX7edc...JQdf\[dq]
}
\f[R]
.fi
.PP
And as an example return this on STDOUT
.IP
.nf
\f[C]
{
  \[dq]type\[dq]: \[dq]sftp\[dq],
  \[dq]_root\[dq]: \[dq]\[dq],
  \[dq]_obscure\[dq]: \[dq]pass\[dq],
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]pass\[dq]: \[dq]mypassword\[dq],
  \[dq]host\[dq]: \[dq]sftp.example.com\[dq]
}
\f[R]
.fi
.PP
This would mean that an SFTP backend would be created on the fly for the
\f[V]user\f[R] and \f[V]pass\f[R]/\f[V]public_key\f[R] returned in the
output to the host given.
Note that since \f[V]_obscure\f[R] is set to \f[V]pass\f[R], rclone will
obscure the \f[V]pass\f[R] parameter before creating the backend (which
is required for sftp backends).
.PP
The program can manipulate the supplied \f[V]user\f[R] in any way, for
example to make proxy to many different sftp backends, you could make
the \f[V]user\f[R] be \f[V]user\[at]example.com\f[R] and then set the
\f[V]host\f[R] to \f[V]example.com\f[R] in the output and the user to
\f[V]user\f[R].
For security you\[aq]d probably want to restrict the \f[V]host\f[R] to a
limited list.
.PP
Note that an internal cache is keyed on \f[V]user\f[R] so only use that
for configuration, don\[aq]t use \f[V]pass\f[R] or \f[V]public_key\f[R].
This also means that if a user\[aq]s password or public-key is changed
the cache will need to expire (which takes 5 mins) before it takes
effect.
.PP
This can be used to build general purpose proxies to any kind of backend
that rclone supports.
.IP
.nf
\f[C]
rclone serve ftp remote:path [flags]
      --addr string                            IPaddress:Port or :Port to bind server to (default \[dq]localhost:2121\[dq])
      --auth-proxy string                      A program to use to create the backend from the auth
      --cert string                            TLS PEM key (concatenation of certificate and CA certificate)
  -h, --help                                   help for ftp
      --key string                             TLS PEM Private key
      --pass string                            Password for authentication (empty value allow every password)
      --passive-port string                    Passive port range to use (default \[dq]30000-32000\[dq])
      --public-ip string                       Public IP address to advertise for passive connections
      --user string                            User name for authentication (default \[dq]anonymous\[dq])
.SH rclone serve http
Serve the remote over HTTP.
Run a basic web server to serve a remote over HTTP.
This can be viewed in a web browser or you can make a remote of type
http read from it.
.PP
You can use the filter flags (e.g.
\f[V]--include\f[R], \f[V]--exclude\f[R]) to control what is served.
.PP
The server will log errors.
Use \f[V]-v\f[R] to see access logs.
.PP
\f[V]--bwlimit\f[R] will be respected for file transfers.
Use \f[V]--stats\f[R] to control the stats printing.
Use \f[V]--addr\f[R] to specify which IP address and port the server
should listen on, eg \f[V]--addr 1.2.3.4:8000\f[R] or
\f[V]--addr :8080\f[R] to listen to all IPs.
If you set \f[V]--addr\f[R] to listen on a public or LAN accessible IP
address then using Authentication is advised - see the next section for
info.
.PP
You can use a unix socket by setting the url to
\f[V]unix:///path/to/socket\f[R] or just by using an absolute path name.
.PP
\f[V]--addr\f[R] may be repeated to listen on multiple
IPs/ports/sockets.
Socket activation, described further below, can also be used to
accomplish the same.
.PP
\f[V]--server-read-timeout\f[R] and \f[V]--server-write-timeout\f[R] can
be used to control the timeouts on the server.
Note that this is the total time for a transfer.
.PP
\f[V]--max-header-bytes\f[R] controls the maximum number of bytes the
server will accept in the HTTP header.
.PP
\f[V]--baseurl\f[R] controls the URL prefix that rclone serves from.
By default rclone will serve from the root.
If you used \f[V]--baseurl \[dq]/rclone\[dq]\f[R] then rclone would
serve from a URL starting with \[dq]/rclone/\[dq].
This is useful if you wish to proxy rclone serve.
Rclone automatically inserts leading and trailing \[dq]/\[dq] on
\f[V]--baseurl\f[R], so \f[V]--baseurl \[dq]rclone\[dq]\f[R],
\f[V]--baseurl \[dq]/rclone\[dq]\f[R] and
\f[V]--baseurl \[dq]/rclone/\[dq]\f[R] are all treated identically.
.PP
\f[V]--disable-zip\f[R] may be set to disable the zipping download
option.
.SS TLS (SSL)
.PP
By default this will serve over http.
If you want you can serve over https.
You will need to supply the \f[V]--cert\f[R] and \f[V]--key\f[R] flags.
If you wish to do client side certificate validation then you will need
to supply \f[V]--client-ca\f[R] also.
.PP
\f[V]--cert\f[R] must be set to the path of a file containing either a
PEM encoded certificate, or a concatenation of that with the CA
certificate.
\f[V]--key\f[R] must be set to the path of a file with the PEM encoded
private key.
If setting \f[V]--client-ca\f[R], it should be set to the path of a file
with PEM encoded client certificate authority certificates.
.PP
\f[V]--min-tls-version\f[R] is minimum TLS version that is acceptable.
Valid values are \[dq]tls1.0\[dq], \[dq]tls1.1\[dq], \[dq]tls1.2\[dq]
and \[dq]tls1.3\[dq] (default \[dq]tls1.0\[dq]).
.SS Socket activation
.PP
Instead of the listening addresses specified above, rclone will listen
to all FDs passed by the service manager, if any (and ignore any
arguments passed by \f[V]--addr\f[R]).
.PP
This allows rclone to be a socket-activated service.
It can be configured with .socket and .service unit files as described
in
<https://www.freedesktop.org/software/systemd/man/latest/systemd.socket.html>.
.PP
Socket activation can be tested ad-hoc with the
\f[V]systemd-socket-activate\f[R]command
.IP
.nf
\f[C]
systemd-socket-activate -l 8000 -- rclone serve
\f[R]
.fi
.PP
This will socket-activate rclone on the first connection to port 8000
over TCP.
.SS Template
.PP
\f[V]--template\f[R] allows a user to specify a custom markup template
for HTTP and WebDAV serve functions.
The server exports the following markup to be used within the template
to server pages:
.PP
.TS
tab(@);
lw(22.6n) lw(24.7n) lw(22.6n).
T{
Parameter
T}@T{
Subparameter
T}@T{
Description
T}
_
T{
\&.Name
T}@T{
T}@T{
The full path of a file/directory.
T}
T{
\&.Title
T}@T{
T}@T{
Directory listing of \[aq].Name\[aq].
T}
T{
\&.Sort
T}@T{
T}@T{
The current sort used.
This is changeable via \[aq]?sort=\[aq] parameter.
Possible values: namedirfirst, name, size, time (default namedirfirst).
T}
T{
\&.Order
T}@T{
T}@T{
The current ordering used.
This is changeable via \[aq]?order=\[aq] parameter.
Possible values: asc, desc (default asc).
T}
T{
\&.Query
T}@T{
T}@T{
Currently unused.
T}
T{
\&.Breadcrumb
T}@T{
T}@T{
Allows for creating a relative navigation.
T}
T{
T}@T{
\&.Link
T}@T{
The link of the Text relative to the root.
T}
T{
T}@T{
\&.Text
T}@T{
The Name of the directory.
T}
T{
\&.Entries
T}@T{
T}@T{
Information about a specific file/directory.
T}
T{
T}@T{
\&.URL
T}@T{
The url of an entry.
T}
T{
T}@T{
\&.Leaf
T}@T{
Currently same as \[aq].URL\[aq] but intended to be just the name.
T}
T{
T}@T{
\&.IsDir
T}@T{
Boolean for if an entry is a directory or not.
T}
T{
T}@T{
\&.Size
T}@T{
Size in bytes of the entry.
T}
T{
T}@T{
\&.ModTime
T}@T{
The UTC timestamp of an entry.
T}
.TE
.PP
The server also makes the following functions available so that they can
be used within the template.
These functions help extend the options for dynamic rendering of HTML.
They can be used to render HTML based on specific conditions.
.PP
.TS
tab(@);
lw(35.0n) lw(35.0n).
T{
Function
T}@T{
Description
T}
_
T{
afterEpoch
T}@T{
Returns the time since the epoch for the given time.
T}
T{
contains
T}@T{
Checks whether a given substring is present or not in a given string.
T}
T{
hasPrefix
T}@T{
Checks whether the given string begins with the specified prefix.
T}
T{
hasSuffix
T}@T{
Checks whether the given string end with the specified suffix.
T}
.TE
You can either use an htpasswd file which can take lots of users, or set
a single username and password with the \f[V]--user\f[R] and
\f[V]--pass\f[R] flags.
.PP
Alternatively, you can have the reverse proxy manage authentication and
use the username provided in the configured header with
\f[V]--user-from-header\f[R] (e.g.,
\f[V]--user-from-header=x-remote-user\f[R]).
Ensure the proxy is trusted and headers cannot be spoofed, as
misconfiguration may lead to unauthorized access.
.PP
If either of the above authentication methods is not configured and
client certificates are required by the \f[V]--client-ca\f[R] flag
passed to the server, the client certificate common name will be
considered as the username.
.PP
Use \f[V]--htpasswd /path/to/htpasswd\f[R] to provide an htpasswd file.
This is in standard apache format and supports MD5, SHA1 and BCrypt for
basic authentication.
Bcrypt is recommended.
.PP
To create an htpasswd file:
.IP
.nf
\f[C]
touch htpasswd
htpasswd -B htpasswd user
htpasswd -B htpasswd anotherUser
\f[R]
.fi
.PP
The password file can be updated while rclone is running.
.PP
Use \f[V]--realm\f[R] to set the authentication realm.
.PP
Use \f[V]--salt\f[R] to change the password hashing salt from the
default.
rclone serve http remote:path [flags]
      --addr stringArray                       IPaddress:Port or :Port to bind server to (default 127.0.0.1:8080)
      --allow-origin string                    Origin which cross-domain request (CORS) can be executed from
      --baseurl string                         Prefix for URLs - leave blank for root
      --client-ca string                       Client certificate authority to verify clients with
      --disable-zip                            Disable zip download of directories
  -h, --help                                   help for http
      --htpasswd string                        A htpasswd file - if not provided no authentication is done
      --max-header-bytes int                   Maximum size of request header (default 4096)
      --min-tls-version string                 Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --pass string                            Password for authentication
      --realm string                           Realm for authentication
      --salt string                            Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --server-read-timeout Duration           Timeout for server reading data (default 1h0m0s)
      --server-write-timeout Duration          Timeout for server writing data (default 1h0m0s)
      --template string                        User-specified template
      --user string                            User name for authentication
      --user-from-header string                User name from a defined HTTP header
.SH rclone serve nfs
Serve the remote as an NFS mount
Create an NFS server that serves the given remote over the network.
This implements an NFSv3 server to serve any rclone remote via NFS.
The primary purpose for this command is to enable the mount
command (https://rclone.org/commands/rclone_mount/) on recent macOS
versions where installing FUSE is very cumbersome.
This server does not implement any authentication so any client will be
able to access the data.
To limit access, you can use \f[V]serve nfs\f[R] on the loopback address
or rely on secure tunnels (such as SSH) or use firewalling.
For this reason, by default, a random TCP port is chosen and the
loopback interface is used for the listening address by default; meaning
that it is only available to the local machine.
If you want other machines to access the NFS mount over local network,
you need to specify the listening address and port using the
\f[V]--addr\f[R] flag.
Modifying files through the NFS protocol requires VFS caching.
Usually you will need to specify \f[V]--vfs-cache-mode\f[R] in order to
be able to write to the mountpoint (\f[V]full\f[R] is recommended).
If you don\[aq]t specify VFS cache mode, the mount will be read-only.
\f[V]--nfs-cache-type\f[R] controls the type of the NFS handle cache.
By default this is \f[V]memory\f[R] where new handles will be randomly
allocated when needed.
These are stored in memory.
If the server is restarted the handle cache will be lost and connected
NFS clients will get stale handle errors.
\f[V]--nfs-cache-type disk\f[R] uses an on disk NFS handle cache.
Rclone hashes the path of the object and stores it in a file named after
the hash.
These hashes are stored on disk the directory controlled by
\f[V]--cache-dir\f[R] or the exact directory may be specified with
\f[V]--nfs-cache-dir\f[R].
Using this means that the NFS server can be restarted at will without
affecting the connected clients.
\f[V]--nfs-cache-type symlink\f[R] is similar to
\f[V]--nfs-cache-type disk\f[R] in that it uses an on disk cache, but
the cache entries are held as symlinks.
Rclone will use the handle of the underlying file as the NFS handle
which improves performance.
This sort of cache can\[aq]t be backed up and restored as the underlying
handles will change.
This is Linux only.
It requires running rclone as root or with
\f[V]CAP_DAC_READ_SEARCH\f[R].
You can run rclone with this extra permission by doing this to the
rclone binary
\f[V]sudo setcap cap_dac_read_search+ep /path/to/rclone\f[R].
\f[V]--nfs-cache-handle-limit\f[R] controls the maximum number of cached
NFS handles stored by the caching handler.
This should not be set too low or you may experience errors when trying
to access files.
The default is \f[V]1000000\f[R], but consider lowering this limit if
the server\[aq]s system resource usage causes problems.
This is only used by the \f[V]memory\f[R] type cache.
To serve NFS over the network use following command:
rclone serve nfs remote: --addr 0.0.0.0:$PORT --vfs-cache-mode=full
This specifies a port that can be used in the mount command.
To mount the server under Linux/macOS, use the following command:
mount -t nfs -o port=$PORT,mountport=$PORT,tcp $HOSTNAME:/ path/to/mountpoint
Where \f[V]$PORT\f[R] is the same port number used in the
\f[V]serve nfs\f[R] command and \f[V]$HOSTNAME\f[R] is the network
address of the machine that \f[V]serve nfs\f[R] was run on.
If \f[V]--vfs-metadata-extension\f[R] is in use then for the
\f[V]--nfs-cache-type disk\f[R] and \f[V]--nfs-cache-type cache\f[R] the
metadata files will have the file handle of their parent file suffixed
with \f[V]0x00, 0x00, 0x00, 0x01\f[R].
This means they can be looked up directly from the parent file handle is
desired.
This command is only available on Unix platforms.
rclone serve nfs remote:path [flags]
      --addr string                            IPaddress:Port or :Port to bind server to
  -h, --help                                   help for nfs
      --nfs-cache-dir string                   The directory the NFS handle cache will use if set
      --nfs-cache-handle-limit int             max file handles cached simultaneously (min 5) (default 1000000)
      --nfs-cache-type memory|disk|symlink     Type of NFS handle cache to use (default memory)
.SH rclone serve restic
Serve the remote for restic\[aq]s REST API.
Run a basic web server to serve a remote over restic\[aq]s REST backend
API over HTTP.
This allows restic to use rclone as a data storage mechanism for cloud
providers that restic does not support directly.
Restic (https://restic.net/) is a command-line program for doing
backups.
The server will log errors.
Use -v to see access logs.
\f[V]--bwlimit\f[R] will be respected for file transfers.
Use \f[V]--stats\f[R] to control the stats printing.
.SS Setting up rclone for use by restic
First set up a remote for your chosen cloud
provider (https://rclone.org/docs/#configure).
Once you have set up the remote, check it is working with, for example
\[dq]rclone lsd remote:\[dq].
You may have called the remote something other than \[dq]remote:\[dq] -
just substitute whatever you called it in the following instructions.
Now start the rclone restic server
.IP
.nf
\f[C]
rclone serve restic -v remote:backup
\f[R]
.fi
Where you can replace \[dq]backup\[dq] in the above by whatever path in
the remote you wish to use.
By default this will serve on \[dq]localhost:8080\[dq] you can change
this with use of the \f[V]--addr\f[R] flag.
You might wish to start this server on boot.
Adding \f[V]--cache-objects=false\f[R] will cause rclone to stop caching
objects returned from the List call.
Caching is normally desirable as it speeds up downloading objects, saves
transactions and uses very little memory.
.SS Setting up restic to use rclone
.PP
Now you can follow the restic
instructions (http://restic.readthedocs.io/en/latest/030_preparing_a_new_repo.html#rest-server)
on setting up restic.
.PP
Note that you will need restic 0.8.2 or later to interoperate with
rclone.
.PP
For the example above you will want to use
\[dq]http://localhost:8080/\[dq] as the URL for the REST server.
.PP
For example:
$ export RESTIC_REPOSITORY=rest:http://localhost:8080/
$ export RESTIC_PASSWORD=yourpassword
$ restic init
created restic backend 8b1a4b56ae at rest:http://localhost:8080/

Please note that knowledge of your password is required to access
the repository. Losing your password means that your data is
irrecoverably lost.
$ restic backup /path/to/files/to/backup
scan [/path/to/files/to/backup]
scanned 189 directories, 312 files in 0:00
[0:00] 100.00%  38.128 MiB / 38.128 MiB  501 / 501 items  0 errors  ETA 0:00
duration: 0:00
snapshot 45c8fdd8 saved
.SS Multiple repositories
Note that you can use the endpoint to host multiple repositories.
Do this by adding a directory name or path after the URL.
Note that these \f[B]must\f[R] end with /.
Eg
$ export RESTIC_REPOSITORY=rest:http://localhost:8080/user1repo/
# backup user1 stuff
$ export RESTIC_REPOSITORY=rest:http://localhost:8080/user2repo/
# backup user2 stuff
.SS Private repositories
The\f[V]--private-repos\f[R] flag can be used to limit users to
repositories starting with a path of \f[V]/<username>/\f[R].
.SS Server options
Use \f[V]--addr\f[R] to specify which IP address and port the server
should listen on, eg \f[V]--addr 1.2.3.4:8000\f[R] or
\f[V]--addr :8080\f[R] to listen to all IPs.
By default it only listens on localhost.
You can use port :0 to let the OS choose an available port.
If you set \f[V]--addr\f[R] to listen on a public or LAN accessible IP
address then using Authentication is advised - see the next section for
info.
You can use a unix socket by setting the url to
\f[V]unix:///path/to/socket\f[R] or just by using an absolute path name.
\f[V]--addr\f[R] may be repeated to listen on multiple
IPs/ports/sockets.
Socket activation, described further below, can also be used to
accomplish the same.
\f[V]--server-read-timeout\f[R] and \f[V]--server-write-timeout\f[R] can
be used to control the timeouts on the server.
Note that this is the total time for a transfer.
\f[V]--max-header-bytes\f[R] controls the maximum number of bytes the
server will accept in the HTTP header.
.PP
\f[V]--baseurl\f[R] controls the URL prefix that rclone serves from.
By default rclone will serve from the root.
If you used \f[V]--baseurl \[dq]/rclone\[dq]\f[R] then rclone would
serve from a URL starting with \[dq]/rclone/\[dq].
This is useful if you wish to proxy rclone serve.
Rclone automatically inserts leading and trailing \[dq]/\[dq] on
\f[V]--baseurl\f[R], so \f[V]--baseurl \[dq]rclone\[dq]\f[R],
\f[V]--baseurl \[dq]/rclone\[dq]\f[R] and
\f[V]--baseurl \[dq]/rclone/\[dq]\f[R] are all treated identically.
.PP
\f[V]--disable-zip\f[R] may be set to disable the zipping download
option.
.SS TLS (SSL)
.PP
By default this will serve over http.
If you want you can serve over https.
You will need to supply the \f[V]--cert\f[R] and \f[V]--key\f[R] flags.
If you wish to do client side certificate validation then you will need
to supply \f[V]--client-ca\f[R] also.
.PP
\f[V]--cert\f[R] must be set to the path of a file containing either a
PEM encoded certificate, or a concatenation of that with the CA
certificate.
\f[V]--key\f[R] must be set to the path of a file with the PEM encoded
private key.
If setting \f[V]--client-ca\f[R], it should be set to the path of a file
with PEM encoded client certificate authority certificates.
.PP
\f[V]--min-tls-version\f[R] is minimum TLS version that is acceptable.
Valid values are \[dq]tls1.0\[dq], \[dq]tls1.1\[dq], \[dq]tls1.2\[dq]
and \[dq]tls1.3\[dq] (default \[dq]tls1.0\[dq]).
.SS Socket activation
.PP
Instead of the listening addresses specified above, rclone will listen
to all FDs passed by the service manager, if any (and ignore any
arguments passed by \f[V]--addr\f[R]).
.PP
This allows rclone to be a socket-activated service.
It can be configured with .socket and .service unit files as described
in
<https://www.freedesktop.org/software/systemd/man/latest/systemd.socket.html>.
.PP
Socket activation can be tested ad-hoc with the
\f[V]systemd-socket-activate\f[R]command
systemd-socket-activate -l 8000 -- rclone serve
This will socket-activate rclone on the first connection to port 8000
over TCP.
.SS Authentication
By default this will serve files without needing a login.
.PP
You can either use an htpasswd file which can take lots of users, or set
a single username and password with the \f[V]--user\f[R] and
\f[V]--pass\f[R] flags.
.PP
Alternatively, you can have the reverse proxy manage authentication and
use the username provided in the configured header with
\f[V]--user-from-header\f[R] (e.g.,
\f[V]--user-from-header=x-remote-user\f[R]).
Ensure the proxy is trusted and headers cannot be spoofed, as
misconfiguration may lead to unauthorized access.
.PP
If either of the above authentication methods is not configured and
client certificates are required by the \f[V]--client-ca\f[R] flag
passed to the server, the client certificate common name will be
considered as the username.
.PP
Use \f[V]--htpasswd /path/to/htpasswd\f[R] to provide an htpasswd file.
This is in standard apache format and supports MD5, SHA1 and BCrypt for
basic authentication.
Bcrypt is recommended.
.PP
To create an htpasswd file:
touch htpasswd
htpasswd -B htpasswd user
htpasswd -B htpasswd anotherUser
The password file can be updated while rclone is running.
.PP
Use \f[V]--realm\f[R] to set the authentication realm.
.PP
Use \f[V]--salt\f[R] to change the password hashing salt from the
default.
rclone serve restic remote:path [flags]
.SS Options
      --addr stringArray                IPaddress:Port or :Port to bind server to (default 127.0.0.1:8080)
      --allow-origin string             Origin which cross-domain request (CORS) can be executed from
      --append-only                     Disallow deletion of repository data
      --baseurl string                  Prefix for URLs - leave blank for root
      --cache-objects                   Cache listed objects (default true)
      --cert string                     TLS PEM key (concatenation of certificate and CA certificate)
      --client-ca string                Client certificate authority to verify clients with
  -h, --help                            help for restic
      --htpasswd string                 A htpasswd file - if not provided no authentication is done
      --key string                      TLS PEM Private key
      --max-header-bytes int            Maximum size of request header (default 4096)
      --min-tls-version string          Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --pass string                     Password for authentication
      --private-repos                   Users can only access their private repo
      --realm string                    Realm for authentication
      --salt string                     Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --server-read-timeout Duration    Timeout for server reading data (default 1h0m0s)
      --server-write-timeout Duration   Timeout for server writing data (default 1h0m0s)
      --stdio                           Run an HTTP2 server on stdin/stdout
      --user string                     User name for authentication
      --user-from-header string         User name from a defined HTTP header
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone serve (https://rclone.org/commands/rclone_serve/) - Serve a
remote over a protocol.
.SH rclone serve s3
Serve remote:path over s3.
.SS Synopsis
\f[V]serve s3\f[R] implements a basic s3 server that serves a remote via
s3.
This can be viewed with an s3 client, or you can make an s3 type
remote (https://rclone.org/s3/) to read and write to it with rclone.
\f[V]serve s3\f[R] is considered \f[B]Experimental\f[R] so use with
care.
S3 server supports Signature Version 4 authentication.
Just use \f[V]--auth-key accessKey,secretKey\f[R] and set the
\f[V]Authorization\f[R] header correctly in the request.
(See the AWS
docs (https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html)).
\f[V]--auth-key\f[R] can be repeated for multiple auth pairs.
If \f[V]--auth-key\f[R] is not provided then \f[V]serve s3\f[R] will
allow anonymous access.
Please note that some clients may require HTTPS endpoints.
See the SSL docs for more information.
.PP
This command uses the VFS directory cache.
All the functionality will work with \f[V]--vfs-cache-mode off\f[R].
Using \f[V]--vfs-cache-mode full\f[R] (or \f[V]writes\f[R]) can be used
to cache objects locally to improve performance.
.PP
Use \f[V]--force-path-style=false\f[R] if you want to use the bucket
name as a part of the hostname (such as mybucket.local)
.PP
Use \f[V]--etag-hash\f[R] if you want to change the hash uses for the
\f[V]ETag\f[R].
Note that using anything other than \f[V]MD5\f[R] (the default) is
likely to cause problems for S3 clients which rely on the Etag being the
MD5.
.SS Quickstart
.PP
For a simple set up, to serve \f[V]remote:path\f[R] over s3, run the
server like this:
rclone serve s3 --auth-key ACCESS_KEY_ID,SECRET_ACCESS_KEY remote:path
For example, to use a simple folder in the filesystem, run the server
with a command like this:
.IP
.nf
\f[C]
rclone serve s3 --auth-key ACCESS_KEY_ID,SECRET_ACCESS_KEY local:/path/to/folder
\f[R]
.fi
.PP
The \f[V]rclone.conf\f[R] for the server could look like this:
.IP
.nf
\f[C]
[local]
type = local
\f[R]
.fi
.PP
The \f[V]local\f[R] configuration is optional though.
If you run the server with a \f[V]remote:path\f[R] like
\f[V]/path/to/folder\f[R] (without the \f[V]local:\f[R] prefix and
without an \f[V]rclone.conf\f[R] file), rclone will fall back to a
default configuration, which will be visible as a warning in the logs.
But it will run nonetheless.
.PP
This will be compatible with an rclone (client) remote configuration
which is defined like this:
.IP
.nf
\f[C]
[serves3]
type = s3
provider = Rclone
endpoint = http://127.0.0.1:8080/
access_key_id = ACCESS_KEY_ID
secret_access_key = SECRET_ACCESS_KEY
use_multipart_uploads = false
\f[R]
.fi
.PP
Note that setting \f[V]use_multipart_uploads = false\f[R] is to work
around a bug which will be fixed in due course.
.SS Bugs
.PP
When uploading multipart files \f[V]serve s3\f[R] holds all the parts in
memory (see #7453 (https://github.com/rclone/rclone/issues/7453)).
This is a limitaton of the library rclone uses for serving S3 and will
hopefully be fixed at some point.
.PP
Multipart server side copies do not work (see
#7454 (https://github.com/rclone/rclone/issues/7454)).
These take a very long time and eventually fail.
The default threshold for multipart server side copies is 5G which is
the maximum it can be, so files above this side will fail to be server
side copied.
.PP
For a current list of \f[V]serve s3\f[R] bugs see the serve
s3 (https://github.com/rclone/rclone/labels/serve%20s3) bug category on
GitHub.
.SS Limitations
.PP
\f[V]serve s3\f[R] will treat all directories in the root as buckets and
ignore all files in the root.
You can use \f[V]CreateBucket\f[R] to create folders under the root, but
you can\[aq]t create empty folders under other folders not in the root.
.PP
When using \f[V]PutObject\f[R] or \f[V]DeleteObject\f[R], rclone will
automatically create or clean up empty folders.
If you don\[aq]t want to clean up empty folders automatically, use
\f[V]--no-cleanup\f[R].
.PP
When using \f[V]ListObjects\f[R], rclone will use \f[V]/\f[R] when the
delimiter is empty.
This reduces backend requests with no effect on most operations, but if
the delimiter is something other than \f[V]/\f[R] and empty, rclone will
do a full recursive search of the backend, which can take some time.
.PP
Versioning is not currently supported.
.PP
Metadata will only be saved in memory other than the rclone
\f[V]mtime\f[R] metadata which will be set as the modification time of
the file.
.SS Supported operations
.PP
\f[V]serve s3\f[R] currently supports the following operations.
.IP \[bu] 2
Bucket
.RS 2
.IP \[bu] 2
\f[V]ListBuckets\f[R]
.IP \[bu] 2
\f[V]CreateBucket\f[R]
.IP \[bu] 2
\f[V]DeleteBucket\f[R]
.RE
.IP \[bu] 2
Object
.RS 2
.IP \[bu] 2
\f[V]HeadObject\f[R]
.IP \[bu] 2
\f[V]ListObjects\f[R]
.IP \[bu] 2
\f[V]GetObject\f[R]
.IP \[bu] 2
\f[V]PutObject\f[R]
.IP \[bu] 2
\f[V]DeleteObject\f[R]
.IP \[bu] 2
\f[V]DeleteObjects\f[R]
.IP \[bu] 2
\f[V]CreateMultipartUpload\f[R]
.IP \[bu] 2
\f[V]CompleteMultipartUpload\f[R]
.IP \[bu] 2
\f[V]AbortMultipartUpload\f[R]
.IP \[bu] 2
\f[V]CopyObject\f[R]
.IP \[bu] 2
\f[V]UploadPart\f[R]
.RE
.PP
Other operations will return error \f[V]Unimplemented\f[R].
.SS Authentication
.PP
By default this will serve files without needing a login.
.PP
You can either use an htpasswd file which can take lots of users, or set
a single username and password with the \f[V]--user\f[R] and
\f[V]--pass\f[R] flags.
.PP
Alternatively, you can have the reverse proxy manage authentication and
use the username provided in the configured header with
\f[V]--user-from-header\f[R] (e.g.,
\f[V]--user-from-header=x-remote-user\f[R]).
Ensure the proxy is trusted and headers cannot be spoofed, as
misconfiguration may lead to unauthorized access.
.PP
If either of the above authentication methods is not configured and
client certificates are required by the \f[V]--client-ca\f[R] flag
passed to the server, the client certificate common name will be
considered as the username.
.PP
Use \f[V]--htpasswd /path/to/htpasswd\f[R] to provide an htpasswd file.
This is in standard apache format and supports MD5, SHA1 and BCrypt for
basic authentication.
Bcrypt is recommended.
.PP
To create an htpasswd file:
.IP
.nf
\f[C]
touch htpasswd
htpasswd -B htpasswd user
htpasswd -B htpasswd anotherUser
\f[R]
.fi
.PP
The password file can be updated while rclone is running.
.PP
Use \f[V]--realm\f[R] to set the authentication realm.
.PP
Use \f[V]--salt\f[R] to change the password hashing salt from the
default.
.SS Server options
.PP
Use \f[V]--addr\f[R] to specify which IP address and port the server
should listen on, eg \f[V]--addr 1.2.3.4:8000\f[R] or
\f[V]--addr :8080\f[R] to listen to all IPs.
By default it only listens on localhost.
You can use port :0 to let the OS choose an available port.
.PP
If you set \f[V]--addr\f[R] to listen on a public or LAN accessible IP
address then using Authentication is advised - see the next section for
info.
.PP
You can use a unix socket by setting the url to
\f[V]unix:///path/to/socket\f[R] or just by using an absolute path name.
.PP
\f[V]--addr\f[R] may be repeated to listen on multiple
IPs/ports/sockets.
Socket activation, described further below, can also be used to
accomplish the same.
.PP
\f[V]--server-read-timeout\f[R] and \f[V]--server-write-timeout\f[R] can
be used to control the timeouts on the server.
Note that this is the total time for a transfer.
.PP
\f[V]--max-header-bytes\f[R] controls the maximum number of bytes the
server will accept in the HTTP header.
.PP
\f[V]--baseurl\f[R] controls the URL prefix that rclone serves from.
By default rclone will serve from the root.
If you used \f[V]--baseurl \[dq]/rclone\[dq]\f[R] then rclone would
serve from a URL starting with \[dq]/rclone/\[dq].
This is useful if you wish to proxy rclone serve.
Rclone automatically inserts leading and trailing \[dq]/\[dq] on
\f[V]--baseurl\f[R], so \f[V]--baseurl \[dq]rclone\[dq]\f[R],
\f[V]--baseurl \[dq]/rclone\[dq]\f[R] and
\f[V]--baseurl \[dq]/rclone/\[dq]\f[R] are all treated identically.
.PP
\f[V]--disable-zip\f[R] may be set to disable the zipping download
option.
.SS TLS (SSL)
.PP
By default this will serve over http.
If you want you can serve over https.
You will need to supply the \f[V]--cert\f[R] and \f[V]--key\f[R] flags.
If you wish to do client side certificate validation then you will need
to supply \f[V]--client-ca\f[R] also.
.PP
\f[V]--cert\f[R] must be set to the path of a file containing either a
PEM encoded certificate, or a concatenation of that with the CA
certificate.
\f[V]--key\f[R] must be set to the path of a file with the PEM encoded
private key.
If setting \f[V]--client-ca\f[R], it should be set to the path of a file
with PEM encoded client certificate authority certificates.
.PP
\f[V]--min-tls-version\f[R] is minimum TLS version that is acceptable.
Valid values are \[dq]tls1.0\[dq], \[dq]tls1.1\[dq], \[dq]tls1.2\[dq]
and \[dq]tls1.3\[dq] (default \[dq]tls1.0\[dq]).
.SS Socket activation
.PP
Instead of the listening addresses specified above, rclone will listen
to all FDs passed by the service manager, if any (and ignore any
arguments passed by \f[V]--addr\f[R]).
.PP
This allows rclone to be a socket-activated service.
It can be configured with .socket and .service unit files as described
in
<https://www.freedesktop.org/software/systemd/man/latest/systemd.socket.html>.
.PP
Socket activation can be tested ad-hoc with the
\f[V]systemd-socket-activate\f[R]command
.IP
.nf
\f[C]
systemd-socket-activate -l 8000 -- rclone serve
\f[R]
.fi
.PP
This will socket-activate rclone on the first connection to port 8000
over TCP.
.SS VFS - Virtual File System
.PP
This command uses the VFS layer.
This adapts the cloud storage objects that rclone uses into something
which looks much more like a disk filing system.
.PP
Cloud storage objects have lots of properties which aren\[aq]t like disk
files - you can\[aq]t extend them or write to the middle of them, so the
VFS layer has to deal with that.
Because there is no one right way of doing this there are various
options explained below.
.PP
The VFS layer also implements a directory cache - this caches info about
files and directories (but not the data) in memory.
.SS VFS Directory Cache
.PP
Using the \f[V]--dir-cache-time\f[R] flag, you can control how long a
directory should be considered up to date and not refreshed from the
backend.
Changes made through the VFS will appear immediately or invalidate the
cache.
.IP
.nf
\f[C]
    --dir-cache-time duration   Time to cache directory entries for (default 5m0s)
    --poll-interval duration    Time to wait between polling for changes. Must be smaller than dir-cache-time. Only on supported remotes. Set to 0 to disable (default 1m0s)
\f[R]
.fi
.PP
However, changes made directly on the cloud storage by the web interface
or a different copy of rclone will only be picked up once the directory
cache expires if the backend configured does not support polling for
changes.
If the backend supports polling, changes will be picked up within the
polling interval.
.PP
You can send a \f[V]SIGHUP\f[R] signal to rclone for it to flush all
directory caches, regardless of how old they are.
Assuming only one rclone instance is running, you can reset the cache
like this:
.IP
.nf
\f[C]
kill -SIGHUP $(pidof rclone)
\f[R]
.fi
.PP
If you configure rclone with a remote control then you can use rclone rc
to flush the whole directory cache:
.IP
.nf
\f[C]
rclone rc vfs/forget
\f[R]
.fi
.PP
Or individual files or directories:
.IP
.nf
\f[C]
rclone rc vfs/forget file=path/to/file dir=path/to/dir
\f[R]
.fi
.SS VFS File Buffering
.PP
The \f[V]--buffer-size\f[R] flag determines the amount of memory, that
will be used to buffer data in advance.
.PP
Each open file will try to keep the specified amount of data in memory
at all times.
The buffered data is bound to one open file and won\[aq]t be shared.
.PP
This flag is a upper limit for the used memory per open file.
The buffer will only use memory for data that is downloaded but not not
yet read.
If the buffer is empty, only a small amount of memory will be used.
.PP
The maximum memory used by rclone for buffering can be up to
\f[V]--buffer-size * open files\f[R].
.SS VFS File Caching
.PP
These flags control the VFS file caching options.
File caching is necessary to make the VFS layer appear compatible with a
normal file system.
It can be disabled at the cost of some compatibility.
.PP
For example you\[aq]ll need to enable VFS caching if you want to read
and write simultaneously to a file.
See below for more details.
.PP
Note that the VFS cache is separate from the cache backend and you may
find that you need one or the other or both.
.IP
.nf
\f[C]
    --cache-dir string                     Directory rclone will use for caching.
    --vfs-cache-mode CacheMode             Cache mode off|minimal|writes|full (default off)
    --vfs-cache-max-age duration           Max time since last access of objects in the cache (default 1h0m0s)
    --vfs-cache-max-size SizeSuffix        Max total size of objects in the cache (default off)
    --vfs-cache-min-free-space SizeSuffix  Target minimum free space on the disk containing the cache (default off)
    --vfs-cache-poll-interval duration     Interval to poll the cache for stale objects (default 1m0s)
    --vfs-write-back duration              Time to writeback files after last use when using cache (default 5s)
\f[R]
.fi
.PP
If run with \f[V]-vv\f[R] rclone will print the location of the file
cache.
The files are stored in the user cache file area which is OS dependent
but can be controlled with \f[V]--cache-dir\f[R] or setting the
appropriate environment variable.
.PP
The cache has 4 different modes selected by \f[V]--vfs-cache-mode\f[R].
The higher the cache mode the more compatible rclone becomes at the cost
of using disk space.
.PP
Note that files are written back to the remote only when they are closed
and if they haven\[aq]t been accessed for \f[V]--vfs-write-back\f[R]
rclone serve s3 remote:path [flags]
      --addr stringArray                       IPaddress:Port or :Port to bind server to (default 127.0.0.1:8080)
      --allow-origin string                    Origin which cross-domain request (CORS) can be executed from
      --auth-key stringArray                   Set key pair for v4 authorization: access_key_id,secret_access_key
      --auth-proxy string                      A program to use to create the backend from the auth
      --baseurl string                         Prefix for URLs - leave blank for root
      --cert string                            TLS PEM key (concatenation of certificate and CA certificate)
      --client-ca string                       Client certificate authority to verify clients with
      --etag-hash string                       Which hash to use for the ETag, or auto or blank for off (default \[dq]MD5\[dq])
      --force-path-style                       If true use path style access if false use virtual hosted style (default true)
  -h, --help                                   help for s3
      --htpasswd string                        A htpasswd file - if not provided no authentication is done
      --key string                             TLS PEM Private key
      --max-header-bytes int                   Maximum size of request header (default 4096)
      --min-tls-version string                 Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --no-cleanup                             Not to cleanup empty folder after object is deleted
      --pass string                            Password for authentication
      --realm string                           Realm for authentication
      --salt string                            Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --server-read-timeout Duration           Timeout for server reading data (default 1h0m0s)
      --server-write-timeout Duration          Timeout for server writing data (default 1h0m0s)
      --user string                            User name for authentication
      --user-from-header string                User name from a defined HTTP header
.SH rclone serve sftp
Serve the remote over SFTP.
Run an SFTP server to serve a remote over SFTP.
This can be used with an SFTP client or you can make a remote of type
sftp to use with it.
You can use the filter flags (e.g.
\f[V]--include\f[R], \f[V]--exclude\f[R]) to control what is served.
.PP
The server will respond to a small number of shell commands, mainly
md5sum, sha1sum and df, which enable it to provide support for checksums
and the about feature when accessed from an sftp remote.
.PP
Note that this server uses standard 32 KiB packet payload size, which
means you must not configure the client to expect anything else, e.g.
with the chunk_size (https://rclone.org/sftp/#sftp-chunk-size) option on
an sftp remote.
Use \f[V]-v\f[R] to see access logs.
You must provide some means of authentication, either with
\f[V]--user\f[R]/\f[V]--pass\f[R], an authorized keys file (specify
location with \f[V]--authorized-keys\f[R] - the default is the same as
ssh), an \f[V]--auth-proxy\f[R], or set the \f[V]--no-auth\f[R] flag for
no authentication when logging in.
If you don\[aq]t supply a host \f[V]--key\f[R] then rclone will generate
rsa, ecdsa and ed25519 variants, and cache them for later use in
rclone\[aq]s cache directory (see \f[V]rclone help flags cache-dir\f[R])
in the \[dq]serve-sftp\[dq] directory.
By default the server binds to localhost:2022 - if you want it to be
reachable externally then supply \f[V]--addr :2022\f[R] for example.
.PP
This also supports being run with socket activation, in which case it
will listen on the first passed FD.
It can be configured with .socket and .service unit files as described
in
<https://www.freedesktop.org/software/systemd/man/latest/systemd.socket.html>.
.PP
Socket activation can be tested ad-hoc with the
\f[V]systemd-socket-activate\f[R]command:
systemd-socket-activate -l 2222 -- rclone serve sftp :local:vfs/
This will socket-activate rclone on the first connection to port 2222
over TCP.
Note that the default of \f[V]--vfs-cache-mode off\f[R] is fine for the
rclone sftp backend, but it may not be with other SFTP clients.
If \f[V]--stdio\f[R] is specified, rclone will serve SFTP over stdio,
which can be used with sshd via \[ti]/.ssh/authorized_keys, for example:
.IP
.nf
\f[C]
restrict,command=\[dq]rclone serve sftp --stdio ./photos\[dq] ssh-rsa ...
\f[R]
.fi
On the client you need to set \f[V]--transfers 1\f[R] when using
\f[V]--stdio\f[R].
Otherwise multiple instances of the rclone server are started by OpenSSH
which can lead to \[dq]corrupted on transfer\[dq] errors.
This is the case because the client chooses indiscriminately which
server to send commands to while the servers all have different views of
the state of the filing system.
The \[dq]restrict\[dq] in authorized_keys prevents SHA1SUMs and MD5SUMs
from being used.
Omitting \[dq]restrict\[dq] and using \f[V]--sftp-path-override\f[R] to
enable checksumming is possible but less secure and you could use the
SFTP server provided by OpenSSH in this case.
.SS VFS - Virtual File System
This command uses the VFS layer.
This adapts the cloud storage objects that rclone uses into something
which looks much more like a disk filing system.
Cloud storage objects have lots of properties which aren\[aq]t like disk
files - you can\[aq]t extend them or write to the middle of them, so the
VFS layer has to deal with that.
Because there is no one right way of doing this there are various
options explained below.
The VFS layer also implements a directory cache - this caches info about
files and directories (but not the data) in memory.
.SS VFS Directory Cache
.PP
Using the \f[V]--dir-cache-time\f[R] flag, you can control how long a
directory should be considered up to date and not refreshed from the
backend.
Changes made through the VFS will appear immediately or invalidate the
cache.
.SS Auth Proxy
.PP
If you supply the parameter \f[V]--auth-proxy /path/to/program\f[R] then
rclone will use that program to generate backends on the fly which then
are used to authenticate incoming requests.
This uses a simple JSON based protocol with input on STDIN and output on
STDOUT.
.PP
\f[B]PLEASE NOTE:\f[R] \f[V]--auth-proxy\f[R] and
\f[V]--authorized-keys\f[R] cannot be used together, if
\f[V]--auth-proxy\f[R] is set the authorized keys option will be
ignored.
.PP
There is an example program
bin/test_proxy.py (https://github.com/rclone/rclone/blob/master/bin/test_proxy.py)
in the rclone source code.
.PP
The program\[aq]s job is to take a \f[V]user\f[R] and \f[V]pass\f[R] on
the input and turn those into the config for a backend on STDOUT in JSON
format.
This config will have any default parameters for the backend added, but
it won\[aq]t use configuration from environment variables or command
line options - it is the job of the proxy program to make a complete
config.
.PP
This config generated must have this extra parameter
.IP \[bu] 2
\f[V]_root\f[R] - root to use for the backend
.PP
And it may have this parameter
.IP \[bu] 2
\f[V]_obscure\f[R] - comma separated strings for parameters to obscure
.PP
If password authentication was used by the client, input to the proxy
process (on STDIN) would look similar to this:
.IP
.nf
\f[C]
{
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]pass\[dq]: \[dq]mypassword\[dq]
}
\f[R]
.fi
.PP
If public-key authentication was used by the client, input to the proxy
process (on STDIN) would look similar to this:
.IP
.nf
\f[C]
{
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]public_key\[dq]: \[dq]AAAAB3NzaC1yc2EAAAADAQABAAABAQDuwESFdAe14hVS6omeyX7edc...JQdf\[dq]
}
\f[R]
.fi
.PP
And as an example return this on STDOUT
.IP
.nf
\f[C]
{
  \[dq]type\[dq]: \[dq]sftp\[dq],
  \[dq]_root\[dq]: \[dq]\[dq],
  \[dq]_obscure\[dq]: \[dq]pass\[dq],
  \[dq]user\[dq]: \[dq]me\[dq],
  \[dq]pass\[dq]: \[dq]mypassword\[dq],
  \[dq]host\[dq]: \[dq]sftp.example.com\[dq]
}
\f[R]
.fi
.PP
This would mean that an SFTP backend would be created on the fly for the
\f[V]user\f[R] and \f[V]pass\f[R]/\f[V]public_key\f[R] returned in the
output to the host given.
Note that since \f[V]_obscure\f[R] is set to \f[V]pass\f[R], rclone will
obscure the \f[V]pass\f[R] parameter before creating the backend (which
is required for sftp backends).
.PP
The program can manipulate the supplied \f[V]user\f[R] in any way, for
example to make proxy to many different sftp backends, you could make
the \f[V]user\f[R] be \f[V]user\[at]example.com\f[R] and then set the
\f[V]host\f[R] to \f[V]example.com\f[R] in the output and the user to
\f[V]user\f[R].
For security you\[aq]d probably want to restrict the \f[V]host\f[R] to a
limited list.
.PP
Note that an internal cache is keyed on \f[V]user\f[R] so only use that
for configuration, don\[aq]t use \f[V]pass\f[R] or \f[V]public_key\f[R].
This also means that if a user\[aq]s password or public-key is changed
the cache will need to expire (which takes 5 mins) before it takes
effect.
.PP
This can be used to build general purpose proxies to any kind of backend
that rclone supports.
.IP
.nf
\f[C]
rclone serve sftp remote:path [flags]
      --addr string                            IPaddress:Port or :Port to bind server to (default \[dq]localhost:2022\[dq])
      --authorized-keys string                 Authorized keys file (default \[dq]\[ti]/.ssh/authorized_keys\[dq])
  -h, --help                                   help for sftp
      --key stringArray                        SSH private host key file (Can be multi-valued, leave blank to auto generate)
      --no-auth                                Allow connections with no authentication if set
      --stdio                                  Run an sftp server on stdin/stdout
.SH rclone serve webdav
Serve remote:path over WebDAV.
Run a basic WebDAV server to serve a remote over HTTP via the WebDAV
protocol.
This can be viewed with a WebDAV client, through a web browser, or you
can make a remote of type WebDAV to read and write it.
.SS WebDAV options
.SS --etag-hash
This controls the ETag header.
Without this flag the ETag will be based on the ModTime and Size of the
object.
If this flag is set to \[dq]auto\[dq] then rclone will choose the first
supported hash on the backend or you can use a named hash such as
\[dq]MD5\[dq] or \[dq]SHA-1\[dq].
Use the hashsum (https://rclone.org/commands/rclone_hashsum/) command to
see the full list.
.SS Access WebDAV on Windows
WebDAV shared folder can be mapped as a drive on Windows, however the
default settings prevent it.
Windows will fail to connect to the server using insecure Basic
authentication.
It will not even display any login dialog.
Windows requires SSL / HTTPS connection to be used with Basic.
If you try to connect via Add Network Location Wizard you will get the
following error: \[dq]The folder you entered does not appear to be
valid.
Please choose another\[dq].
However, you still can connect if you set the following registry key on
a client machine:
\f[V]HKEY_LOCAL_MACHINE\[rs]SYSTEM\[rs]CurrentControlSet\[rs]Services\[rs]WebClient\[rs]Parameters\[rs]BasicAuthLevel\f[R]
to 2.
The BasicAuthLevel can be set to the following values:
.IP
.nf
\f[C]
0 - Basic authentication disabled
1 - Basic authentication enabled for SSL connections only
2 - Basic authentication enabled for SSL connections and for non-SSL connections
\f[R]
.fi
If required, increase the FileSizeLimitInBytes to a higher value.
Navigate to the Services interface, then restart the WebClient service.
.SS Access Office applications on WebDAV
Navigate to following registry
\f[V]HKEY_CURRENT_USER\[rs]Software\[rs]Microsoft\[rs]Office\[rs][14.0/15.0/16.0]\[rs]Common\[rs]Internet\f[R]
Create a new DWORD BasicAuthLevel with value 2.
.IP
.nf
\f[C]
0 - Basic authentication disabled
1 - Basic authentication enabled for SSL connections only
2 - Basic authentication enabled for SSL and for non-SSL connections
\f[R]
.fi
<https://learn.microsoft.com/en-us/office/troubleshoot/powerpoint/office-opens-blank-from-sharepoint>
.SS Serving over a unix socket
You can serve the webdav on a unix socket like this:
.IP
.nf
\f[C]
rclone serve webdav --addr unix:///tmp/my.socket remote:path
\f[R]
.fi
and connect to it like this using rclone and the webdav backend:
.IP
.nf
\f[C]
rclone --webdav-unix-socket /tmp/my.socket --webdav-url http://localhost lsf :webdav:
\f[R]
.fi
Note that there is no authentication on http protocol - this is expected
to be done by the permissions on the socket.
.SS Server options
.PP
Use \f[V]--addr\f[R] to specify which IP address and port the server
should listen on, eg \f[V]--addr 1.2.3.4:8000\f[R] or
\f[V]--addr :8080\f[R] to listen to all IPs.
By default it only listens on localhost.
You can use port :0 to let the OS choose an available port.
.PP
If you set \f[V]--addr\f[R] to listen on a public or LAN accessible IP
address then using Authentication is advised - see the next section for
info.
.PP
You can use a unix socket by setting the url to
\f[V]unix:///path/to/socket\f[R] or just by using an absolute path name.
.PP
\f[V]--addr\f[R] may be repeated to listen on multiple
IPs/ports/sockets.
Socket activation, described further below, can also be used to
accomplish the same.
.PP
\f[V]--server-read-timeout\f[R] and \f[V]--server-write-timeout\f[R] can
be used to control the timeouts on the server.
Note that this is the total time for a transfer.
.PP
\f[V]--max-header-bytes\f[R] controls the maximum number of bytes the
server will accept in the HTTP header.
.PP
\f[V]--baseurl\f[R] controls the URL prefix that rclone serves from.
By default rclone will serve from the root.
If you used \f[V]--baseurl \[dq]/rclone\[dq]\f[R] then rclone would
serve from a URL starting with \[dq]/rclone/\[dq].
This is useful if you wish to proxy rclone serve.
Rclone automatically inserts leading and trailing \[dq]/\[dq] on
\f[V]--baseurl\f[R], so \f[V]--baseurl \[dq]rclone\[dq]\f[R],
\f[V]--baseurl \[dq]/rclone\[dq]\f[R] and
\f[V]--baseurl \[dq]/rclone/\[dq]\f[R] are all treated identically.
.PP
\f[V]--disable-zip\f[R] may be set to disable the zipping download
option.
.SS TLS (SSL)
.PP
By default this will serve over http.
If you want you can serve over https.
You will need to supply the \f[V]--cert\f[R] and \f[V]--key\f[R] flags.
If you wish to do client side certificate validation then you will need
to supply \f[V]--client-ca\f[R] also.
.PP
\f[V]--cert\f[R] must be set to the path of a file containing either a
PEM encoded certificate, or a concatenation of that with the CA
certificate.
\f[V]--key\f[R] must be set to the path of a file with the PEM encoded
private key.
If setting \f[V]--client-ca\f[R], it should be set to the path of a file
with PEM encoded client certificate authority certificates.
.PP
\f[V]--min-tls-version\f[R] is minimum TLS version that is acceptable.
Valid values are \[dq]tls1.0\[dq], \[dq]tls1.1\[dq], \[dq]tls1.2\[dq]
and \[dq]tls1.3\[dq] (default \[dq]tls1.0\[dq]).
.SS Socket activation
.PP
Instead of the listening addresses specified above, rclone will listen
to all FDs passed by the service manager, if any (and ignore any
arguments passed by \f[V]--addr\f[R]).
.PP
This allows rclone to be a socket-activated service.
\f[V]systemd-socket-activate\f[R]command
systemd-socket-activate -l 8000 -- rclone serve
This will socket-activate rclone on the first connection to port 8000
.SS Template
\f[V]--template\f[R] allows a user to specify a custom markup template
for HTTP and WebDAV serve functions.
The server exports the following markup to be used within the template
to server pages:
.TS
tab(@);
lw(22.6n) lw(24.7n) lw(22.6n).
T{
Parameter
T}@T{
Subparameter
T}@T{
Description
T}
_
T{
\&.Name
T}@T{
T}@T{
The full path of a file/directory.
T}
T{
\&.Title
T}@T{
T}@T{
Directory listing of \[aq].Name\[aq].
T}
T{
\&.Sort
T}@T{
T}@T{
The current sort used.
This is changeable via \[aq]?sort=\[aq] parameter.
Possible values: namedirfirst, name, size, time (default namedirfirst).
T}
T{
\&.Order
T}@T{
T}@T{
The current ordering used.
This is changeable via \[aq]?order=\[aq] parameter.
Possible values: asc, desc (default asc).
T}
T{
\&.Query
T}@T{
T}@T{
Currently unused.
T}
T{
\&.Breadcrumb
T}@T{
T}@T{
Allows for creating a relative navigation.
T}
T{
T}@T{
\&.Link
T}@T{
The link of the Text relative to the root.
T}
T{
T}@T{
\&.Text
T}@T{
The Name of the directory.
T}
T{
\&.Entries
T}@T{
T}@T{
Information about a specific file/directory.
T}
T{
T}@T{
\&.URL
T}@T{
The url of an entry.
T}
T{
T}@T{
\&.Leaf
T}@T{
Currently same as \[aq].URL\[aq] but intended to be just the name.
T}
T{
T}@T{
\&.IsDir
T}@T{
Boolean for if an entry is a directory or not.
T}
T{
T}@T{
\&.Size
T}@T{
Size in bytes of the entry.
T}
T{
T}@T{
\&.ModTime
T}@T{
The UTC timestamp of an entry.
T}
.TE
.PP
The server also makes the following functions available so that they can
be used within the template.
These functions help extend the options for dynamic rendering of HTML.
They can be used to render HTML based on specific conditions.
.PP
.TS
tab(@);
lw(35.0n) lw(35.0n).
T{
Function
T}@T{
Description
T}
_
T{
afterEpoch
T}@T{
Returns the time since the epoch for the given time.
T}
T{
contains
T}@T{
Checks whether a given substring is present or not in a given string.
T}
T{
hasPrefix
T}@T{
Checks whether the given string begins with the specified prefix.
T}
T{
hasSuffix
T}@T{
Checks whether the given string end with the specified suffix.
T}
.TE
.SS Authentication
.PP
By default this will serve files without needing a login.
.PP
You can either use an htpasswd file which can take lots of users, or set
a single username and password with the \f[V]--user\f[R] and
\f[V]--pass\f[R] flags.
.PP
Alternatively, you can have the reverse proxy manage authentication and
use the username provided in the configured header with
\f[V]--user-from-header\f[R] (e.g.,
\f[V]--user-from-header=x-remote-user\f[R]).
Ensure the proxy is trusted and headers cannot be spoofed, as
misconfiguration may lead to unauthorized access.
.PP
If either of the above authentication methods is not configured and
client certificates are required by the \f[V]--client-ca\f[R] flag
passed to the server, the client certificate common name will be
considered as the username.
.PP
Use \f[V]--htpasswd /path/to/htpasswd\f[R] to provide an htpasswd file.
This is in standard apache format and supports MD5, SHA1 and BCrypt for
basic authentication.
Bcrypt is recommended.
.PP
To create an htpasswd file:
touch htpasswd
htpasswd -B htpasswd user
htpasswd -B htpasswd anotherUser
The password file can be updated while rclone is running.
Use \f[V]--realm\f[R] to set the authentication realm.
.PP
Use \f[V]--salt\f[R] to change the password hashing salt from the
default.
rclone serve webdav remote:path [flags]
      --addr stringArray                       IPaddress:Port or :Port to bind server to (default 127.0.0.1:8080)
      --allow-origin string                    Origin which cross-domain request (CORS) can be executed from
      --baseurl string                         Prefix for URLs - leave blank for root
      --cert string                            TLS PEM key (concatenation of certificate and CA certificate)
      --client-ca string                       Client certificate authority to verify clients with
      --disable-dir-list                       Disable HTML directory list on GET request for a directory
      --etag-hash string                       Which hash to use for the ETag, or auto or blank for off
  -h, --help                                   help for webdav
      --htpasswd string                        A htpasswd file - if not provided no authentication is done
      --key string                             TLS PEM Private key
      --max-header-bytes int                   Maximum size of request header (default 4096)
      --min-tls-version string                 Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --realm string                           Realm for authentication
      --salt string                            Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --server-read-timeout Duration           Timeout for server reading data (default 1h0m0s)
      --server-write-timeout Duration          Timeout for server writing data (default 1h0m0s)
      --template string                        User-specified template
      --uid uint32                             Override the uid field set by the filesystem (not supported on Windows) (default 1000)
      --umask FileMode                         Override the permission bits set by the filesystem (not supported on Windows) (default 002)
      --user-from-header string                User name from a defined HTTP header
.SH rclone settier
Changes storage class/tier of objects in remote.
Changes storage tier or class at remote if supported.
Few cloud storage services provides different storage classes on
objects, for example AWS S3 and Glacier, Azure Blob storage - Hot, Cool
and Archive, Google Cloud Storage, Regional Storage, Nearline, Coldline
etc.
Note that, certain tier changes make objects not available to access
immediately.
For example tiering to archive in azure blob storage makes objects in
frozen state, user can restore by setting tier to Hot/Cool, similarly S3
to Glacier makes object inaccessible.true
You can use it to tier single object
rclone settier Cool remote:path/file
Or use rclone filters to set tier on only specific files
rclone --include \[dq]*.txt\[dq] settier Hot remote:path/dir
Or just provide remote directory and all files in directory will be
tiered
rclone settier tier remote:path/dir
rclone settier tier remote:path [flags]
.SS Options
  -h, --help   help for settier
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone (https://rclone.org/commands/rclone/) - Show help for rclone
commands, flags and backends.
.SH rclone test
Run a test command
.SS Synopsis
Rclone test is used to run test commands.
Select which test command you want with the subcommand, eg
rclone test memory remote:
Each subcommand has its own options which you can see in their help.
\f[B]NB\f[R] Be careful running these commands, they may do strange
things so reading their documentation first is recommended.
.SS Options
  -h, --help   help for test
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone (https://rclone.org/commands/rclone/) - Show help for rclone
commands, flags and backends.
.IP \[bu] 2
rclone test
changenotify (https://rclone.org/commands/rclone_test_changenotify/) -
Log any change notify requests for the remote passed in.
.IP \[bu] 2
rclone test
histogram (https://rclone.org/commands/rclone_test_histogram/) - Makes a
histogram of file name characters.
.IP \[bu] 2
rclone test info (https://rclone.org/commands/rclone_test_info/) -
Discovers file name or other limitations for paths.
.IP \[bu] 2
rclone test makefile (https://rclone.org/commands/rclone_test_makefile/)
- Make files with random contents of the size given
.IP \[bu] 2
rclone test
makefiles (https://rclone.org/commands/rclone_test_makefiles/) - Make a
random file hierarchy in a directory
.IP \[bu] 2
rclone test memory (https://rclone.org/commands/rclone_test_memory/) -
Load all the objects at remote:path into memory and report memory stats.
.IP \[bu] 2
rclone test speed (https://rclone.org/commands/rclone_test_speed/) - Run
a speed test to the remote
.SH rclone test changenotify
Log any change notify requests for the remote passed in.
rclone test changenotify remote: [flags]
.SS Options
  -h, --help                     help for changenotify
      --poll-interval Duration   Time to wait between polling for changes (default 10s)
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test histogram
.PP
Makes a histogram of file name characters.
.SS Synopsis
.PP
This command outputs JSON which shows the histogram of characters used
in filenames in the remote:path specified.
.PP
The data doesn\[aq]t contain any identifying information but is useful
for the rclone developers when developing filename compression.
rclone test histogram [remote:path] [flags]
.SS Options
  -h, --help   help for histogram
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test info
Discovers file name or other limitations for paths.
.SS Synopsis
Discovers what filenames and upload methods are possible to write to the
paths passed in and how long they can be.
It can take some time.
It will write test files into the remote:path passed in.
It outputs a bit of go code for each one.
\f[B]NB\f[R] this can create undeletable files and other hazards - use
with care!
.IP
.nf
\f[C]
rclone test info [remote:path]+ [flags]
\f[R]
.fi
.SS Options
.IP
.nf
\f[C]
      --all                    Run all tests
      --check-base32768        Check can store all possible base32768 characters
      --check-control          Check control characters
      --check-length           Check max filename length
      --check-normalization    Check UTF-8 Normalization
      --check-streaming        Check uploads with indeterminate file size
  -h, --help                   help for info
      --keep-test-files        Keep test files after execution
      --upload-wait Duration   Wait after writing a file (default 0s)
      --write-json string      Write results to file
\f[R]
.fi
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test makefile
Make files with random contents of the size given
.IP
.nf
\f[C]
rclone test makefile <size> [<file>]+ [flags]
\f[R]
.fi
.SS Options
.IP
.nf
\f[C]
      --ascii      Fill files with random ASCII printable bytes only
      --chargen    Fill files with a ASCII chargen pattern
  -h, --help       help for makefile
      --pattern    Fill files with a periodic pattern
      --seed int   Seed for the random number generator (0 for random) (default 1)
      --sparse     Make the files sparse (appear to be filled with ASCII 0x00)
      --zero       Fill files with ASCII 0x00
\f[R]
.fi
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test makefiles
Make a random file hierarchy in a directory
.IP
.nf
\f[C]
rclone test makefiles <dir> [flags]
\f[R]
.fi
.SS Options
.IP
.nf
\f[C]
      --ascii                      Fill files with random ASCII printable bytes only
      --chargen                    Fill files with a ASCII chargen pattern
      --files int                  Number of files to create (default 1000)
      --files-per-directory int    Average number of files per directory (default 10)
      --flat                       If set create all files in the root directory
  -h, --help                       help for makefiles
      --max-depth int              Maximum depth of directory hierarchy (default 10)
      --max-file-size SizeSuffix   Maximum size of files to create (default 100)
      --max-name-length int        Maximum size of file names (default 12)
      --min-file-size SizeSuffix   Minimum size of file to create
      --min-name-length int        Minimum size of file names (default 4)
      --pattern                    Fill files with a periodic pattern
      --seed int                   Seed for the random number generator (0 for random) (default 1)
      --sparse                     Make the files sparse (appear to be filled with ASCII 0x00)
      --zero                       Fill files with ASCII 0x00
\f[R]
.fi
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test memory
Load all the objects at remote:path into memory and report memory stats.
.IP
.nf
\f[C]
rclone test memory remote:path [flags]
\f[R]
.fi
.SS Options
.IP
.nf
\f[C]
  -h, --help   help for memory
\f[R]
.fi
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone test speed
Run a speed test to the remote
.SS Synopsis
Run a speed test to the remote.
This command runs a series of uploads and downloads to the remote,
measuring and printing the speed of each test using varying file sizes
and numbers of files.
Test time can be innaccurate with small file caps and large files.
As it uses the results of an initial test to determine how many files to
use in each subsequent test.
It is recommended to use -q flag for a simpler output.
e.g.:
rclone test speed remote: -q
\f[B]NB\f[R] This command will create and delete files on the remote in
a randomly named directory which will be automatically removed on a
clean exit.
You can use the --json flag to only print the results in JSON format.
.IP
.nf
\f[C]
rclone test speed <remote> [flags]
\f[R]
.fi
.SS Options
.IP
.nf
\f[C]
      --ascii                Fill files with random ASCII printable bytes only
      --chargen              Fill files with a ASCII chargen pattern
      --file-cap int         Maximum number of files to use in each test (default 100)
  -h, --help                 help for speed
      --json                 Output only results in JSON format
      --large SizeSuffix     Size of large files (default 1Gi)
      --medium SizeSuffix    Size of medium files (default 10Mi)
      --pattern              Fill files with a periodic pattern
      --seed int             Seed for the random number generator (0 for random) (default 1)
      --small SizeSuffix     Size of small files (default 1Ki)
      --sparse               Make the files sparse (appear to be filled with ASCII 0x00)
      --test-time Duration   Length for each test to run (default 15s)
      --zero                 Fill files with ASCII 0x00
\f[R]
.fi
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS See Also
.IP \[bu] 2
rclone test (https://rclone.org/commands/rclone_test/) - Run a test
command
.SH rclone touch
Create new file or change file modification time.
.SS Synopsis
Set the modification time on file(s) as specified by remote:path to have
the current time.
If remote:path does not exist then a zero sized file will be created,
unless \f[V]--no-create\f[R] or \f[V]--recursive\f[R] is provided.
If \f[V]--recursive\f[R] is used then recursively sets the modification
time on all existing files that is found under the path.
Filters are supported, and you can test with the \f[V]--dry-run\f[R] or
the \f[V]--interactive\f[R]/\f[V]-i\f[R] flag.
This will touch \f[V]--transfers\f[R] files concurrently.
If \f[V]--timestamp\f[R] is used then sets the modification time to that
time instead of the current time.
Times may be specified as one of:
.IP \[bu] 2
\[aq]YYMMDD\[aq] - e.g.
17.10.30
.IP \[bu] 2
\[aq]YYYY-MM-DDTHH:MM:SS\[aq] - e.g.
2006-01-02T15:04:05
.IP \[bu] 2
\[aq]YYYY-MM-DDTHH:MM:SS.SSS\[aq] - e.g.
2006-01-02T15:04:05.123456789
Note that value of \f[V]--timestamp\f[R] is in UTC.
If you want local time then add the \f[V]--localtime\f[R] flag.
rclone touch remote:path [flags]
.SS Options
  -h, --help               help for touch
      --localtime          Use localtime for timestamp, not UTC
  -C, --no-create          Do not create the file if it does not exist (implied with --recursive)
  -R, --recursive          Recursively touch all files
  -t, --timestamp string   Use specified time instead of the current time of day
Options shared with other commands are described next.
See the global flags page (https://rclone.org/flags/) for global options
not listed here.
.SS Important Options
.PP
Important flags useful for most commands
  -n, --dry-run         Do a trial run with no permanent changes
  -i, --interactive     Enable interactive mode
  -v, --verbose count   Print lots more stuff (repeat for more)
.SS Filter Options
Flags for filtering directory listings
      --delete-excluded                     Delete files on dest excluded from sync
      --exclude stringArray                 Exclude files matching pattern
      --exclude-from stringArray            Read file exclude patterns from file (use - to read from stdin)
      --exclude-if-present stringArray      Exclude directories if filename is present
      --files-from stringArray              Read list of source-file names from file (use - to read from stdin)
      --files-from-raw stringArray          Read list of source-file names from file without any processing of lines (use - to read from stdin)
  -f, --filter stringArray                  Add a file filtering rule
      --filter-from stringArray             Read file filtering patterns from a file (use - to read from stdin)
      --hash-filter string                  Partition filenames by hash k/n or randomly \[at]/n
      --ignore-case                         Ignore case in filters (case insensitive)
      --include stringArray                 Include files matching pattern
      --include-from stringArray            Read file include patterns from file (use - to read from stdin)
      --max-age Duration                    Only transfer files younger than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --max-depth int                       If set limits the recursion depth to this (default -1)
      --max-size SizeSuffix                 Only transfer files smaller than this in KiB or suffix B|K|M|G|T|P (default off)
      --metadata-exclude stringArray        Exclude metadatas matching pattern
      --metadata-exclude-from stringArray   Read metadata exclude patterns from file (use - to read from stdin)
      --metadata-filter stringArray         Add a metadata filtering rule
      --metadata-filter-from stringArray    Read metadata filtering patterns from a file (use - to read from stdin)
      --metadata-include stringArray        Include metadatas matching pattern
      --metadata-include-from stringArray   Read metadata include patterns from file (use - to read from stdin)
      --min-age Duration                    Only transfer files older than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --min-size SizeSuffix                 Only transfer files bigger than this in KiB or suffix B|K|M|G|T|P (default off)
.SS Listing Options
Flags for listing directories
.IP
.nf
\f[C]
      --default-time Time   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --fast-list           Use recursive list if available; uses more memory but fewer transactions
\f[R]
.fi
.SS See Also
.IP \[bu] 2
rclone (https://rclone.org/commands/rclone/) - Show help for rclone
commands, flags and backends.
.SH rclone tree
List the contents of the remote in a tree like fashion.
.SS Synopsis
Lists the contents of a remote in a similar way to the unix tree
command.
For example
$ rclone tree remote:path
/
 file1
 file2
 file3
 subdir
     file4
     file5

1 directories, 5 files
You can use any of the filtering options with the tree command (e.g.
\f[V]--include\f[R] and \f[V]--exclude\f[R].
You can also use \f[V]--fast-list\f[R].
The tree command has many options for controlling the listing which are
compatible with the tree command, for example you can include file sizes
with \f[V]--size\f[R].
Note that not all of them have short options as they conflict with
rclone\[aq]s short options.
For a more interactive navigation of the remote see the
ncdu (https://rclone.org/commands/rclone_ncdu/) command.
rclone tree remote:path [flags]
  -a, --all             All files are listed (list . files too)
  -d, --dirs-only       List directories only
      --dirsfirst       List directories before files (-U disables)
      --full-path       Print the full path prefix for each file
  -h, --help            help for tree
      --level int       Descend only level directories deep
  -D, --modtime         Print the date of last modification.
      --noindent        Don\[aq]t print indentation lines
      --noreport        Turn off file/directory count at end of tree listing
  -o, --output string   Output to file instead of stdout
  -p, --protections     Print the protections for each file.
  -Q, --quote           Quote filenames with double quotes.
  -s, --size            Print the size in bytes of each file.
      --sort string     Select sort: name,version,size,mtime,ctime
      --sort-ctime      Sort files by last status change time
  -t, --sort-modtime    Sort files by last modification time
  -r, --sort-reverse    Reverse the order of the sort
  -U, --unsorted        Leave files unsorted
      --version         Sort files alphanumerically by version
.SS Listing Options
.PP
Flags for listing directories
.IP
.nf
\f[C]
      --default-time Time   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --fast-list           Use recursive list if available; uses more memory but fewer transactions
\f[R]
.fi
rclone (https://rclone.org/commands/rclone/) - Show help for rclone
commands, flags and backends.
.SS Copying single files
rclone normally syncs or copies directories.
However, if the source remote points to a file, rclone will just copy
that file.
The destination remote must point to a directory - rclone will give the
error
\f[V]Failed to create file system for \[dq]remote:file\[dq]: is a file not a directory\f[R]
if it isn\[aq]t.
For example, suppose you have a remote with a file in called
\f[V]test.jpg\f[R], then you could copy just that file like this
rclone copy remote:test.jpg /tmp/download
The file \f[V]test.jpg\f[R] will be placed inside
\f[V]/tmp/download\f[R].
.PP
This is equivalent to specifying
rclone copy --files-from /tmp/files remote: /tmp/download
Where \f[V]/tmp/files\f[R] contains the single line
test.jpg
.PP
It is recommended to use \f[V]copy\f[R] when copying individual files,
not \f[V]sync\f[R].
They have pretty much the same effect but \f[V]copy\f[R] will use a lot
less memory.
.SS Syntax of remote paths
.PP
The syntax of the paths passed to the rclone command are as follows.
.SS /path/to/dir
.PP
This refers to the local file system.
.PP
On Windows \f[V]\[rs]\f[R] may be used instead of \f[V]/\f[R] in local
paths \f[B]only\f[R], non local paths must use \f[V]/\f[R].
See local filesystem (https://rclone.org/local/#paths-on-windows)
documentation for more about Windows-specific paths.
.PP
These paths needn\[aq]t start with a leading \f[V]/\f[R] - if they
don\[aq]t then they will be relative to the current directory.
.SS remote:path/to/dir
.PP
This refers to a directory \f[V]path/to/dir\f[R] on \f[V]remote:\f[R] as
defined in the config file (configured with \f[V]rclone config\f[R]).
.SS remote:/path/to/dir
.PP
On most backends this is refers to the same directory as
\f[V]remote:path/to/dir\f[R] and that format should be preferred.
On a very small number of remotes (FTP, SFTP, Dropbox for business) this
will refer to a different directory.
On these, paths without a leading \f[V]/\f[R] will refer to your
\[dq]home\[dq] directory and paths with a leading \f[V]/\f[R] will refer
to the root.
.SS :backend:path/to/dir
.PP
This is an advanced form for creating remotes on the fly.
\f[V]backend\f[R] should be the name or prefix of a backend (the
\f[V]type\f[R] in the config file) and all the configuration for the
backend should be provided on the command line (or in environment
variables).
.PP
Here are some examples:
rclone lsd --http-url https://pub.rclone.org :http:
.PP
To list all the directories in the root of
\f[V]https://pub.rclone.org/\f[R].
rclone lsf --http-url https://example.com :http:path/to/dir
To list files and directories in
\f[V]https://example.com/path/to/dir/\f[R]
rclone copy --http-url https://example.com :http:path/to/dir /tmp/dir
To copy files and directories in
\f[V]https://example.com/path/to/dir\f[R] to \f[V]/tmp/dir\f[R].
rclone copy --sftp-host example.com :sftp:path/to/dir /tmp/dir
To copy files and directories from \f[V]example.com\f[R] in the relative
directory \f[V]path/to/dir\f[R] to \f[V]/tmp/dir\f[R] using sftp.
.SS Connection strings
The above examples can also be written using a connection string syntax,
so instead of providing the arguments as command line parameters
\f[V]--http-url https://pub.rclone.org\f[R] they are provided as part of
the remote specification as a kind of connection string.
rclone lsd \[dq]:http,url=\[aq]https://pub.rclone.org\[aq]:\[dq]
rclone lsf \[dq]:http,url=\[aq]https://example.com\[aq]:path/to/dir\[dq]
rclone copy \[dq]:http,url=\[aq]https://example.com\[aq]:path/to/dir\[dq] /tmp/dir
rclone copy :sftp,host=example.com:path/to/dir /tmp/dir
.PP
These can apply to modify existing remotes as well as create new remotes
with the on the fly syntax.
This example is equivalent to adding the
\f[V]--drive-shared-with-me\f[R] parameter to the remote
\f[V]gdrive:\f[R].
rclone lsf \[dq]gdrive,shared_with_me:path/to/dir\[dq]
The major advantage to using the connection string style syntax is that
it only applies to the remote, not to all the remotes of that type of
the command line.
A common confusion is this attempt to copy a file shared on google drive
to the normal drive which \f[B]does not work\f[R] because the
\f[V]--drive-shared-with-me\f[R] flag applies to both the source and the
destination.
rclone copy --drive-shared-with-me gdrive:shared-file.txt gdrive:
.PP
However using the connection string syntax, this does work.
rclone copy \[dq]gdrive,shared_with_me:shared-file.txt\[dq] gdrive:
Note that the connection string only affects the options of the
immediate backend.
If for example gdriveCrypt is a crypt based on gdrive, then the
following command \f[B]will not work\f[R] as intended, because
\f[V]shared_with_me\f[R] is ignored by the crypt backend:
rclone copy \[dq]gdriveCrypt,shared_with_me:shared-file.txt\[dq] gdriveCrypt:
.PP
The connection strings have the following syntax
remote,parameter=value,parameter2=value2:path/to/dir
:backend,parameter=value,parameter2=value2:path/to/dir
If the \f[V]parameter\f[R] has a \f[V]:\f[R] or \f[V],\f[R] then it must
be placed in quotes \f[V]\[dq]\f[R] or \f[V]\[aq]\f[R], so
remote,parameter=\[dq]colon:value\[dq],parameter2=\[dq]comma,value\[dq]:path/to/dir
:backend,parameter=\[aq]colon:value\[aq],parameter2=\[aq]comma,value\[aq]:path/to/dir
.PP
If a quoted value needs to include that quote, then it should be
doubled, so
remote,parameter=\[dq]with\[dq]\[dq]quote\[dq],parameter2=\[aq]with\[aq]\[aq]quote\[aq]:path/to/dir
This will make \f[V]parameter\f[R] be \f[V]with\[dq]quote\f[R] and
\f[V]parameter2\f[R] be \f[V]with\[aq]quote\f[R].
If you leave off the \f[V]=parameter\f[R] then rclone will substitute
\f[V]=true\f[R] which works very well with flags.
For example, to use s3 configured in the environment you could use:
rclone lsd :s3,env_auth:
.PP
Which is equivalent to
rclone lsd :s3,env_auth=true:
Note that on the command line you might need to surround these
connection strings with \f[V]\[dq]\f[R] or \f[V]\[aq]\f[R] to stop the
shell interpreting any special characters within them.
If you are a shell master then you\[aq]ll know which strings are OK and
which aren\[aq]t, but if you aren\[aq]t sure then enclose them in
\f[V]\[dq]\f[R] and use \f[V]\[aq]\f[R] as the inside quote.
This syntax works on all OSes.
rclone copy \[dq]:http,url=\[aq]https://example.com\[aq]:path/to/dir\[dq] /tmp/dir
.PP
On Linux/macOS some characters are still interpreted inside
\f[V]\[dq]\f[R] strings in the shell (notably \f[V]\[rs]\f[R] and
\f[V]$\f[R] and \f[V]\[dq]\f[R]) so if your strings contain those you
can swap the roles of \f[V]\[dq]\f[R] and \f[V]\[aq]\f[R] thus.
(This syntax does not work on Windows.)
rclone copy \[aq]:http,url=\[dq]https://example.com\[dq]:path/to/dir\[aq] /tmp/dir
You can use rclone config
string (https://rclone.org/commands/rclone_config_string/) to convert a
remote into a connection string.
.SS Connection strings, config and logging
If you supply extra configuration to a backend by command line flag,
environment variable or connection string then rclone will add a suffix
based on the hash of the config to the name of the remote, eg
.IP
.nf
\f[C]
rclone -vv lsf --s3-chunk-size 20M s3:
\f[R]
.fi
Has the log message
DEBUG : s3: detected overridden config - adding \[dq]{Srj1p}\[dq] suffix to name
This is so rclone can tell the modified remote apart from the unmodified
remote when caching the backends.
This should only be noticeable in the logs.
.PP
This means that on the fly backends such as
rclone -vv lsf :s3,env_auth:
.PP
Will get their own names
DEBUG : :s3: detected overridden config - adding \[dq]{YTu53}\[dq] suffix to name
.SS Valid remote names
Remote names are case sensitive, and must adhere to the following rules:
May contain number, letter, \f[V]_\f[R], \f[V]-\f[R], \f[V].\f[R],
\f[V]+\f[R], \f[V]\[at]\f[R] and space.
.IP \[bu] 2
May not start with \f[V]-\f[R] or space.
.IP \[bu] 2
May not end with space.
Starting with rclone version 1.61, any Unicode numbers and letters are
allowed, while in older versions it was limited to plain ASCII (0-9,
A-Z, a-z).
If you use the same rclone configuration from different shells, which
may be configured with different character encoding, you must be
cautious to use characters that are possible to write in all of them.
This is mostly a problem on Windows, where the console traditionally
uses a non-Unicode character set - defined by the so-called \[dq]code
page\[dq].
Do not use single character names on Windows as it creates ambiguity
with Windows drives\[aq] names, e.g.: remote called \f[V]C\f[R] is
indistinguishable from \f[V]C\f[R] drive.
Rclone will always assume that single letter name refers to a drive.
.SS Adding global configuration to a remote
It is possible to add global configuration to the remote configuration
which will be applied just before the remote is created.
This can be done in two ways.
The first is to use \f[V]override.var = value\f[R] in the config file or
the connection string for a temporary change, and the second is to use
\f[V]global.var = value\f[R] in the config file or connection string for
a permanent change.
This is explained fully below.
.SS override.var
This is used to override a global variable \f[B]just\f[R] for the
duration of the remote creation.
It won\[aq]t affect other remotes even if they are created at the same
time.
.PP
This is very useful for overriding networking config needed for just for
that remote.
For example, say you have a remote which needs
\f[V]--no-check-certificate\f[R] as it is running on test infrastructure
without a proper certificate.
You could supply the \f[V]--no-check-certificate\f[R] flag to rclone,
but this will affect \f[B]all\f[R] the remotes.
To make it just affect this remote you use an override.
You could put this in the config file:
[remote]
type = XXX
\&...
override.no_check_certificate = true
.PP
or use it in the connection string
\f[V]remote,override.no_check_certificate=true:\f[R] (or just
\f[V]remote,override.no_check_certificate:\f[R]).
.PP
Note how the global flag name loses its initial \f[V]--\f[R] and gets
\f[V]-\f[R] replaced with \f[V]_\f[R] and gets an \f[V]override.\f[R]
prefix.
.PP
Not all global variables make sense to be overridden like this as the
config is only applied during the remote creation.
Here is a non exhaustive list of ones which might be useful:
.IP \[bu] 2
\f[V]bind_addr\f[R]
.IP \[bu] 2
\f[V]ca_cert\f[R]
.IP \[bu] 2
\f[V]client_cert\f[R]
.IP \[bu] 2
\f[V]client_key\f[R]
.IP \[bu] 2
\f[V]connect_timeout\f[R]
.IP \[bu] 2
\f[V]disable_http2\f[R]
.IP \[bu] 2
\f[V]disable_http_keep_alives\f[R]
.IP \[bu] 2
\f[V]dump\f[R]
.IP \[bu] 2
\f[V]expect_continue_timeout\f[R]
.IP \[bu] 2
\f[V]headers\f[R]
.IP \[bu] 2
\f[V]http_proxy\f[R]
.IP \[bu] 2
\f[V]low_level_retries\f[R]
.IP \[bu] 2
\f[V]max_connections\f[R]
.IP \[bu] 2
\f[V]no_check_certificate\f[R]
.IP \[bu] 2
\f[V]no_gzip\f[R]
.IP \[bu] 2
\f[V]timeout\f[R]
.IP \[bu] 2
\f[V]traffic_class\f[R]
.IP \[bu] 2
\f[V]use_cookies\f[R]
.IP \[bu] 2
\f[V]use_server_modtime\f[R]
.IP \[bu] 2
\f[V]user_agent\f[R]
.PP
An \f[V]override.var\f[R] will override all other config methods, but
\f[B]just\f[R] for the duration of the creation of the remote.
.SS global.var
.PP
This is used to set a global variable \f[B]for everything\f[R].
The global variable is set just before the remote is created.
.PP
This is useful for parameters (eg sync parameters) which can\[aq]t be
set as an \f[V]override\f[R].
For example, say you have a remote where you would always like to use
the \f[V]--checksum\f[R] flag.
You could supply the \f[V]--checksum\f[R] flag to rclone on every
command line, but instead you could put this in the config file:
[remote]
type = XXX
\&...
global.checksum = true
or use it in the connection string
\f[V]remote,global.checksum=true:\f[R] (or just
\f[V]remote,global.checksum:\f[R]).
This is equivalent to using the \f[V]--checksum\f[R] flag.
Note how the global flag name loses its initial \f[V]--\f[R] and gets
\f[V]-\f[R] replaced with \f[V]_\f[R] and gets a \f[V]global.\f[R]
prefix.
.PP
Any global variable can be set like this and it is exactly equivalent to
using the equivalent flag on the command line.
This means it will affect all uses of rclone.
.PP
If two remotes set the same global variable then the first one
instantiated will be overridden by the second one.
A \f[V]global.var\f[R] will override all other config methods when the
remote is created.
.SS Quoting and the shell
.PP
When you are typing commands to your computer you are using something
called the command line shell.
This interprets various characters in an OS specific way.
.PP
Here are some gotchas which may help users unfamiliar with the shell
rules
.SS Linux / macOS
.PP
If your names have spaces or shell metacharacters (e.g.
\f[V]*\f[R], \f[V]?\f[R], \f[V]$\f[R], \f[V]\[aq]\f[R], \f[V]\[dq]\f[R],
etc.)
then you must quote them.
Use single quotes \f[V]\[aq]\f[R] by default.
rclone copy \[aq]Important files?\[aq] remote:backup
If you want to send a \f[V]\[aq]\f[R] you will need to use
\f[V]\[dq]\f[R], e.g.
rclone copy \[dq]O\[aq]Reilly Reviews\[dq] remote:backup
The rules for quoting metacharacters are complicated and if you want the
full details you\[aq]ll have to consult the manual page for your shell.
.SS Windows
.PP
If your names have spaces in you need to put them in \f[V]\[dq]\f[R],
e.g.
rclone copy \[dq]E:\[rs]folder name\[rs]folder name\[rs]folder name\[dq] remote:backup
If you are using the root directory on its own then don\[aq]t quote it
(see #464 (https://github.com/rclone/rclone/issues/464) for why), e.g.
rclone copy E:\[rs] remote:backup
.SS Copying files or directories with \f[V]:\f[R] in the names
rclone uses \f[V]:\f[R] to mark a remote name.
This is, however, a valid filename component in non-Windows OSes.
The remote name parser will only search for a \f[V]:\f[R] up to the
first \f[V]/\f[R] so if you need to act on a file or directory like this
then use the full path starting with a \f[V]/\f[R], or use \f[V]./\f[R]
as a current directory prefix.
So to sync a directory called \f[V]sync:me\f[R] to a remote called
\f[V]remote:\f[R] use
rclone sync --interactive ./sync:me remote:path
.PP
or
rclone sync --interactive /full/path/to/sync:me remote:path
.SS Server-side copy
Most remotes (but not all - see the
overview (https://rclone.org/overview/#optional-features)) support
server-side copy.
This means if you want to copy one folder to another then rclone
won\[aq]t download all the files and re-upload them; it will instruct
the server to copy them in place.
.PP
Eg
rclone copy s3:oldbucket s3:newbucket
Will copy the contents of \f[V]oldbucket\f[R] to \f[V]newbucket\f[R]
without downloading and re-uploading.
.PP
Remotes which don\[aq]t support server-side copy \f[B]will\f[R] download
and re-upload in this case.
.PP
Server-side copies are used with \f[V]sync\f[R] and \f[V]copy\f[R] and
will be identified in the log when using the \f[V]-v\f[R] flag.
The \f[V]move\f[R] command may also use them if remote doesn\[aq]t
support server-side move directly.
This is done by issuing a server-side copy then a delete which is much
quicker than a download and re-upload.
.PP
Server-side copies will only be attempted if the remote names are the
same.
.PP
This can be used when scripting to make aged backups efficiently, e.g.
rclone sync --interactive remote:current-backup remote:previous-backup
rclone sync --interactive /path/to/files remote:current-backup
.SS Metadata support
.PP
Metadata is data about a file (or directory) which isn\[aq]t the
contents of the file (or directory).
Normally rclone only preserves the modification time and the content
(MIME) type where possible.
.PP
Rclone supports preserving all the available metadata on files and
directories when using the \f[V]--metadata\f[R] or \f[V]-M\f[R] flag.
.PP
Exactly what metadata is supported and what that support means depends
on the backend.
Backends that support metadata have a metadata section in their docs and
are listed in the features table (https://rclone.org/overview/#features)
(Eg local (https://rclone.org/local/#metadata), s3)
.PP
Some backends don\[aq]t support metadata, some only support metadata on
files and some support metadata on both files and directories.
.PP
Rclone only supports a one-time sync of metadata.
This means that metadata will be synced from the source object to the
destination object only when the source object has changed and needs to
be re-uploaded.
If the metadata subsequently changes on the source object without
changing the object itself then it won\[aq]t be synced to the
destination object.
This is in line with the way rclone syncs \f[V]Content-Type\f[R] without
the \f[V]--metadata\f[R] flag.
.PP
Using \f[V]--metadata\f[R] when syncing from local to local will
preserve file attributes such as file mode, owner, extended attributes
(not Windows).
.PP
Note that arbitrary metadata may be added to objects using the
\f[V]--metadata-set key=value\f[R] flag when the object is first
uploaded.
This flag can be repeated as many times as necessary.
.PP
The --metadata-mapper flag can be used to pass the name of a program in
which can transform metadata when it is being copied from source to
destination.
.PP
Rclone supports \f[V]--metadata-set\f[R] and \f[V]--metadata-mapper\f[R]
when doing server-side \f[V]Move\f[R] and server-side \f[V]Copy\f[R],
but not when doing server side \f[V]DirMove\f[R] (renaming a directory)
as this would involve recursing into the directory.
Note that you can disable \f[V]DirMove\f[R] with
\f[V]--disable DirMove\f[R] and rclone will revert back to using
\f[V]Move\f[R] for each individual object where \f[V]--metadata-set\f[R]
and \f[V]--metadata-mapper\f[R] are supported.
.SS Types of metadata
.PP
Metadata is divided into two type.
System metadata and User metadata.
.PP
Metadata which the backend uses itself is called system metadata.
For example on the local backend the system metadata \f[V]uid\f[R] will
store the user ID of the file when used on a unix based platform.
.PP
Arbitrary metadata is called user metadata and this can be set however
is desired.
.PP
When objects are copied from backend to backend, they will attempt to
interpret system metadata if it is supplied.
Metadata may change from being user metadata to system metadata as
objects are copied between different backends.
For example copying an object from s3 sets the \f[V]content-type\f[R]
metadata.
In a backend which understands this (like \f[V]azureblob\f[R]) this will
become the Content-Type of the object.
In a backend which doesn\[aq]t understand this (like the \f[V]local\f[R]
backend) this will become user metadata.
However should the local object be copied back to s3, the Content-Type
will be set correctly.
.SS Metadata framework
.PP
Rclone implements a metadata framework which can read metadata from an
object and write it to the object when (and only when) it is being
uploaded.
.PP
This metadata is stored as a dictionary with string keys and string
values.
.PP
There are some limits on the names of the keys (these may be clarified
further in the future).
must be lower case
.IP \[bu] 2
may be \f[V]a-z\f[R] \f[V]0-9\f[R] containing \f[V].\f[R] \f[V]-\f[R] or
\f[V]_\f[R]
.IP \[bu] 2
length is backend dependent
Each backend can provide system metadata that it understands.
Some backends can also store arbitrary user metadata.
Where possible the key names are standardized, so, for example, it is
possible to copy object metadata from s3 to azureblob for example and
metadata will be translated appropriately.
Some backends have limits on the size of the metadata and rclone will
give errors on upload if they are exceeded.
.SS Metadata preservation
The goal of the implementation is to
.IP "1." 3
Preserve metadata if at all possible
.IP "2." 3
Interpret metadata if at all possible
The consequences of 1 is that you can copy an S3 object to a local disk
then back to S3 losslessly.
Likewise you can copy a local file with file attributes and xattrs from
local disk to s3 and back again losslessly.
The consequence of 2 is that you can copy an S3 object with metadata to
Azureblob (say) and have the metadata appear on the Azureblob object
also.
.SS Standard system metadata
Here is a table of standard system metadata which, if appropriate, a
backend may implement.
.TS
tab(@);
lw(34.2n) lw(21.2n) lw(14.7n).
T{
key
T}@T{
description
T}@T{
example
T}
_
T{
mode
T}@T{
File type and mode: octal, unix style
T}@T{
0100664
T}
T{
uid
T}@T{
User ID of owner: decimal number
T}@T{
500
T}
T{
gid
T}@T{
Group ID of owner: decimal number
T}@T{
500
T}
T{
rdev
T}@T{
Device ID (if special file) => hexadecimal
T}@T{
0
T}
T{
atime
T}@T{
Time of last access: RFC 3339
T}@T{
2006-01-02T15:04:05.999999999Z07:00
T}
T{
mtime
T}@T{
Time of last modification: RFC 3339
T}@T{
2006-01-02T15:04:05.999999999Z07:00
T}
T{
btime
T}@T{
Time of file creation (birth): RFC 3339
T}@T{
2006-01-02T15:04:05.999999999Z07:00
T}
T{
utime
T}@T{
Time of file upload: RFC 3339
T}@T{
2006-01-02T15:04:05.999999999Z07:00
T}
T{
cache-control
T}@T{
Cache-Control header
T}@T{
no-cache
T}
T{
content-disposition
T}@T{
Content-Disposition header
T}@T{
inline
T}
T{
content-encoding
T}@T{
Content-Encoding header
T}@T{
gzip
T}
T{
content-language
T}@T{
Content-Language header
T}@T{
en-US
T}
T{
content-type
T}@T{
Content-Type header
T}@T{
text/plain
T}
.TE
The metadata keys \f[V]mtime\f[R] and \f[V]content-type\f[R] will take
precedence if supplied in the metadata over reading the
\f[V]Content-Type\f[R] or modification time of the source object.
Hashes are not included in system metadata as there is a well defined
way of reading those already.
.SS Options
Rclone has a number of options to control its behaviour.
These are documented below, and in the flags page.
Options that take parameters can have the values passed in two ways,
\f[V]--option=value\f[R] or \f[V]--option value\f[R].
However boolean (true/false) options behave slightly differently to the
other options in that \f[V]--boolean\f[R] sets the option to
\f[V]true\f[R] and the absence of the flag sets it to \f[V]false\f[R].
It is also possible to specify \f[V]--boolean=false\f[R] or
\f[V]--boolean=true\f[R].
Note that \f[V]--boolean false\f[R] is not valid - this is parsed as
\f[V]--boolean\f[R] and the \f[V]false\f[R] is parsed as an extra
command line argument for rclone.
String values that are recognized as special identifiers, e.g.
the name of the log level to set with option \f[V]--log-level\f[R], are
case insensitive, e.g.
\f[V]--log-level ERROR\f[R] and \f[V]--log-level error\f[R] are
identical.
Options documented to take a \f[V]stringArray\f[R] parameter accept
multiple values.
To pass more than one value, repeat the option; for example:
\f[V]--include value1 --include value2\f[R].
Other options may only accept a single value, and should only be
specified once, but where the specified parameter may indicate a list of
values separated by space or comma.
Such options are documented to take a \f[V]CommaSepList\f[R] parameter,
if comma separated, and \f[V]SpaceSepList\f[R] if space separated,
although some may also have different parameters such as
\f[V]DumpFlags\f[R] or just \f[V]string\f[R] and the help text explains
that this will be interpreted as a list.
.PP
Floating-point values with fractional part must use period (\f[V].\f[R])
as decimal separator, common in English-speaking countries, regardless
of your configured system locale.
Parameter type \f[V]float\f[R] accepts decimal and hexadecimal
floating-point numbers as defined by the Go syntax for floating-point
literals (https://go.dev/ref/spec#Floating-point_literals).
.SS Time and duration options
.PP
Options that take a \f[V]Time\f[R] or \f[V]Duration\f[R] parameter must
be specified as a formatted string describing an absolute or relative
time.
Note that both \f[V]Time\f[R] and \f[V]Duration\f[R] parameter types can
be expressed as either absolute or relative time, just with different
interpretations, e.g.
a relative time will be treated as an offset from the current time when
passed as a \f[V]Time\f[R] value.
.PP
An absolute time can be specified as a string in one of the following
formats:
.IP \[bu] 2
RFC3339 - e.g.
\f[V]2006-01-02T15:04:05Z\f[R] or \f[V]2006-01-02T15:04:05+07:00\f[R]
.IP \[bu] 2
ISO8601 Date and time, local timezone - \f[V]2006-01-02T15:04:05\f[R]
.IP \[bu] 2
ISO8601 Date and time, local timezone - \f[V]2006-01-02 15:04:05\f[R]
.IP \[bu] 2
ISO8601 Date - \f[V]2006-01-02\f[R] (YYYY-MM-DD)
.PP
A relative time is a string with a, possibly signed, sequence of decimal
numbers, each with optional fraction, and each with a unit suffix.
If the string only contains a single number, then the unit suffix is
optional and will default to seconds, i.e.
a plain decimal value will be treated as a number of seconds.
The following suffixes are valid:
.IP \[bu] 2
\f[V]ms\f[R] - Milliseconds
.IP \[bu] 2
\f[V]s\f[R] - Seconds
.IP \[bu] 2
\f[V]m\f[R] - Minutes
.IP \[bu] 2
\f[V]h\f[R] - Hours
.IP \[bu] 2
\f[V]d\f[R] - Days
.IP \[bu] 2
\f[V]w\f[R] - Weeks
.IP \[bu] 2
\f[V]M\f[R] - Months
.IP \[bu] 2
\f[V]y\f[R] - Years
.PP
Examples: \[dq]10\[dq], \[dq]300ms\[dq], \[dq]-1.5h\[dq] or
\[dq]2h45m\[dq].
.SS Size options
.PP
Options that take a SizeSuffix parameter can be specified as an integer
value, which will then be assumed to represent a KiB value (multiples of
1024 bytes) by default.
The interpretation can be changed by appending a suffix: \f[V]B\f[R] for
Byte, \f[V]K\f[R] for KiB, \f[V]M\f[R] for MiB, \f[V]G\f[R] for GiB,
\f[V]T\f[R] for TiB and \f[V]P\f[R] for PiB.
These are the binary units, e.g.
1, 2**10, 2**20, 2**30 respectively.
.PP
See also --human-readable.
.SS Main options
.SS --backup-dir string
.PP
When using sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/), any files which would
have been overwritten or deleted are moved in their original hierarchy
into this directory.
.PP
If \f[V]--suffix\f[R] is set, then the moved files will have the suffix
added to them.
If there is a file with the same path (after the suffix has been added)
in the directory, then it will be overwritten.
.PP
The remote in use must support server-side move or copy and you must use
the same remote as the destination of the sync.
The backup directory must not overlap the destination directory without
it being excluded by a filter rule.
.PP
For example
rclone sync --interactive /path/to/local remote:current --backup-dir remote:old
will sync \f[V]/path/to/local\f[R] to \f[V]remote:current\f[R], but for
any files which would have been updated or deleted will be stored in
\f[V]remote:old\f[R].
.PP
If running rclone from a script you might want to use today\[aq]s date
as the directory name passed to \f[V]--backup-dir\f[R] to store the old
files, or you might want to pass \f[V]--suffix\f[R] with today\[aq]s
date.
This can be done with \f[V]--suffix $(date +%F)\f[R] in bash, and
\f[V]--suffix $(Get-Date -Format \[aq]yyyy-MM-dd\[aq])\f[R] in
PowerShell.
.PP
See \f[V]--compare-dest\f[R] and \f[V]--copy-dest\f[R].
.SS --bind string
.PP
Local address to bind to for outgoing connections.
This can be an IPv4 address (1.2.3.4), an IPv6 address (1234::789A) or
host name.
If the host name doesn\[aq]t resolve or resolves to more than one IP
address it will give an error.
.PP
You can use \f[V]--bind 0.0.0.0\f[R] to force rclone to use IPv4
addresses and \f[V]--bind ::0\f[R] to force rclone to use IPv6
addresses.
.SS --bwlimit BwTimetable
.PP
This option controls the bandwidth limit.
For example
--bwlimit 10M
would mean limit the upload and download bandwidth to 10 MiB/s.
\f[B]NB\f[R] this is \f[B]bytes\f[R] per second not \f[B]bits\f[R] per
second.
To use a single limit, specify the desired bandwidth in KiB/s, or use a
suffix B|K|M|G|T|P.
The default is \f[V]0\f[R] which means to not limit bandwidth.
.PP
The upload and download bandwidth can be specified separately, as
\f[V]--bwlimit UP:DOWN\f[R], so
--bwlimit 10M:100k
would mean limit the upload bandwidth to 10 MiB/s and the download
bandwidth to 100 KiB/s.
Either limit can be \[dq]off\[dq] meaning no limit, so to just limit the
upload bandwidth you would use
--bwlimit 10M:off
this would limit the upload bandwidth to 10 MiB/s but the download
bandwidth would be unlimited.
When specified as above the bandwidth limits last for the duration of
run of the rclone binary.
It is also possible to specify a \[dq]timetable\[dq] of limits, which
will cause certain limits to be applied at certain times.
To specify a timetable, format your entries as
\f[V]WEEKDAY-HH:MM,BANDWIDTH WEEKDAY-HH:MM,BANDWIDTH...\f[R] where:
\f[V]WEEKDAY\f[R] is optional element.
.IP \[bu] 2
\f[V]BANDWIDTH\f[R] can be a single number, e.g.\f[V]100k\f[R] or a pair
of numbers for upload:download, e.g.\f[V]10M:1M\f[R].
.IP \[bu] 2
\f[V]WEEKDAY\f[R] can be written as the whole word or only using the
first 3 characters.
It is optional.
.IP \[bu] 2
\f[V]HH:MM\f[R] is an hour from 00:00 to 23:59.
Entries can be separated by spaces or semicolons.
\f[B]Note:\f[R] Semicolons can be used as separators instead of spaces
to avoid parsing issues in containerized environments.
An example of a typical timetable to avoid link saturation during
daytime working hours could be:
Using spaces as separators:
\f[V]--bwlimit \[dq]08:00,512k 12:00,10M 13:00,512k 18:00,30M 23:00,off\[dq]\f[R]
Using semicolons as separators:
\f[V]--bwlimit \[dq]08:00,512k;12:00,10M;13:00,512k;18:00,30M;23:00,off\[dq]\f[R]
In these examples, the transfer bandwidth will be set to 512 KiB/s at
8am every day.
At noon, it will rise to 10 MiB/s, and drop back to 512 KiB/sec at 1pm.
At 6pm, the bandwidth limit will be set to 30 MiB/s, and at 11pm it will
be completely disabled (full speed).
Anything between 11pm and 8am will remain unlimited.
An example of timetable with \f[V]WEEKDAY\f[R] could be:
Using spaces as separators:
\f[V]--bwlimit \[dq]Mon-00:00,512 Fri-23:59,10M Sat-10:00,1M Sun-20:00,off\[dq]\f[R]
Using semicolons as separators:
\f[V]--bwlimit \[dq]Mon-00:00,512;Fri-23:59,10M;Sat-10:00,1M;Sun-20:00,off\[dq]\f[R]
It means that, the transfer bandwidth will be set to 512 KiB/s on
Monday.
It will rise to 10 MiB/s before the end of Friday.
At 10:00 on Saturday it will be set to 1 MiB/s.
From 20:00 on Sunday it will be unlimited.
Timeslots without \f[V]WEEKDAY\f[R] are extended to the whole week.
So this example:
--bwlimit \[dq]Mon-00:00,512 12:00,1M Sun-20:00,off\[dq]
Is equivalent to this:
--bwlimit \[dq]Mon-00:00,512Mon-12:00,1M Tue-12:00,1M Wed-12:00,1M Thu-12:00,1M Fri-12:00,1M Sat-12:00,1M Sun-12:00,1M Sun-20:00,off\[dq]
Bandwidth limit apply to the data transfer for all backends.
For most backends the directory listing bandwidth is also included
(exceptions being the non HTTP backends, \f[V]ftp\f[R], \f[V]sftp\f[R]
and \f[V]storj\f[R]).
Note that the units are \f[B]Byte/s\f[R], not \f[B]bit/s\f[R].
Typically connections are measured in bit/s - to convert divide by 8.
For example, let\[aq]s say you have a 10 Mbit/s connection and you wish
rclone to use half of it - 5 Mbit/s.
This is 5/8 = 0.625 MiB/s so you would use a \f[V]--bwlimit 0.625M\f[R]
parameter for rclone.
On Unix systems (Linux, macOS, \&...)
the bandwidth limiter can be toggled by sending a \f[V]SIGUSR2\f[R]
signal to rclone.
This allows to remove the limitations of a long running rclone transfer
and to restore it back to the value specified with \f[V]--bwlimit\f[R]
quickly when needed.
Assuming there is only one rclone instance running, you can toggle the
limiter like this:
kill -SIGUSR2 $(pidof rclone)
If you configure rclone with a remote control then you can use change
the bwlimit dynamically:
rclone rc core/bwlimit rate=1M
.SS --bwlimit-file BwTimetable
This option controls per file bandwidth limit.
For the options see the \f[V]--bwlimit\f[R] flag.
.PP
For example use this to allow no transfers to be faster than 1 MiB/s
--bwlimit-file 1M
This can be used in conjunction with \f[V]--bwlimit\f[R].
Note that if a schedule is provided the file will use the schedule in
effect at the start of the transfer.
.SS --buffer-size SizeSuffix
Use this sized buffer to speed up file transfers.
Each \f[V]--transfer\f[R] will use this much memory for buffering.
When using \f[V]mount\f[R] or \f[V]cmount\f[R] each open file descriptor
will use this much memory for buffering.
See the mount (https://rclone.org/commands/rclone_mount/#file-buffering)
documentation for more details.
Set to \f[V]0\f[R] to disable the buffering for the minimum memory
usage.
Note that the memory allocation of the buffers is influenced by the
--use-mmap flag.
.SS --cache-dir string
Specify the directory rclone will use for caching, to override the
default.
Default value is depending on operating system:
Windows \f[V]%LocalAppData%\[rs]rclone\f[R], if \f[V]LocalAppData\f[R]
is defined.
macOS \f[V]$HOME/Library/Caches/rclone\f[R] if \f[V]HOME\f[R] is
defined.
Unix \f[V]$XDG_CACHE_HOME/rclone\f[R] if \f[V]XDG_CACHE_HOME\f[R] is
defined, else \f[V]$HOME/.cache/rclone\f[R] if \f[V]HOME\f[R] is
defined.
Fallback (on all OS) to \f[V]$TMPDIR/rclone\f[R], where \f[V]TMPDIR\f[R]
is the value from --temp-dir.
You can use the config
paths (https://rclone.org/commands/rclone_config_paths/) command to see
the current value.
Cache directory is heavily used by the VFS File
Caching (https://rclone.org/commands/rclone_mount/#vfs-file-caching)
mount feature, but also by
serve (https://rclone.org/commands/rclone_serve/), GUI and other parts
of rclone.
.SS --check-first
If this flag is set then in a
sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/), rclone will do all the
checks to see whether files need to be transferred before doing any of
the transfers.
Normally rclone would start running transfers as soon as possible.
This flag can be useful on IO limited systems where transfers interfere
with checking.
It can also be useful to ensure perfect ordering when using
\f[V]--order-by\f[R].
If both \f[V]--check-first\f[R] and \f[V]--order-by\f[R] are set when
doing \f[V]rclone move\f[R] then rclone will use the transfer thread to
delete source files which don\[aq]t need transferring.
This will enable perfect ordering of the transfers and deletes but will
cause the transfer stats to have more items in than expected.
Using this flag can use more memory as it effectively sets
\f[V]--max-backlog\f[R] to infinite.
This means that all the info on the objects to transfer is held in
memory before the transfers start.
.SS --checkers int
Originally controlling just the number of file checkers to run in
parallel, e.g.
by \f[V]rclone copy\f[R].
Now a fairly universal parallelism control used by \f[V]rclone\f[R] in
several places.
Note: checkers do the equality checking of files during a sync.
For some storage systems (e.g.
S3, Swift, Dropbox) this can take a significant amount of time so they
are run in parallel.
The default is to run 8 checkers in parallel.
However, in case of slow-reacting backends you may need to lower (rather
than increase) this default by setting \f[V]--checkers\f[R] to 4 or less
threads.
This is especially advised if you are experiencing backend server
crashes during file checking phase (e.g.
on subsequent or top-up backups where little or no file copying is done
and checking takes up most of the time).
Increase this setting only with utmost care, while monitoring your
server health and file checking throughput.
.SS -c, --checksum
Normally rclone will look at modification time and size of files to see
if they are equal.
If you set this flag then rclone will check the file hash and size to
determine if files are equal.
This is useful when the remote doesn\[aq]t support setting modified time
and a more accurate sync is desired than just checking the file size.
This is very useful when transferring between remotes which store the
same hash type on the object, e.g.
Drive and Swift.
For details of which remotes support which hash type see the table in
the overview section (https://rclone.org/overview/).
Eg \f[V]rclone --checksum sync s3:/bucket swift:/bucket\f[R] would run
much quicker than without the \f[V]--checksum\f[R] flag.
When using this flag, rclone won\[aq]t update mtimes of remote files if
they are incorrect as it would normally.
.SS --color AUTO|NEVER|ALWAYS
Specify when colors (and other ANSI codes) should be added to the
output.
\f[V]AUTO\f[R] only allows ANSI codes when the output is a terminal.
This is the default.
\f[V]NEVER\f[R] never allow ANSI codes.
\f[V]ALWAYS\f[R] always add ANSI codes, regardless of the output format
(terminal or file).
.SS --compare-dest stringArray
When using sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/), the specified paths are
checked in addition to the destination for files.
If a file identical to the source is found, that file is \f[B]not\f[R]
copied from source.
This is useful to copy just files that have changed since the last
backup.
.PP
You must use the same remote as the destination of the sync.
The compare directory must not overlap the destination directory.
.PP
See \f[V]--copy-dest\f[R] and \f[V]--backup-dir\f[R].
.SS --config string
.PP
Specify the location of the rclone configuration file, to override the
default.
E.g.
\f[V]rclone config --config=\[dq]rclone.conf\[dq]\f[R].
.PP
The exact default is a bit complex to describe, due to changes
introduced through different versions of rclone while preserving
backwards compatibility, but in most cases it is as simple as:
.IP \[bu] 2
\f[V]%APPDATA%/rclone/rclone.conf\f[R] on Windows
.IP \[bu] 2
\f[V]\[ti]/.config/rclone/rclone.conf\f[R] on other
.PP
The complete logic is as follows: Rclone will look for an existing
configuration file in any of the following locations, in priority order:
.IP "1." 3
\f[V]rclone.conf\f[R] (in program directory, where rclone executable is)
.IP "2." 3
\f[V]%APPDATA%/rclone/rclone.conf\f[R] (only on Windows)
.IP "3." 3
\f[V]$XDG_CONFIG_HOME/rclone/rclone.conf\f[R] (on all systems, including
Windows)
.IP "4." 3
\f[V]\[ti]/.config/rclone/rclone.conf\f[R] (see below for explanation of
\[ti] symbol)
.IP "5." 3
\f[V]\[ti]/.rclone.conf\f[R]
.PP
If no existing configuration file is found, then a new one will be
created in the following location:
.IP \[bu] 2
On Windows: Location 2 listed above, except in the unlikely event that
\f[V]APPDATA\f[R] is not defined, then location 4 is used instead.
.IP \[bu] 2
On Unix: Location 3 if \f[V]XDG_CONFIG_HOME\f[R] is defined, else
location 4.
.IP \[bu] 2
Fallback to location 5 (on all OS), when the rclone directory cannot be
created, but if also a home directory was not found then path
\f[V].rclone.conf\f[R] relative to current working directory will be
used as a final resort.
.PP
The \f[V]\[ti]\f[R] symbol in paths above represent the home directory
of the current user on any OS, and the value is defined as following:
.IP \[bu] 2
On Windows: \f[V]%HOME%\f[R] if defined, else \f[V]%USERPROFILE%\f[R],
or else \f[V]%HOMEDRIVE%\[rs]%HOMEPATH%\f[R].
.IP \[bu] 2
On Unix: \f[V]$HOME\f[R] if defined, else by looking up current user in
OS-specific user database (e.g.
passwd file), or else use the result from shell command
\f[V]cd && pwd\f[R].
.PP
If you run \f[V]rclone config file\f[R] you will see where the default
location is for you.
Running \f[V]rclone config touch\f[R] will ensure a configuration file
exists, creating an empty one in the default location if there is none.
.PP
The fact that an existing file \f[V]rclone.conf\f[R] in the same
directory as the rclone executable is always preferred, means that it is
easy to run in \[dq]portable\[dq] mode by downloading rclone executable
to a writable directory and then create an empty file
\f[V]rclone.conf\f[R] in the same directory.
.PP
If the location is set to empty string \f[V]\[dq]\[dq]\f[R] or path to a
file with name \f[V]notfound\f[R], or the os null device represented by
value \f[V]NUL\f[R] on Windows and \f[V]/dev/null\f[R] on Unix systems,
then rclone will keep the configuration file in memory only.
.PP
You may see a log message \[dq]Config file not found - using
defaults\[dq] if there is no configuration file.
This can be supressed, e.g.
if you are using rclone entirely with on the fly
remotes (https://rclone.org/docs/#backend-path-to-dir), by using
memory-only configuration file or by creating an empty configuration
file, as described above.
.PP
The file format is basic
INI (https://en.wikipedia.org/wiki/INI_file#Format): Sections of text,
led by a \f[V][section]\f[R] header and followed by \f[V]key=value\f[R]
entries on separate lines.
In rclone each remote is represented by its own section, where the
section name defines the name of the remote.
Options are specified as the \f[V]key=value\f[R] entries, where the key
is the option name without the \f[V]--backend-\f[R] prefix, in lowercase
and with \f[V]_\f[R] instead of \f[V]-\f[R].
E.g.
option \f[V]--mega-hard-delete\f[R] corresponds to key
\f[V]hard_delete\f[R].
Only backend options can be specified.
A special, and required, key \f[V]type\f[R] identifies the storage
system (https://rclone.org/overview/), where the value is the internal
lowercase name as returned by command \f[V]rclone help backends\f[R].
Comments are indicated by \f[V];\f[R] or \f[V]#\f[R] at the beginning of
a line.
.PP
Example:
[megaremote]
type = mega
user = you\[at]example.com
pass = PDPcQVVjVtzFY-GTdDFozqBhTdsPg3qH
Note that passwords are in
obscured (https://rclone.org/commands/rclone_obscure/) form.
Also, many storage systems uses token-based authentication instead of
passwords, and this requires additional steps.
It is easier, and safer, to use the interactive command
\f[V]rclone config\f[R] instead of manually editing the configuration
file.
The configuration file will typically contain login information, and
should therefore have restricted permissions so that only the current
user can read it.
Rclone tries to ensure this when it writes the file.
You may also choose to encrypt the file.
When token-based authentication are used, the configuration file must be
writable, because rclone needs to update the tokens inside it.
To reduce risk of corrupting an existing configuration file, rclone will
not write directly to it when saving changes.
Instead it will first write to a new, temporary, file.
If a configuration file already existed, it will (on Unix systems) try
to mirror its permissions to the new file.
Then it will rename the existing file to a temporary name as backup.
Next, rclone will rename the new file to the correct name, before
finally cleaning up by deleting the backup file.
If the configuration file path used by rclone is a symbolic link, then
this will be evaluated and rclone will write to the resolved path,
instead of overwriting the symbolic link.
Temporary files used in the process (described above) will be written to
the same parent directory as that of the resolved configuration file,
but if this directory is also a symbolic link it will not be resolved
and the temporary files will be written to the location of the directory
symbolic link.
.SS --contimeout Duration
.PP
Set the connection timeout.
This should be in go time format which looks like \f[V]5s\f[R] for 5
seconds, \f[V]10m\f[R] for 10 minutes, or \f[V]3h30m\f[R].
.PP
The connection timeout is the amount of time rclone will wait for a
connection to go through to a remote object storage system.
It is \f[V]1m\f[R] by default.
.SS --copy-dest stringArray
.PP
When using sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/), the specified paths are
checked in addition to the destination for files.
This part is the same as \f[V]--compare-dest\f[R], but the difference is
that with \f[V]--copy-dest\f[R], if a file identical to the source is
found, that file is server-side copied from the specified paths to the
destination.
This is useful for incremental backup.
.PP
The remote in use must support server-side copy and you must use the
same remote as the destination of the sync.
The compare directory must not overlap the destination directory.
.PP
See \f[V]--compare-dest\f[R] and \f[V]--backup-dir\f[R].
.SS --dedupe-mode interactive|skip|first|newest|oldest|largest|smallest|rename|list
.PP
Mode to run dedupe command in.
One of \f[V]interactive\f[R], \f[V]skip\f[R], \f[V]first\f[R],
\f[V]newest\f[R], \f[V]oldest\f[R], \f[V]largest\f[R],
\f[V]smallest\f[R], \f[V]rename\f[R] \f[V]list\f[R].
The default is \f[V]interactive\f[R].
See the dedupe (https://rclone.org/commands/rclone_dedupe/) command for
more information as to what these options mean.
.SS --default-time Time
.PP
If a file or directory does have a modification time rclone can read
then rclone will display this fixed time instead.
.PP
The default is \f[V]2000-01-01 00:00:00 UTC\f[R].
This can be configured in any of the ways shown in time options.
.PP
For example \f[V]--default-time 2020-06-01\f[R] to set the default time
to the 1st of June 2020 or \f[V]--default-time 0s\f[R] to set the
default time to the time rclone started up.
.SS --disable string
.PP
This disables a comma separated list of optional features.
For example to disable server-side move and server-side copy use:
--disable move,copy
The features can be put in any case.
To see a list of which features can be disabled use:
.IP
.nf
\f[C]
--disable help
\f[R]
.fi
The features a remote has can be seen in JSON format with:
.IP
.nf
\f[C]
rclone backend features remote:
\f[R]
.fi
See the overview features (https://rclone.org/overview/#features) and
optional features (https://rclone.org/overview/#optional-features) to
get an idea of which feature does what.
Note that some features can be set to \f[V]true\f[R] if they are
\f[V]true\f[R]/\f[V]false\f[R] feature flag features by prefixing them
with \f[V]!\f[R].
For example the \f[V]CaseInsensitive\f[R] feature can be forced to
\f[V]false\f[R] with \f[V]--disable CaseInsensitive\f[R] and forced to
\f[V]true\f[R] with \f[V]--disable \[aq]!CaseInsensitive\[aq]\f[R].
In general it isn\[aq]t a good idea doing this but it may be useful in
extremis.
(Note that \f[V]!\f[R] is a shell command which you will need to escape
with single quotes or a backslash on unix like platforms.)
This flag can be useful for debugging and in exceptional circumstances
(e.g.
Google Drive limiting the total volume of server-side copies to 100
GiB/day).
.SS --disable-http2
This stops rclone from trying to use HTTP/2 if available.
This can sometimes speed up transfers due to a problem in the Go
standard library (https://github.com/golang/go/issues/37373).
.SS --dscp string
Specify a DSCP value or name to use in connections.
This could help QoS system to identify traffic class.
BE, EF, DF, LE, CSx and AFxx are allowed.
See the description of differentiated
services (https://en.wikipedia.org/wiki/Differentiated_services) to get
an idea of this field.
Setting this to 1 (LE) to identify the flow to SCAVENGER class can avoid
occupying too much bandwidth in a network with DiffServ support (RFC
8622 (https://tools.ietf.org/html/rfc8622)).
For example, if you configured QoS on router to handle LE properly.
Running:
.IP
.nf
\f[C]
rclone copy --dscp LE from:/from to:/to
\f[R]
.fi
would make the priority lower than usual internet flows.
This option has no effect on Windows (see
golang/go#42728 (https://github.com/golang/go/issues/42728)).
.SS -n, --dry-run
Do a trial run with no permanent changes.
Use this to see what rclone would do without actually doing it.
Useful when setting up the
sync (https://rclone.org/commands/rclone_sync/) command which deletes
files in the destination.
.SS --expect-continue-timeout Duration
This specifies the amount of time to wait for a server\[aq]s first
response headers after fully writing the request headers if the request
has an \[dq]Expect: 100-continue\[dq] header.
Not all backends support using this.
Zero means no timeout and causes the body to be sent immediately,
without waiting for the server to approve.
This time does not include the time to send the request header.
.PP
The default is \f[V]1s\f[R].
Set to \f[V]0\f[R] to disable.
.SS --error-on-no-transfer
.PP
By default, rclone will exit with return code 0 if there were no errors.
.PP
This option allows rclone to return exit code 9 if no files were
transferred between the source and destination.
This allows using rclone in scripts, and triggering follow-on actions if
data was copied, or skipping if not.
.PP
NB: Enabling this option turns a usually non-fatal error into a
potentially fatal one - please check and adjust your scripts
accordingly!
.SS --fix-case
.PP
Normally, a sync to a case insensitive dest (such as macOS / Windows)
will not result in a matching filename if the source and dest filenames
have casing differences but are otherwise identical.
For example, syncing \f[V]hello.txt\f[R] to \f[V]HELLO.txt\f[R] will
normally result in the dest filename remaining \f[V]HELLO.txt\f[R].
If \f[V]--fix-case\f[R] is set, then \f[V]HELLO.txt\f[R] will be renamed
to \f[V]hello.txt\f[R] to match the source.
.PP
NB:
directory names with incorrect casing will also be fixed
\f[V]--fix-case\f[R] will be ignored if \f[V]--immutable\f[R] is set
using \f[V]--local-case-sensitive\f[R] instead is not advisable; it will
cause \f[V]HELLO.txt\f[R] to get deleted!
.IP \[bu] 2
the old dest filename must not be excluded by filters.
Be especially careful with
\f[V]--files-from\f[R] (https://rclone.org/filtering/#files-from-read-list-of-source-file-names),
which does not respect
\f[V]--ignore-case\f[R] (https://rclone.org/filtering/#ignore-case-make-searches-case-insensitive)!
.IP \[bu] 2
on remotes that do not support server-side move, \f[V]--fix-case\f[R]
will require downloading the file and re-uploading it.
To avoid this, do not use \f[V]--fix-case\f[R].
.SS --fs-cache-expire-duration Duration
When using rclone via the API rclone caches created remotes for 5
minutes by default in the \[dq]fs cache\[dq].
This means that if you do repeated actions on the same remote then
rclone won\[aq]t have to build it again from scratch, which makes it
more efficient.
This flag sets the time that the remotes are cached for.
If you set it to \f[V]0\f[R] (or negative) then rclone won\[aq]t cache
the remotes at all.
Note that if you use some flags, eg \f[V]--backup-dir\f[R] and if this
is set to \f[V]0\f[R] rclone may build two remotes (one for the source
or destination and one for the \f[V]--backup-dir\f[R] where it may have
only built one before.
.SS --fs-cache-expire-interval Duration
This controls how often rclone checks for cached remotes to expire.
See the \f[V]--fs-cache-expire-duration\f[R] documentation above for
more info.
The default is 60s, set to 0 to disable expiry.
.SS --header stringArray
Add an HTTP header for all transactions.
The flag can be repeated to add multiple headers.
If you want to add headers only for uploads use
\f[V]--header-upload\f[R] and if you want to add headers only for
downloads use \f[V]--header-download\f[R].
This flag is supported for all HTTP based backends even those not
supported by \f[V]--header-upload\f[R] and \f[V]--header-download\f[R]
so may be used as a workaround for those with care.
.IP
.nf
\f[C]
rclone ls remote:test --header \[dq]X-Rclone: Foo\[dq] --header \[dq]X-LetMeIn: Yes\[dq]
\f[R]
.fi
.SS --header-download stringArray
Add an HTTP header for all download transactions.
The flag can be repeated to add multiple headers.
.IP
.nf
\f[C]
rclone sync --interactive s3:test/src \[ti]/dst --header-download \[dq]X-Amz-Meta-Test: Foo\[dq] --header-download \[dq]X-Amz-Meta-Test2: Bar\[dq]
\f[R]
.fi
See GitHub issue #59 (https://github.com/rclone/rclone/issues/59) for
currently supported backends.
.SS --header-upload stringArray
Add an HTTP header for all upload transactions.
The flag can be repeated to add multiple headers.
.IP
.nf
\f[C]
rclone sync --interactive \[ti]/src s3:test/dst --header-upload \[dq]Content-Disposition: attachment; filename=\[aq]cool.html\[aq]\[dq] --header-upload \[dq]X-Amz-Meta-Test: FooBar\[dq]
\f[R]
.fi
See GitHub issue #59 (https://github.com/rclone/rclone/issues/59) for
currently supported backends.
.SS --http-proxy string
Use this option to set an HTTP proxy for all HTTP based services to use.
Rclone also supports the standard HTTP proxy environment variables which
it will pick up automatically.
The is the way the HTTP proxy will normally be set but this flag can be
used to override it.
.SS --human-readable
Rclone commands output values for sizes (e.g.
number of bytes) and counts (e.g.
number of files) either as \f[I]raw\f[R] numbers, or in
\f[I]human-readable\f[R] format.
In human-readable format the values are scaled to larger units,
indicated with a suffix shown after the value, and rounded to three
decimals.
Rclone consistently uses binary units (powers of 2) for sizes and
decimal units (powers of 10) for counts.
The unit prefix for size is according to IEC standard notation, e.g.
\f[V]Ki\f[R] for kibi.
Used with byte unit, \f[V]1 KiB\f[R] means 1024 Byte.
In list type of output, only the unit prefix appended to the value (e.g.
\f[V]9.762Ki\f[R]), while in more textual output the full unit is shown
(e.g.
\f[V]9.762 KiB\f[R]).
For counts the SI standard notation is used, e.g.
prefix \f[V]k\f[R] for kilo.
Used with file counts, \f[V]1k\f[R] means 1000 files.
The various list (https://rclone.org/commands/rclone_ls/) commands
output raw numbers by default.
Option \f[V]--human-readable\f[R] will make them output values in
human-readable format instead (with the short unit prefix).
The about (https://rclone.org/commands/rclone_about/) command outputs
human-readable by default, with a command-specific option
\f[V]--full\f[R] to output the raw numbers instead.
Command size (https://rclone.org/commands/rclone_size/) outputs both
human-readable and raw numbers in the same output.
The tree (https://rclone.org/commands/rclone_tree/) command also
considers \f[V]--human-readable\f[R], but it will not use the exact same
notation as the other commands: It rounds to one decimal, and uses
single letter suffix, e.g.
\f[V]K\f[R] instead of \f[V]Ki\f[R].
The reason for this is that it relies on an external library.
The interactive command ncdu (https://rclone.org/commands/rclone_ncdu/)
shows human-readable by default, and responds to key \f[V]u\f[R] for
toggling human-readable format.
.SS --ignore-case-sync
Using this option will cause rclone to ignore the case of the files when
synchronizing so files will not be copied/synced when the existing
filenames are the same, even if the casing is different.
.SS --ignore-checksum
Normally rclone will check that the checksums of transferred files
match, and give an error \[dq]corrupted on transfer\[dq] if they
don\[aq]t.
.PP
You can use this option to skip that check.
You should only use it if you have had the \[dq]corrupted on
transfer\[dq] error message and you are sure you might want to transfer
potentially corrupted data.
.SS --ignore-existing
.PP
Using this option will make rclone unconditionally skip all files that
exist on the destination, no matter the content of these files.
.PP
While this isn\[aq]t a generally recommended option, it can be useful in
cases where your files change due to encryption.
However, it cannot correct partial transfers in case a transfer was
interrupted.
.PP
When performing a \f[V]move\f[R]/\f[V]moveto\f[R] command, this flag
will leave skipped files in the source location unchanged when a file
with the same name exists on the destination.
.SS --ignore-size
.PP
Normally rclone will look at modification time and size of files to see
if they are equal.
If you set this flag then rclone will check only the modification time.
If \f[V]--checksum\f[R] is set then it only checks the checksum.
.PP
It will also cause rclone to skip verifying the sizes are the same after
transfer.
.PP
This can be useful for transferring files to and from OneDrive which
occasionally misreports the size of image files (see
#399 (https://github.com/rclone/rclone/issues/399) for more info).
.SS -I, --ignore-times
.PP
Using this option will cause rclone to unconditionally upload all files
regardless of the state of files on the destination.
.PP
Normally rclone would skip any files that have the same modification
time and are the same size (or have the same checksum if using
\f[V]--checksum\f[R]).
.SS --immutable
.PP
Treat source and destination files as immutable and disallow
modification.
.PP
With this option set, files will be created and deleted as requested,
but existing files will never be updated.
If an existing file does not match between the source and destination,
rclone will give the error
\f[V]Source and destination exist but do not match: immutable file modified\f[R].
.PP
Note that only commands which transfer files (e.g.
sync (https://rclone.org/commands/rclone_sync/),
move (https://rclone.org/commands/rclone_move/)) are affected by this
behavior, and only modification is disallowed.
Files may still be deleted explicitly (e.g.
delete (https://rclone.org/commands/rclone_delete/),
purge (https://rclone.org/commands/rclone_purge/)) or implicitly (e.g.
sync (https://rclone.org/commands/rclone_sync/),
move (https://rclone.org/commands/rclone_move/)).
Use \f[V]copy --immutable\f[R] if it is desired to avoid deletion as
well as modification.
This can be useful as an additional layer of protection for immutable or
append-only data sets (notably backup archives), where modification
implies corruption and should not be propagated.
.SS --inplace
The \f[V]--inplace\f[R] flag changes the behaviour of rclone when
uploading files to some backends (backends with the
\f[V]PartialUploads\f[R] feature flag set) such as:
.IP \[bu] 2
local
.IP \[bu] 2
ftp
.IP \[bu] 2
sftp
.IP \[bu] 2
pcloud
Without \f[V]--inplace\f[R] (the default) rclone will first upload to a
temporary file with an extension like this, where \f[V]XXXXXX\f[R]
represents a hash of the source file\[aq]s fingerprint and
\f[V].partial\f[R] is --partial-suffix value (\f[V].partial\f[R] by
default).
original-file-name.XXXXXX.partial
(rclone will make sure the final name is no longer than 100 characters
by truncating the \f[V]original-file-name\f[R] part if necessary).
When the upload is complete, rclone will rename the \f[V].partial\f[R]
file to the correct name, overwriting any existing file at that point.
If the upload fails then the \f[V].partial\f[R] file will be deleted.
This prevents other users of the backend from seeing partially uploaded
files in their new names and prevents overwriting the old file until the
new one is completely uploaded.
If the \f[V]--inplace\f[R] flag is supplied, rclone will upload directly
to the final name without creating a \f[V].partial\f[R] file.
This means that an incomplete file will be visible in the directory
listings while the upload is in progress and any existing files will be
overwritten as soon as the upload starts.
If the transfer fails then the file will be deleted.
This can cause data loss of the existing file if the transfer fails.
Note that on the local file system if you don\[aq]t use
\f[V]--inplace\f[R] hard links (Unix only) will be broken.
And if you do use \f[V]--inplace\f[R] you won\[aq]t be able to update in
use executables.
Note also that versions of rclone prior to v1.63.0 behave as if the
\f[V]--inplace\f[R] flag is always supplied.
.SS -i, --interactive
This flag can be used to tell rclone that you wish a manual confirmation
before destructive operations.
It is \f[B]recommended\f[R] that you use this flag while learning rclone
especially with \f[V]rclone sync\f[R].
.PP
For example
$ rclone delete --interactive /tmp/dir
rclone: delete \[dq]important-file.txt\[dq]?
y) Yes, this is OK (default)
n) No, skip this
s) Skip all delete operations with no more questions
!) Do all delete operations with no more questions
q) Exit rclone now.
y/n/s/!/q> n
The options mean
\f[V]y\f[R]: \f[B]Yes\f[R], this operation should go ahead.
You can also press Return for this to happen.
You\[aq]ll be asked every time unless you choose \f[V]s\f[R] or
\f[V]!\f[R].
\f[V]n\f[R]: \f[B]No\f[R], do not do this operation.
You\[aq]ll be asked every time unless you choose \f[V]s\f[R] or
\f[V]!\f[R].
\f[V]s\f[R]: \f[B]Skip\f[R] all the following operations of this type
with no more questions.
This takes effect until rclone exits.
If there are any different kind of operations you\[aq]ll be prompted for
them.
.IP \[bu] 2
\f[V]!\f[R]: \f[B]Do all\f[R] the following operations with no more
questions.
Useful if you\[aq]ve decided that you don\[aq]t mind rclone doing that
kind of operation.
This takes effect until rclone exits .
If there are any different kind of operations you\[aq]ll be prompted for
them.
.IP \[bu] 2
\f[V]q\f[R]: \f[B]Quit\f[R] rclone now, just in case!
.SS --leave-root
During rmdirs it will not remove root directory, even if it\[aq]s empty.
.SS -l, --links
Normally rclone will ignore symlinks or junction points (which behave
like symlinks under Windows).
Ignored files won\[aq]t be copied, moved or deleted in a sync.
If you supply this flag then rclone will copy symbolic links from any
supported backend backend, and store them as text files, with a
\f[V].rclonelink\f[R] suffix in the destination.
The text file will contain the target of the symbolic link.
The \f[V]--links\f[R] / \f[V]-l\f[R] flag enables this feature for all
supported backends and the VFS.
There are individual flags for just enabling it for the VFS
\f[V]--vfs-links\f[R] and the local backend \f[V]--local-links\f[R] if
required.
.SS --list-cutoff int
When syncing rclone needs to sort directory entries before comparing
them.
Below this threshold (1,000,000) by default, rclone will store the
directory entries in memory.
1,000,000 entries will take approx 1GB of RAM to store.
Above this threshold rclone will store directory entries on disk and
sort them without using a lot of memory.
Doing this is slightly less efficient then sorting them in memory and
will only work well for the bucket based backends (eg s3, b2, azureblob,
swift) but these are the only backends likely to have millions of
entries in a directory.
.SS --log-file string
Log all of rclone\[aq]s output to a file.
This is not active by default.
This can be useful for tracking down problems with syncs in combination
with the \f[V]-v\f[R] flag.
See the logging section for more info.
If the file exists, then rclone will append to it.
Note that if you are using the \f[V]logrotate\f[R] program to manage
rclone\[aq]s logs, then you should use the \f[V]copytruncate\f[R] option
as rclone doesn\[aq]t have a signal to rotate logs.
Alternatively you can use the options below to manage rclone\[aq]s built
in log rotation.
.SS --log-file-max-size SizeSuffix
Maximum size of the log file before it\[aq]s rotated (eg \f[V]10M\f[R]).
This SizeSuffix is rounded to the nearest MiB or 1 MiB if lower.
If \f[V]--log-file\f[R] is not set then this option will be ignored.
If this option is not set, then the other log rotation options will be
ignored.
For example if the following flags are in use
rclone --log-file rclone.log --log-file-max-size 1M --log-file-max-backups 3
Then this will create log files which look like this
$ ls -l
-rw-------  1 user user  1048491 Apr 11 17:15 rclone-2025-04-11T17-15-29.998.log
-rw-------  1 user user  1048511 Apr 11 17:15 rclone-2025-04-11T17-15-30.467.log
-rw-------  1 user user  1048559 Apr 11 17:15 rclone-2025-04-11T17-15-30.543.log
-rw-------  1 user user   521602 Apr 11 17:15 rclone.log
The file \f[V]rclone.log\f[R] being the current one.
.SS --log-file-compress
If set, compress rotated log files using gzip.
This changes the extension of the old log files to \f[V].log.gz\f[R].
Defaults to false - don\[aq]t compress log files.
.SS --log-file-max-age Duration
Maximum duration to retain old log files (eg \f[V]7d\f[R]).
This is rounded to the dearest day, or 1 day if lower.
The default is to retain all old log files.
.SS --log-file-max-backups int
Maximum number of old log files to retain
The default is to retain all old log files.
.SS --log-format string
Comma separated list of log format options.
The accepted options are:
\f[V]date\f[R] - Add a date in the format YYYY/MM/YY to the log.
\f[V]time\f[R] - Add a time to the log in format HH:MM:SS.
\f[V]microseconds\f[R] - Add microseconds to the time in format
HH:MM:SS.SSSSSS.
\f[V]UTC\f[R] - Make the logs in UTC not localtime.
.IP \[bu] 2
\f[V]longfile\f[R] - Adds the source file and line number of the log
statement.
.IP \[bu] 2
\f[V]shortfile\f[R] - Adds the source file and line number of the log
statement.
.IP \[bu] 2
\f[V]pid\f[R] - Add the process ID to the log - useful with
\f[V]rclone mount --daemon\f[R].
.IP \[bu] 2
\f[V]nolevel\f[R] - Don\[aq]t add the level to the log.
.IP \[bu] 2
\f[V]json\f[R] - Equivalent to adding \f[V]--use-json-log\f[R]
They are added to the log line in the order above.
The default log format is \f[V]\[dq]date,time\[dq]\f[R].
.SS --log-level LogLevel
This sets the log level for rclone.
The default log level is \f[V]NOTICE\f[R].
\f[V]DEBUG\f[R] is equivalent to \f[V]-vv\f[R].
It outputs lots of debug info - useful for bug reports and really
finding out what rclone is doing.
\f[V]INFO\f[R] is equivalent to \f[V]-v\f[R].
It outputs information about each transfer and prints stats once a
minute by default.
\f[V]NOTICE\f[R] is the default log level if no logging flags are
supplied.
It outputs very little when things are working normally.
It outputs warnings and significant events.
\f[V]ERROR\f[R] is equivalent to \f[V]-q\f[R].
It only outputs error messages.
See also the logging section.
.SS --windows-event-log LogLevel
If this is configured (the default is \f[V]OFF\f[R]) then logs of this
level and above will be logged to the Windows event log in
\f[B]addition\f[R] to the normal logs.
These will be logged in JSON format as described below regardless of
what format the main logs are configured for.
The Windows event log only has 3 levels of severity \f[V]Info\f[R],
\f[V]Warning\f[R] and \f[V]Error\f[R].
If enabled we map rclone levels like this.
\f[V]Error\f[R]  \f[V]ERROR\f[R] (and above)
\f[V]Warning\f[R]  \f[V]WARNING\f[R] (note that this level is defined
but not currently used).
\f[V]Info\f[R]  \f[V]NOTICE\f[R], \f[V]INFO\f[R] and \f[V]DEBUG\f[R].
Rclone will declare its log source as \[dq]rclone\[dq] if it is has
enough permissions to create the registry key needed.
If not then logs will appear as \[dq]Application\[dq].
You can run \f[V]rclone version --windows-event-log DEBUG\f[R] once as
administrator to create the registry key in advance.
\f[B]Note\f[R] that the \f[V]--windows-event-log\f[R] level must be
greater (more severe) than or equal to the \f[V]--log-level\f[R].
For example to log DEBUG to a log file but ERRORs to the event log you
would use
--log-file rclone.log --log-level DEBUG --windows-event-log ERROR
This option is only supported Windows platforms.
.SS --use-json-log
This switches the log format to JSON.
The log messages are then streamed as individual JSON objects, with
fields: \f[V]level\f[R], \f[V]msg\f[R], \f[V]source\f[R], and
\f[V]time\f[R].
The resulting format is what is sometimes referred to as
newline-delimited
JSON (https://en.wikipedia.org/wiki/JSON_streaming#Newline-delimited_JSON)
(NDJSON), or JSON Lines (JSONL).
This is well suited for processing by traditional line-oriented tools
and shell pipelines, but a complete log file is not strictly valid JSON
and needs a parser that can handle it.
The JSON logs will be printed on a single line, but are shown expanded
here for clarity.
{
  \[dq]time\[dq]: \[dq]2025-05-13T17:30:51.036237518+01:00\[dq],
  \[dq]level\[dq]: \[dq]debug\[dq],
  \[dq]msg\[dq]: \[dq]4 go routines active\[rs]n\[dq],
  \[dq]source\[dq]: \[dq]cmd/cmd.go:298\[dq]
}
Completed data transfer logs will have extra \f[V]size\f[R] information.
Logs which are about a particular object will have \f[V]object\f[R] and
\f[V]objectType\f[R] fields also.
{
  \[dq]time\[dq]: \[dq]2025-05-13T17:38:05.540846352+01:00\[dq],
  \[dq]level\[dq]: \[dq]info\[dq],
  \[dq]msg\[dq]: \[dq]Copied (new) to: file2.txt\[dq],
  \[dq]size\[dq]: 6,
  \[dq]object\[dq]: \[dq]file.txt\[dq],
  \[dq]objectType\[dq]: \[dq]*local.Object\[dq],
  \[dq]source\[dq]: \[dq]operations/copy.go:368\[dq]
}
Stats logs will contain a \f[V]stats\f[R] field which is the same as
returned from the rc call
core/stats (https://rclone.org/rc/#core-stats).
{
  \[dq]time\[dq]: \[dq]2025-05-13T17:38:05.540912847+01:00\[dq],
  \[dq]level\[dq]: \[dq]info\[dq],
  \[dq]msg\[dq]: \[dq]...text version of the stats...\[dq],
  \[dq]stats\[dq]: {
    \[dq]bytes\[dq]: 6,
    \[dq]checks\[dq]: 0,
    \[dq]deletedDirs\[dq]: 0,
    \[dq]deletes\[dq]: 0,
    \[dq]elapsedTime\[dq]: 0.000904825,
    ...truncated for clarity...
    \[dq]totalBytes\[dq]: 6,
    \[dq]totalChecks\[dq]: 0,
    \[dq]totalTransfers\[dq]: 1,
    \[dq]transferTime\[dq]: 0.000882794,
    \[dq]transfers\[dq]: 1
  },
  \[dq]source\[dq]: \[dq]accounting/stats.go:569\[dq]
}
.SS --low-level-retries int
This controls the number of low level retries rclone does.
A low level retry is used to retry a failing operation - typically one
HTTP request.
This might be uploading a chunk of a big file for example.
You will see low level retries in the log with the \f[V]-v\f[R] flag.
This shouldn\[aq]t need to be changed from the default in normal
operations.
However, if you get a lot of low level retries you may wish to reduce
the value so rclone moves on to a high level retry (see the
\f[V]--retries\f[R] flag) quicker.
Disable low level retries with \f[V]--low-level-retries 1\f[R].
.SS --max-backlog int
This is the maximum allowable backlog of files in a sync/copy/move
queued for being checked or transferred.
This can be set arbitrarily large.
It will only use memory when the queue is in use.
Note that it will use in the order of N KiB of memory when the backlog
is in use.
Setting this large allows rclone to calculate how many files are pending
more accurately, give a more accurate estimated finish time and make
\f[V]--order-by\f[R] work more accurately.
Setting this small will make rclone more synchronous to the listings of
the remote which may be desirable.
Setting this to a negative number will make the backlog as large as
possible.
.SS --max-buffer-memory SizeSuffix
If set, don\[aq]t allocate more than given amount of memory as buffers.
If not set or set to \f[V]0\f[R] or \f[V]off\f[R] this will not limit
the amount of memory in use.
This includes memory used by buffers created by the \f[V]--buffer\f[R]
flag and buffers used by multi-thread transfers.
Most multi-thread transfers do not take additional memory, but some do
depending on the backend (eg the s3 backend for uploads).
This means there is a tension between total setting
\f[V]--transfers\f[R] as high as possible and memory use.
Setting \f[V]--max-buffer-memory\f[R] allows the buffer memory to be
controlled so that it doesn\[aq]t overwhelm the machine and allows
\f[V]--transfers\f[R] to be set large.
.SS --max-connections int
This sets the maximum number of concurrent calls to the backend API.
It may not map 1:1 to TCP or HTTP connections depending on the backend
in use and the use of HTTP1 vs HTTP2.
When downloading files, backends only limit the initial opening of the
stream.
The bulk data download is not counted as a connection.
This means that the \f[V]--max--connections\f[R] flag won\[aq]t limit
the total number of downloads.
Note that it is possible to cause deadlocks with this setting so it
should be used with care.
If you are doing a sync or copy then make sure
\f[V]--max-connections\f[R] is one more than the sum of
\f[V]--transfers\f[R] and \f[V]--checkers\f[R].
If you use \f[V]--check-first\f[R] then \f[V]--max-connections\f[R] just
needs to be one more than the maximum of \f[V]--checkers\f[R] and
\f[V]--transfers\f[R].
So for \f[V]--max-connections 3\f[R] you\[aq]d use
\f[V]--checkers 2 --transfers 2 --check-first\f[R] or
\f[V]--checkers 1 --transfers 1\f[R].
Setting this flag can be useful for backends which do multipart uploads
to limit the number of simultaneous parts being transferred.
.SS --max-delete int
This tells rclone not to delete more than N files.
If that limit is exceeded then a fatal error will be generated and
rclone will stop the operation in progress.
.SS --max-delete-size SizeSuffix
Rclone will stop deleting files when the total size of deletions has
reached the size specified.
It defaults to off.
If that limit is exceeded then a fatal error will be generated and
rclone will stop the operation in progress.
.SS --max-depth int
This modifies the recursion depth for all the commands except purge.
So if you do \f[V]rclone --max-depth 1 ls remote:path\f[R] you will see
only the files in the top level directory.
Using \f[V]--max-depth 2\f[R] means you will see all the files in first
two directory levels and so on.
.PP
For historical reasons the \f[V]lsd\f[R] command defaults to using a
\f[V]--max-depth\f[R] of 1 - you can override this with the command line
flag.
.PP
You can use this command to disable recursion (with
\f[V]--max-depth 1\f[R]).
.PP
Note that if you use this with \f[V]sync\f[R] and
\f[V]--delete-excluded\f[R] the files not recursed through are
considered excluded and will be deleted on the destination.
Test first with \f[V]--dry-run\f[R] if you are not sure what will
happen.
.SS --max-duration Duration
.PP
Rclone will stop transferring when it has run for the duration
specified.
Defaults to off.
.PP
When the limit is reached all transfers will stop immediately.
Use \f[V]--cutoff-mode\f[R] to modify this behaviour.
.PP
Rclone will exit with exit code 10 if the duration limit is reached.
.SS --max-transfer SizeSuffix
.PP
Rclone will stop transferring when it has reached the size specified.
Defaults to off.
.PP
When the limit is reached all transfers will stop immediately.
Use \f[V]--cutoff-mode\f[R] to modify this behaviour.
.PP
Rclone will exit with exit code 8 if the transfer limit is reached.
.SS --cutoff-mode HARD|SOFT|CAUTIOUS
.PP
Configure the behavior of \f[V]--max-transfer\f[R] and
\f[V]--max-duration\f[R].
.PP
\f[V]HARD\f[R] will stop transferring immediately when rclone reaches
the limit.
This is the default.
.PP
\f[V]SOFT\f[R] will stop starting new transfers when rclone reaches the
limit.
.PP
\f[V]CAUTIOUS\f[R] will try to prevent rclone from reaching the limit.
Only applicable for \f[V]--max-transfer\f[R].
.SS -M, --metadata
.PP
Setting this flag enables rclone to copy the metadata from the source to
the destination.
For local backends this is ownership, permissions, xattr etc.
See the metadata section for more info.
.SS --metadata-mapper SpaceSepList
.PP
If you supply the parameter \f[V]--metadata-mapper /path/to/program\f[R]
then rclone will use that program to map metadata from source object to
destination object.
.PP
The argument to this flag should be a command with an optional space
separated list of arguments.
If one of the arguments has a space in then enclose it in
\f[V]\[dq]\f[R], if you want a literal \f[V]\[dq]\f[R] in an argument
then enclose the argument in \f[V]\[dq]\f[R] and double the
\f[V]\[dq]\f[R].
See CSV encoding (https://godoc.org/encoding/csv) for more info.
--metadata-mapper \[dq]python bin/test_metadata_mapper.py\[dq]
--metadata-mapper \[aq]python bin/test_metadata_mapper.py \[dq]argument with a space\[dq]\[aq]
--metadata-mapper \[aq]python bin/test_metadata_mapper.py \[dq]argument with \[dq]\[dq]two\[dq]\[dq] quotes\[dq]\[aq]
This uses a simple JSON based protocol with input on STDIN and output on
STDOUT.
This will be called for every file and directory copied and may be
called concurrently.
.PP
The program\[aq]s job is to take a metadata blob on the input and turn
it into a metadata blob on the output suitable for the destination
backend.
.PP
Input to the program (via STDIN) might look like this.
This provides some context for the \f[V]Metadata\f[R] which may be
important.
.IP \[bu] 2
\f[V]SrcFs\f[R] is the config string for the remote that the object is
currently on.
.IP \[bu] 2
\f[V]SrcFsType\f[R] is the name of the source backend.
.IP \[bu] 2
\f[V]DstFs\f[R] is the config string for the remote that the object is
being copied to
.IP \[bu] 2
\f[V]DstFsType\f[R] is the name of the destination backend.
.IP \[bu] 2
\f[V]Remote\f[R] is the path of the object relative to the root.
.IP \[bu] 2
\f[V]Size\f[R], \f[V]MimeType\f[R], \f[V]ModTime\f[R] are attributes of
the object.
.IP \[bu] 2
\f[V]IsDir\f[R] is \f[V]true\f[R] if this is a directory (not yet
implemented).
.IP \[bu] 2
\f[V]ID\f[R] is the source \f[V]ID\f[R] of the object if known.
.IP \[bu] 2
\f[V]Metadata\f[R] is the backend specific metadata as described in the
backend docs.
{
  \[dq]SrcFs\[dq]: \[dq]gdrive:\[dq],
  \[dq]SrcFsType\[dq]: \[dq]drive\[dq],
  \[dq]DstFs\[dq]: \[dq]newdrive:user\[dq],
  \[dq]DstFsType\[dq]: \[dq]onedrive\[dq],
  \[dq]Remote\[dq]: \[dq]test.txt\[dq],
  \[dq]Size\[dq]: 6,
  \[dq]MimeType\[dq]: \[dq]text/plain; charset=utf-8\[dq],
  \[dq]ModTime\[dq]: \[dq]2022-10-11T17:53:10.286745272+01:00\[dq],
  \[dq]IsDir\[dq]: false,
  \[dq]ID\[dq]: \[dq]xyz\[dq],
  \[dq]Metadata\[dq]: {
    \[dq]btime\[dq]: \[dq]2022-10-11T16:53:11Z\[dq],
    \[dq]content-type\[dq]: \[dq]text/plain; charset=utf-8\[dq],
    \[dq]mtime\[dq]: \[dq]2022-10-11T17:53:10.286745272+01:00\[dq],
    \[dq]owner\[dq]: \[dq]user1\[at]domain1.com\[dq],
    \[dq]permissions\[dq]: \[dq]...\[dq],
    \[dq]description\[dq]: \[dq]my nice file\[dq],
    \[dq]starred\[dq]: \[dq]false\[dq]
  }
}
The program should then modify the input as desired and send it to
STDOUT.
The returned \f[V]Metadata\f[R] field will be used in its entirety for
the destination object.
Any other fields will be ignored.
Note in this example we translate user names and permissions and add
something to the description:
{
  \[dq]Metadata\[dq]: {
    \[dq]btime\[dq]: \[dq]2022-10-11T16:53:11Z\[dq],
    \[dq]content-type\[dq]: \[dq]text/plain; charset=utf-8\[dq],
    \[dq]mtime\[dq]: \[dq]2022-10-11T17:53:10.286745272+01:00\[dq],
    \[dq]owner\[dq]: \[dq]user1\[at]domain2.com\[dq],
    \[dq]permissions\[dq]: \[dq]...\[dq],
    \[dq]description\[dq]: \[dq]my nice file [migrated from domain1]\[dq],
    \[dq]starred\[dq]: \[dq]false\[dq]
  }
}
Metadata can be removed here too.
An example python program might look something like this to implement
the above transformations.
.IP
.nf
\f[C]
import sys, json

i = json.load(sys.stdin)
metadata = i[\[dq]Metadata\[dq]]
# Add tag to description
if \[dq]description\[dq] in metadata:
    metadata[\[dq]description\[dq]] += \[dq] [migrated from domain1]\[dq]
else:
    metadata[\[dq]description\[dq]] = \[dq][migrated from domain1]\[dq]
# Modify owner
if \[dq]owner\[dq] in metadata:
    metadata[\[dq]owner\[dq]] = metadata[\[dq]owner\[dq]].replace(\[dq]domain1.com\[dq], \[dq]domain2.com\[dq])
o = { \[dq]Metadata\[dq]: metadata }
json.dump(o, sys.stdout, indent=\[dq]\[rs]t\[dq])
\f[R]
.fi
You can find this example (slightly expanded) in the rclone source code
at
bin/test_metadata_mapper.py (https://github.com/rclone/rclone/blob/master/bin/test_metadata_mapper.py).
If you want to see the input to the metadata mapper and the output
returned from it in the log you can use \f[V]-vv --dump mapper\f[R].
See the metadata section for more info.
.SS --metadata-set stringArray
Specify value as string in format \f[V]key=value\f[R] to add metadata
\f[V]key\f[R] with value \f[V]value\f[R] when uploading.
This can be repeated as many times as required.
See the metadata section for more info.
.SS --modify-window Duration
When checking whether a file has been modified, this is the maximum
allowed time difference that a file can have and still be considered
equivalent.
The default is \f[V]1ns\f[R] unless this is overridden by a remote.
For example OS X only stores modification times to the nearest second so
if you are reading and writing to an OS X filing system this will be
\f[V]1s\f[R] by default.
This command line flag allows you to override that computed default.
.SS --multi-thread-write-buffer-size SizeSuffix
When transferring with multiple threads, rclone will buffer the
specified number of bytes in memory before writing to disk for each
thread.
This can improve performance if the underlying filesystem does not deal
well with a lot of small writes in different positions of the file, so
if you see transfers being limited by disk write speed, you might want
to experiment with different values.
Specially for magnetic drives and remote file systems a higher value can
be useful.
Nevertheless, the default of \f[V]128k\f[R] should be fine for almost
all use cases, so before changing it ensure that network is not really
your bottleneck.
As a final hint, size is not the only factor: block size (or similar
concept) can have an impact.
In one case, we observed that exact multiples of 16k performed much
better than other values.
.SS --multi-thread-chunk-size SizeSuffix
Normally the chunk size for multi thread transfers is set by the
backend.
However some backends such as \f[V]local\f[R] and \f[V]smb\f[R] (which
implement \f[V]OpenWriterAt\f[R] but not \f[V]OpenChunkWriter\f[R])
don\[aq]t have a natural chunk size.
In this case the value of this option is used (default 64Mi).
.SS --multi-thread-cutoff SizeSuffix
When transferring files above specified size to capable backends, rclone
will use multiple threads to transfer the file (default 256M).
Capable backends are marked in the
overview (https://rclone.org/overview/#optional-features) as
\f[V]MultithreadUpload\f[R].
(They need to implement either the \f[V]OpenWriterAt\f[R] or
\f[V]OpenChunkWriter\f[R] internal interfaces).
These include include, \f[V]local\f[R], \f[V]s3\f[R],
\f[V]azureblob\f[R], \f[V]b2\f[R], \f[V]oracleobjectstorage\f[R] and
\f[V]smb\f[R] at the time of writing.
On the local disk, rclone preallocates the file (using
\f[V]fallocate(FALLOC_FL_KEEP_SIZE)\f[R] on unix or
\f[V]NTSetInformationFile\f[R] on Windows both of which takes no time)
then each thread writes directly into the file at the correct place.
This means that rclone won\[aq]t create fragmented or sparse files and
there won\[aq]t be any assembly time at the end of the transfer.
The number of threads used to transfer is controlled by
\f[V]--multi-thread-streams\f[R].
Use \f[V]-vv\f[R] if you wish to see info about the threads.
This will work with the sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) and
move (https://rclone.org/commands/rclone_move/) commands, and friends
copyto (https://rclone.org/commands/rclone_copyto/),
moveto (https://rclone.org/commands/rclone_moveto/).
Multi thread transfers will be used with \f[V]rclone mount\f[R] and
\f[V]rclone serve\f[R] if \f[V]--vfs-cache-mode\f[R] is set to
\f[V]writes\f[R] or above.
Most multi-thread transfers do not take additional memory, but some do
(for example uploading to s3).
In the worst case memory usage can be at maximum \f[V]--transfers\f[R] *
\f[V]--multi-thread-chunk-size\f[R] * \f[V]--multi-thread-streams\f[R]
or specifically for the s3 backend \f[V]--transfers\f[R] *
\f[V]--s3-chunk-size\f[R] * \f[V]--s3-concurrency\f[R].
However you can use the the
--max-buffer-memory (https://rclone.org/docs/#max-buffer-memory) flag to
control the maximum memory used here.
\f[B]NB\f[R] that this \f[B]only\f[R] works with supported backends as
the destination but will work with any backend as the source.
\f[B]NB\f[R] that multi-thread copies are disabled for local to local
copies as they are faster without unless
\f[V]--multi-thread-streams\f[R] is set explicitly.
.PP
\f[B]NB\f[R] on Windows using multi-thread transfers to the local disk
will cause the resulting files to be
sparse (https://en.wikipedia.org/wiki/Sparse_file).
Use \f[V]--local-no-sparse\f[R] to disable sparse files (which may cause
long delays at the start of transfers) or disable multi-thread transfers
with \f[V]--multi-thread-streams 0\f[R]
.SS --multi-thread-streams int
.PP
When using multi thread transfers (see above
\f[V]--multi-thread-cutoff\f[R]) this sets the number of streams to use.
Set to \f[V]0\f[R] to disable multi thread transfers (Default 4).
.PP
If the backend has a \f[V]--backend-upload-concurrency\f[R] setting (eg
\f[V]--s3-upload-concurrency\f[R]) then this setting will be used as the
number of transfers instead if it is larger than the value of
\f[V]--multi-thread-streams\f[R] or \f[V]--multi-thread-streams\f[R]
isn\[aq]t set.
.SS --name-transform stringArray
.PP
\f[V]--name-transform\f[R] introduces path name transformations for
\f[V]rclone copy\f[R], \f[V]rclone sync\f[R], and \f[V]rclone move\f[R].
These transformations enable modifications to source and destination
file names by applying prefixes, suffixes, and other alterations during
transfer operations.
For detailed docs and examples, see
\f[V]convmv\f[R] (https://rclone.org/commands/rclone_convmv/).
.SS --no-check-dest
.PP
The \f[V]--no-check-dest\f[R] can be used with \f[V]move\f[R] or
\f[V]copy\f[R] and it causes rclone not to check the destination at all
when copying files.
.PP
This means that:
the destination is not listed minimising the API calls
files are always transferred
this can cause duplicates on remotes which allow it (e.g.
Google Drive)
\f[V]--retries 1\f[R] is recommended otherwise you\[aq]ll transfer
everything again on a retry
This flag is useful to minimise the transactions if you know that none
of the files are on the destination.
This is a specialized flag which should be ignored by most users!
.SS --no-gzip-encoding
Don\[aq]t set \f[V]Accept-Encoding: gzip\f[R].
This means that rclone won\[aq]t ask the server for compressed files
automatically.
Useful if you\[aq]ve set the server to return files with
\f[V]Content-Encoding: gzip\f[R] but you uploaded compressed files.
There is no need to set this in normal operation, and doing so will
decrease the network transfer efficiency of rclone.
.SS --no-traverse
The \f[V]--no-traverse\f[R] flag controls whether the destination file
system is traversed when using the \f[V]copy\f[R] or \f[V]move\f[R]
commands.
\f[V]--no-traverse\f[R] is not compatible with \f[V]sync\f[R] and will
be ignored if you supply it with \f[V]sync\f[R].
If you are only copying a small number of files (or are filtering most
of the files) and/or have a large number of files on the destination
then \f[V]--no-traverse\f[R] will stop rclone listing the destination
and save time.
However, if you are copying a large number of files, especially if you
are doing a copy where lots of the files under consideration haven\[aq]t
changed and won\[aq]t need copying then you shouldn\[aq]t use
\f[V]--no-traverse\f[R].
See rclone copy (https://rclone.org/commands/rclone_copy/) for an
example of how to use it.
.SS --no-unicode-normalization
Don\[aq]t normalize unicode characters in filenames during the sync
routine.
Sometimes, an operating system will store filenames containing unicode
parts in their decomposed form (particularly macOS).
Some cloud storage systems will then recompose the unicode, resulting in
duplicate files if the data is ever copied back to a local filesystem.
Using this flag will disable that functionality, treating each unicode
character as unique.
For example, by default e and  will be normalized into the same
character.
With \f[V]--no-unicode-normalization\f[R] they will be treated as unique
characters.
.SS --no-update-modtime
When using this flag, rclone won\[aq]t update modification times of
remote files if they are incorrect as it would normally.
.PP
This can be used if the remote is being synced with another tool also
(e.g.
the Google Drive client).
.SS --no-update-dir-modtime
.PP
When using this flag, rclone won\[aq]t update modification times of
remote directories if they are incorrect as it would normally.
.SS --order-by string
.PP
The \f[V]--order-by\f[R] flag controls the order in which files in the
backlog are processed in \f[V]rclone sync\f[R], \f[V]rclone copy\f[R]
and \f[V]rclone move\f[R].
.PP
The order by string is constructed like this.
The first part describes what aspect is being measured:
\f[V]size\f[R] - order by the size of the files
\f[V]name\f[R] - order by the full path of the files
\f[V]modtime\f[R] - order by the modification date of the files
.PP
This can have a modifier appended with a comma:
\f[V]ascending\f[R] or \f[V]asc\f[R] - order so that the smallest (or
oldest) is processed first
\f[V]descending\f[R] or \f[V]desc\f[R] - order so that the largest (or
newest) is processed first
.IP \[bu] 2
\f[V]mixed\f[R] - order so that the smallest is processed first for some
threads and the largest for others
If the modifier is \f[V]mixed\f[R] then it can have an optional
percentage (which defaults to \f[V]50\f[R]), e.g.
\f[V]size,mixed,25\f[R] which means that 25% of the threads should be
taking the smallest items and 75% the largest.
The threads which take the smallest first will always take the smallest
first and likewise the largest first threads.
The \f[V]mixed\f[R] mode can be useful to minimise the transfer time
when you are transferring a mixture of large and small files - the large
files are guaranteed upload threads and bandwidth and the small files
will be processed continuously.
If no modifier is supplied then the order is \f[V]ascending\f[R].
For example
.IP \[bu] 2
\f[V]--order-by size,desc\f[R] - send the largest files first
.IP \[bu] 2
\f[V]--order-by modtime,ascending\f[R] - send the oldest files first
.IP \[bu] 2
\f[V]--order-by name\f[R] - send the files with alphabetically by path
first
If the \f[V]--order-by\f[R] flag is not supplied or it is supplied with
an empty string then the default ordering will be used which is as
scanned.
With \f[V]--checkers 1\f[R] this is mostly alphabetical, however with
the default \f[V]--checkers 8\f[R] it is somewhat random.
.SS Limitations
The \f[V]--order-by\f[R] flag does not do a separate pass over the data.
This means that it may transfer some files out of the order specified if
.IP \[bu] 2
there are no files in the backlog or the source has not been fully
scanned yet
.IP \[bu] 2
there are more than --max-backlog files in the backlog
Rclone will do its best to transfer the best file it has so in practice
this should not cause a problem.
Think of \f[V]--order-by\f[R] as being more of a best efforts flag
rather than a perfect ordering.
If you want perfect ordering then you will need to specify --check-first
which will find all the files which need transferring first before
transferring any.
.SS --partial-suffix string
When --inplace is not used, it causes rclone to use the
\f[V]--partial-suffix\f[R] as suffix for temporary files.
Suffix length limit is 16 characters.
The default is \f[V].partial\f[R].
.SS --password-command SpaceSepList
This flag supplies a program which should supply the config password
when run.
This is an alternative to rclone prompting for the password or setting
the \f[V]RCLONE_CONFIG_PASS\f[R] variable.
It is also used when setting the config password for the first time.
The argument to this should be a command with a space separated list of
arguments.
If one of the arguments has a space in then enclose it in
\f[V]\[dq]\f[R], if you want a literal \f[V]\[dq]\f[R] in an argument
then enclose the argument in \f[V]\[dq]\f[R] and double the
\f[V]\[dq]\f[R].
See CSV encoding (https://godoc.org/encoding/csv) for more info.
Eg
--password-command \[dq]echo hello\[dq]
--password-command \[aq]echo \[dq]hello with space\[dq]\[aq]
--password-command \[aq]echo \[dq]hello with \[dq]\[dq]quotes\[dq]\[dq] and space\[dq]\[aq]
Note that when changing the configuration password the environment
variable \f[V]RCLONE_PASSWORD_CHANGE=1\f[R] will be set.
This can be used to distinguish initial decryption of the config file
from the new password.
See the Configuration Encryption for more info.
See a Windows PowerShell example on the
Wiki (https://github.com/rclone/rclone/wiki/Windows-Powershell-use-rclone-password-command-for-Config-file-password).
.SS -P, --progress
This flag makes rclone update the stats in a static block in the
terminal providing a realtime overview of the transfer.
Any log messages will scroll above the static block.
Log messages will push the static block down to the bottom of the
terminal where it will stay.
Normally this is updated every 500mS but this period can be overridden
with the \f[V]--stats\f[R] flag.
This can be used with the \f[V]--stats-one-line\f[R] flag for a simpler
display.
To change the display length of filenames (for different terminal
widths), see the \f[V]--stats-file-name-length\f[R] option.
The default output is formatted for 80 character wide terminals.
Note: On Windows until this
bug (https://github.com/Azure/go-ansiterm/issues/26) is fixed all
non-ASCII characters will be replaced with \f[V].\f[R] when
\f[V]--progress\f[R] is in use.
.SS --progress-terminal-title
This flag, when used with \f[V]-P/--progress\f[R], will print the string
\f[V]ETA: %s\f[R] to the terminal title.
.SS -q, --quiet
This flag will limit rclone\[aq]s output to error messages only.
.SS --refresh-times
The \f[V]--refresh-times\f[R] flag can be used to update modification
times of existing files when they are out of sync on backends which
don\[aq]t support hashes.
This is useful if you uploaded files with the incorrect timestamps and
you now wish to correct them.
This flag is \f[B]only\f[R] useful for destinations which don\[aq]t
support hashes (e.g.
\f[V]crypt\f[R]).
This can be used any of the sync commands
sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/).
To use this flag you will need to be doing a modification time sync (so
not using \f[V]--size-only\f[R] or \f[V]--checksum\f[R]).
The flag will have no effect when using \f[V]--size-only\f[R] or
\f[V]--checksum\f[R].
If this flag is used when rclone comes to upload a file it will check to
see if there is an existing file on the destination.
If this file matches the source with size (and checksum if available)
but has a differing timestamp then instead of re-uploading it, rclone
will update the timestamp on the destination file.
If the checksum does not match rclone will upload the new file.
If the checksum is absent (e.g.
on a \f[V]crypt\f[R] backend) then rclone will update the timestamp.
Note that some remotes can\[aq]t set the modification time without
re-uploading the file so this flag is less useful on them.
Normally if you are doing a modification time sync rclone will update
modification times without \f[V]--refresh-times\f[R] provided that the
remote supports checksums \f[B]and\f[R] the checksums match on the file.
However if the checksums are absent then rclone will upload the file
rather than setting the timestamp as this is the safe behaviour.
.SS --retries int
Retry the entire sync if it fails this many times it fails (default 3).
Some remotes can be unreliable and a few retries help pick up the files
which didn\[aq]t get transferred because of errors.
Disable retries with \f[V]--retries 1\f[R].
.SS --retries-sleep Duration
This sets the interval between each retry specified by
\f[V]--retries\f[R]
The default is \f[V]0\f[R].
Use \f[V]0\f[R] to disable.
.SS --server-side-across-configs
Allow server-side operations (e.g.
copy or move) to work across different configurations.
.PP
This can be useful if you wish to do a server-side copy or move between
two remotes which use the same backend but are configured differently.
.PP
Note that this isn\[aq]t enabled by default because it isn\[aq]t easy
for rclone to tell if it will work between any two configurations.
.SS --size-only
.PP
Normally rclone will look at modification time and size of files to see
if they are equal.
If you set this flag then rclone will check only the size.
.PP
This can be useful transferring files from Dropbox which have been
modified by the desktop sync client which doesn\[aq]t set checksums of
modification times in the same way as rclone.
.SS --stats Duration
.PP
Commands which transfer data
(sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/),
copyto (https://rclone.org/commands/rclone_copyto/),
move (https://rclone.org/commands/rclone_move/),
moveto (https://rclone.org/commands/rclone_moveto/)) will print data
transfer stats at regular intervals to show their progress.
.PP
This sets the interval.
.PP
The default is \f[V]1m\f[R].
Use \f[V]0\f[R] to disable.
.PP
If you set the stats interval then all commands can show stats.
This can be useful when running other commands, \f[V]check\f[R] or
\f[V]mount\f[R] for example.
.PP
Stats are logged at \f[V]INFO\f[R] level by default which means they
won\[aq]t show at default log level \f[V]NOTICE\f[R].
Use \f[V]--stats-log-level NOTICE\f[R] or \f[V]-v\f[R] to make them
show.
See the logging section for more info on log levels.
.PP
Note that on macOS you can send a SIGINFO (which is normally ctrl-T in
the terminal) to make the stats print immediately.
.SS --stats-file-name-length int
.PP
By default, the \f[V]--stats\f[R] output will truncate file names and
paths longer than 40 characters.
This is equivalent to providing \f[V]--stats-file-name-length 40\f[R].
Use \f[V]--stats-file-name-length 0\f[R] to disable any truncation of
file names printed by stats.
.SS --stats-log-level LogLevel
.PP
Log level to show \f[V]--stats\f[R] output at.
This can be \f[V]DEBUG\f[R], \f[V]INFO\f[R], \f[V]NOTICE\f[R], or
\f[V]ERROR\f[R].
The default is \f[V]INFO\f[R].
This means at the default level of logging, which is \f[V]NOTICE\f[R],
the stats won\[aq]t show - if you want them to then use
\f[V]--stats-log-level NOTICE\f[R].
See the logging section for more details on log levels.
.SS --stats-one-line
.PP
When this is specified, rclone condenses the stats into a single line
showing the most important stats only.
.SS --stats-one-line-date
.PP
When this is specified, rclone enables the single-line stats and
prepends the display with a date string.
The default is \f[V]2006/01/02 15:04:05 -\f[R]
.SS --stats-one-line-date-format string
.PP
When this is specified, rclone enables the single-line stats and
prepends the display with a user-supplied date string.
The date string MUST be enclosed in quotes.
Follow golang specs (https://golang.org/pkg/time/#Time.Format) for date
formatting syntax.
.SS --stats-unit string
.PP
By default, data transfer rates will be printed in bytes per second,
corresponding to \f[V]--stats-unit bytes\f[R].
.PP
This option allows the data rate to be printed in bits per second, by
specifying \f[V]--stats-unit bits\f[R].
Data transfer volume will still be reported in bytes.
.PP
The rate is reported as a binary unit, not SI unit.
So 1 Mbit/s equals 1,048,576 bit/s and not 1,000,000 bit/s.
.SS --suffix string
.PP
When using sync (https://rclone.org/commands/rclone_sync/),
copy (https://rclone.org/commands/rclone_copy/) or
move (https://rclone.org/commands/rclone_move/) any files which would
have been overwritten or deleted will have the suffix added to them.
If there is a file with the same path (after the suffix has been added),
then it will be overwritten.
.PP
The remote in use must support server-side move or copy and you must use
the same remote as the destination of the sync.
.PP
This is for use with files to add the suffix in the current directory or
with \f[V]--backup-dir\f[R].
See \f[V]--backup-dir\f[R] for more info.
.PP
For example
rclone copy --interactive /path/to/local/file remote:current --suffix .bak
will copy \f[V]/path/to/local\f[R] to \f[V]remote:current\f[R], but for
any files which would have been updated or deleted have .bak added.
.PP
If using \f[V]rclone sync\f[R] with \f[V]--suffix\f[R] and without
\f[V]--backup-dir\f[R] then it is recommended to put a filter rule in
excluding the suffix otherwise the \f[V]sync\f[R] will delete the backup
files.
rclone sync --interactive /path/to/local/file remote:current --suffix .bak --exclude \[dq]*.bak\[dq]
.SS --suffix-keep-extension
When using \f[V]--suffix\f[R], setting this causes rclone put the SUFFIX
before the extension of the files that it backs up rather than after.
So let\[aq]s say we had \f[V]--suffix -2019-01-01\f[R], without the flag
\f[V]file.txt\f[R] would be backed up to \f[V]file.txt-2019-01-01\f[R]
and with the flag it would be backed up to
\f[V]file-2019-01-01.txt\f[R].
This can be helpful to make sure the suffixed files can still be opened.
If a file has two (or more) extensions and the second (or subsequent)
extension is recognised as a valid mime type, then the suffix will go
before that extension.
So \f[V]file.tar.gz\f[R] would be backed up to
\f[V]file-2019-01-01.tar.gz\f[R] whereas \f[V]file.badextension.gz\f[R]
would be backed up to \f[V]file.badextension-2019-01-01.gz\f[R].
.SS --syslog
On capable OSes (not Windows or Plan9) send all log output to syslog.
This can be useful for running rclone in a script or
\f[V]rclone mount\f[R].
.SS --syslog-facility string
If using \f[V]--syslog\f[R] this sets the syslog facility (e.g.
\f[V]KERN\f[R], \f[V]USER\f[R]).
See \f[V]man syslog\f[R] for a list of possible facilities.
The default facility is \f[V]DAEMON\f[R].
.SS --temp-dir string
Specify the directory rclone will use for temporary files, to override
the default.
Make sure the directory exists and have accessible permissions.
By default the operating system\[aq]s temp directory will be used:
.IP \[bu] 2
On Unix systems, \f[V]$TMPDIR\f[R] if non-empty, else \f[V]/tmp\f[R].
.IP \[bu] 2
On Windows, the first non-empty value from \f[V]%TMP%\f[R],
\f[V]%TEMP%\f[R], \f[V]%USERPROFILE%\f[R], or the Windows directory.
When overriding the default with this option, the specified path will be
set as value of environment variable \f[V]TMPDIR\f[R] on Unix systems
and \f[V]TMP\f[R] and \f[V]TEMP\f[R] on Windows.
You can use the config
paths (https://rclone.org/commands/rclone_config_paths/) command to see
the current value.
.SS --tpslimit float
Limit transactions per second to this number.
Default is 0 which is used to mean unlimited transactions per second.
A transaction is roughly defined as an API call; its exact meaning will
depend on the backend.
For HTTP based backends it is an HTTP PUT/GET/POST/etc and its response.
For FTP/SFTP it is a round trip transaction over TCP.
For example, to limit rclone to 10 transactions per second use
\f[V]--tpslimit 10\f[R], or to 1 transaction every 2 seconds use
\f[V]--tpslimit 0.5\f[R].
Use this when the number of transactions per second from rclone is
causing a problem with the cloud storage provider (e.g.
getting you banned or rate limited).
This can be very useful for \f[V]rclone mount\f[R] to control the
behaviour of applications using it.
This limit applies to all HTTP based backends and to the FTP and SFTP
backends.
It does not apply to the local backend or the Storj backend.
See also \f[V]--tpslimit-burst\f[R].
.SS --tpslimit-burst int
Max burst of transactions for \f[V]--tpslimit\f[R] (default
\f[V]1\f[R]).
Normally \f[V]--tpslimit\f[R] will do exactly the number of transaction
per second specified.
However if you supply \f[V]--tps-burst\f[R] then rclone can save up some
transactions from when it was idle giving a burst of up to the parameter
supplied.
For example if you provide \f[V]--tpslimit-burst 10\f[R] then if rclone
has been idle for more than 10*\f[V]--tpslimit\f[R] then it can do 10
transactions very quickly before they are limited again.
This may be used to increase performance of \f[V]--tpslimit\f[R] without
changing the long term average number of transactions per second.
.SS --track-renames
By default, rclone doesn\[aq]t keep track of renamed files, so if you
rename a file locally then sync it to a remote, rclone will delete the
old file on the remote and upload a new copy.
An rclone sync with \f[V]--track-renames\f[R] runs like a normal sync,
but keeps track of objects which exist in the destination but not in the
source (which would normally be deleted), and which objects exist in the
source but not the destination (which would normally be transferred).
These objects are then candidates for renaming.
After the sync, rclone matches up the source only and destination only
objects using the \f[V]--track-renames-strategy\f[R] specified and
either renames the destination object or transfers the source and
deletes the destination object.
\f[V]--track-renames\f[R] is stateless like all of rclone\[aq]s syncs.
To use this flag the destination must support server-side copy or
server-side move, and to use a hash based
\f[V]--track-renames-strategy\f[R] (the default) the source and the
destination must have a compatible hash.
If the destination does not support server-side copy or move, rclone
will fall back to the default behaviour and log an error level message
to the console.
Encrypted destinations are not currently supported by
\f[V]--track-renames\f[R] if \f[V]--track-renames-strategy\f[R] includes
\f[V]hash\f[R].
Note that \f[V]--track-renames\f[R] is incompatible with
\f[V]--no-traverse\f[R] and that it uses extra memory to keep track of
all the rename candidates.
Note also that \f[V]--track-renames\f[R] is incompatible with
\f[V]--delete-before\f[R] and will select \f[V]--delete-after\f[R]
instead of \f[V]--delete-during\f[R].
.SS --track-renames-strategy string
This option changes the file matching criteria for
\f[V]--track-renames\f[R].
The matching is controlled by a comma separated selection of these
tokens:
.IP \[bu] 2
\f[V]modtime\f[R] - the modification time of the file - not supported on
all backends
.IP \[bu] 2
\f[V]hash\f[R] - the hash of the file contents - not supported on all
backends
.IP \[bu] 2
\f[V]leaf\f[R] - the name of the file not including its directory name
.IP \[bu] 2
\f[V]size\f[R] - the size of the file (this is always enabled)
The default option is \f[V]hash\f[R].
Using \f[V]--track-renames-strategy modtime,leaf\f[R] would match files
based on modification time, the leaf of the file name and the size only.
Using \f[V]--track-renames-strategy modtime\f[R] or \f[V]leaf\f[R] can
enable \f[V]--track-renames\f[R] support for encrypted destinations.
Note that the \f[V]hash\f[R] strategy is not supported with encrypted
destinations.
.SS --delete-(before,during,after)
This option allows you to specify when files on your destination are
deleted when you sync folders.
Specifying the value \f[V]--delete-before\f[R] will delete all files
present on the destination, but not on the source \f[I]before\f[R]
starting the transfer of any new or updated files.
This uses two passes through the file systems, one for the deletions and
one for the copies.
Specifying \f[V]--delete-during\f[R] will delete files while checking
and uploading files.
This is the fastest option and uses the least memory.
Specifying \f[V]--delete-after\f[R] (the default value) will delay
deletion of files until all new/updated files have been successfully
transferred.
The files to be deleted are collected in the copy pass then deleted
after the copy pass has completed successfully.
The files to be deleted are held in memory so this mode may use more
memory.
This is the safest mode as it will only delete files if there have been
no errors subsequent to that.
If there have been errors before the deletions start then you will get
the message \f[V]not deleting files as there were IO errors\f[R].
.SS --fast-list
When doing anything which involves a directory listing (e.g.
\f[V]sync\f[R], \f[V]copy\f[R], \f[V]ls\f[R] - in fact nearly every
command), rclone has different strategies to choose from.
The basic strategy is to list one directory and processes it before
using more directory lists to process any subdirectories.
This is a mandatory backend feature, called \f[V]List\f[R], which means
it is supported by all backends.
This strategy uses small amount of memory, and because it can be
parallelised it is fast for operations involving processing of the list
results.
Some backends provide the support for an alternative strategy, where all
files beneath a directory can be listed in one (or a small number) of
transactions.
Rclone supports this alternative strategy through an optional backend
feature called \f[V]ListR\f[R] (https://rclone.org/overview/#listr).
You can see in the storage system overview documentation\[aq]s optional
features (https://rclone.org/overview/#optional-features) section which
backends it is enabled for (these tend to be the bucket-based ones, e.g.
S3, B2, GCS, Swift).
This strategy requires fewer transactions for highly recursive
operations, which is important on backends where this is charged or
heavily rate limited.
It may be faster (due to fewer transactions) or slower (because it
can\[aq]t be parallelized) depending on different parameters, and may
require more memory if rclone has to keep the whole listing in memory.
Which listing strategy rclone picks for a given operation is
complicated, but in general it tries to choose the best possible.
It will prefer \f[V]ListR\f[R] in situations where it doesn\[aq]t need
to store the listed files in memory, e.g.
for unlimited recursive \f[V]ls\f[R] command variants.
In other situations it will prefer \f[V]List\f[R], e.g.
for \f[V]sync\f[R] and \f[V]copy\f[R], where it needs to keep the listed
files in memory, and is performing operations on them where
parallelization may be a huge advantage.
Rclone is not able to take all relevant parameters into account for
deciding the best strategy, and therefore allows you to influence the
choice in two ways: You can stop rclone from using \f[V]ListR\f[R] by
disabling the feature, using the --disable option
(\f[V]--disable ListR\f[R]), or you can allow rclone to use
\f[V]ListR\f[R] where it would normally choose not to do so due to
higher memory usage, using the \f[V]--fast-list\f[R] option.
Rclone should always produce identical results either way.
Using \f[V]--disable ListR\f[R] or \f[V]--fast-list\f[R] on a remote
which doesn\[aq]t support \f[V]ListR\f[R] does nothing, rclone will just
ignore it.
A rule of thumb is that if you pay for transactions and can fit your
entire sync listing into memory, then \f[V]--fast-list\f[R] is
recommended.
If you have a very big sync to do, then don\[aq]t use
\f[V]--fast-list\f[R], otherwise you will run out of memory.
Run some tests and compare before you decide, and if in doubt then just
leave the default, let rclone decide, i.e.
not use \f[V]--fast-list\f[R].
.SS --timeout Duration
This sets the IO idle timeout.
If a transfer has started but then becomes idle for this long it is
considered broken and disconnected.
The default is \f[V]5m\f[R].
Set to \f[V]0\f[R] to disable.
.SS --transfers int
The number of file transfers to run in parallel.
It can sometimes be useful to set this to a smaller number if the remote
is giving a lot of timeouts or bigger if you have lots of bandwidth and
a fast remote.
The default is to run 4 file transfers in parallel.
Look at --multi-thread-streams if you would like to control single file
transfers.
.SS -u, --update
This forces rclone to skip any files which exist on the destination and
have a modified time that is newer than the source file.
This can be useful in avoiding needless transfers when transferring to a
remote which doesn\[aq]t support modification times directly (or when
using \f[V]--use-server-modtime\f[R] to avoid extra API calls) as it is
more accurate than a \f[V]--size-only\f[R] check and faster than using
\f[V]--checksum\f[R].
On such remotes (or when using \f[V]--use-server-modtime\f[R]) the time
checked will be the uploaded time.
If an existing destination file has a modification time older than the
source file\[aq]s, it will be updated if the sizes are different.
If the sizes are the same, it will be updated if the checksum is
different or not available.
If an existing destination file has a modification time equal (within
the computed modify window) to the source file\[aq]s, it will be updated
if the sizes are different.
The checksum will not be checked in this case unless the
\f[V]--checksum\f[R] flag is provided.
In all other cases the file will not be updated.
Consider using the \f[V]--modify-window\f[R] flag to compensate for time
skews between the source and the backend, for backends that do not
support mod times, and instead use uploaded times.
However, if the backend does not support checksums, note that syncing or
copying within the time skew window may still result in additional
transfers for safety.
.SS --use-mmap
If this flag is set then rclone will use anonymous memory allocated by
mmap on Unix based platforms and VirtualAlloc on Windows for its
transfer buffers (size controlled by \f[V]--buffer-size\f[R]).
Memory allocated like this does not go on the Go heap and can be
returned to the OS immediately when it is finished with.
If this flag is not set then rclone will allocate and free the buffers
using the Go memory allocator which may use more memory as memory pages
are returned less aggressively to the OS.
It is possible this does not work well on all platforms so it is
disabled by default; in the future it may be enabled by default.
.SS --use-server-modtime
Some object-store backends (e.g, Swift, S3) do not preserve file
modification times (modtime).
On these backends, rclone stores the original modtime as additional
metadata on the object.
By default it will make an API call to retrieve the metadata when the
modtime is needed by an operation.
Use this flag to disable the extra API call and rely instead on the
server\[aq]s modified time.
In cases such as a local to remote sync using \f[V]--update\f[R],
knowing the local file is newer than the time it was last uploaded to
the remote is sufficient.
In those cases, this flag can speed up the process and reduce the number
of API calls necessary.
Using this flag on a sync operation without also using
\f[V]--update\f[R] would cause all files modified at any time other than
the last upload time to be uploaded again, which is probably not what
you want.
.SS -v, -vv, --verbose
With \f[V]-v\f[R] rclone will tell you about each file that is
transferred and a small number of significant events.
With \f[V]-vv\f[R] rclone will become very verbose telling you about
every file it considers and transfers.
Please send bug reports with a log with this setting.
When setting verbosity as an environment variable, use
\f[V]RCLONE_VERBOSE=1\f[R] or \f[V]RCLONE_VERBOSE=2\f[R] for
\f[V]-v\f[R] and \f[V]-vv\f[R] respectively.
.SS -V, --version
Prints the version number
.SS SSL/TLS options
The outgoing SSL/TLS connections rclone makes can be controlled with
these options.
For example this can be very useful with the HTTP or WebDAV backends.
Rclone HTTP servers have their own set of configuration for SSL/TLS
which you can find in their documentation.
.SS --ca-cert stringArray
This loads the PEM encoded certificate authority certificates and uses
it to verify the certificates of the servers rclone connects to.
If you have generated certificates signed with a local CA then you will
need this flag to connect to servers using those certificates.
.SS --client-cert string
This loads the PEM encoded client side certificate.
This is used for mutual TLS
authentication (https://en.wikipedia.org/wiki/Mutual_authentication).
The \f[V]--client-key\f[R] flag is required too when using this.
.SS --client-key string
This loads the PEM encoded client side private key used for mutual TLS
authentication.
Used in conjunction with \f[V]--client-cert\f[R].
Supported types are:
Unencrypted PKCS#1 (\[dq]BEGIN RSA PRIVATE KEY\[dq])
Unencrypted PKCS#8 (\[dq]BEGIN PRIVATE KEY\[dq])
Encrypted PKCS#8 (\[dq]BEGIN ENCRYPTED PRIVATE KEY\[dq])
Legacy PEM encryption (e.g., DEK-Info headers), which are automatically
detected.
.SS --client-pass string
This can be used to supply an optional password to decrypt the client
key file.
\f[B]NB\f[R] the password should be obscured so it should be the output
of \f[V]rclone obscure YOURPASSWORD\f[R].
.SS --no-check-certificate
\f[V]--no-check-certificate\f[R] controls whether a client verifies the
server\[aq]s certificate chain and host name.
If \f[V]--no-check-certificate\f[R] is true, TLS accepts any certificate
presented by the server and any host name in that certificate.
In this mode, TLS is susceptible to man-in-the-middle attacks.
This option defaults to \f[V]false\f[R].
\f[B]This should be used only for testing.\f[R]
.SS Configuration encryption
Your configuration file contains information for logging in to your
cloud services.
This means that you should keep your \f[V]rclone.conf\f[R] file in a
secure location.
If you are in an environment where that isn\[aq]t possible, you can add
a password to your configuration.
This means that you will have to supply the password every time you
start rclone.
To add a password to your rclone configuration, execute
\f[V]rclone config\f[R].
.IP
.nf
\f[C]
$ rclone config
Current remotes:

e) Edit existing remote
n) New remote
d) Delete remote
s) Set configuration password
q) Quit config
e/n/d/s/q>
\f[R]
.fi
Go into \f[V]s\f[R], Set configuration password:
.IP
.nf
\f[C]
e/n/d/s/q> s
Your configuration is not encrypted.
If you add a password, you will protect your login information to cloud services.
a) Add Password
q) Quit to main menu
a/q> a
Enter NEW configuration password:
password:
Confirm NEW password:
password:
Password set
Your configuration is encrypted.
c) Change Password
u) Unencrypt configuration
q) Quit to main menu
c/u/q>
\f[R]
.fi
Your configuration is now encrypted, and every time you start rclone you
will have to supply the password.
See below for details.
In the same menu, you can change the password or completely remove
encryption from your configuration.
There is no way to recover the configuration if you lose your password.
You can also use
rclone config encryption
set (https://rclone.org/commands/rclone_config_encryption_set/) to set
the config encryption directly
rclone config encryption
remove (https://rclone.org/commands/rclone_config_encryption_remove/) to
remove it
rclone config encryption
check (https://rclone.org/commands/rclone_config_encryption_check/) to
check that it is encrypted properly.
rclone uses nacl
secretbox (https://godoc.org/golang.org/x/crypto/nacl/secretbox) which
in turn uses XSalsa20 and Poly1305 to encrypt and authenticate your
configuration with secret-key cryptography.
The password is SHA-256 hashed, which produces the key for secretbox.
The hashed password is not stored.
While this provides very good security, we do not recommend storing your
encrypted rclone configuration in public if it contains sensitive
information, maybe except if you use a very strong password.
If it is safe in your environment, you can set the
\f[V]RCLONE_CONFIG_PASS\f[R] environment variable to contain your
password, in which case it will be used for decrypting the
configuration.
You can set this for a session from a script.
For unix like systems save this to a file called
\f[V]set-rclone-password\f[R]:
.IP
.nf
\f[C]
#!/bin/echo Source this file don\[aq]t run it

read -s RCLONE_CONFIG_PASS
export RCLONE_CONFIG_PASS
\f[R]
.fi
Then source the file when you want to use it.
From the shell you would do \f[V]source set-rclone-password\f[R].
It will then ask you for the password and set it in the environment
variable.
An alternate means of supplying the password is to provide a script
which will retrieve the password and print on standard output.
This script should have a fully specified path name and not rely on any
environment variables.
The script is supplied either via
\f[V]--password-command=\[dq]...\[dq]\f[R] command line argument or via
the \f[V]RCLONE_PASSWORD_COMMAND\f[R] environment variable.
One useful example of this is using the \f[V]passwordstore\f[R]
application to retrieve the password:
.IP
.nf
\f[C]
export RCLONE_PASSWORD_COMMAND=\[dq]pass rclone/config\[dq]
\f[R]
.fi
If the \f[V]passwordstore\f[R] password manager holds the password for
the rclone configuration, using the script method means the password is
primarily protected by the \f[V]passwordstore\f[R] system, and is never
embedded in the clear in scripts, nor available for examination using
the standard commands available.
It is quite possible with long running rclone sessions for copies of
passwords to be innocently captured in log files or terminal scroll
buffers, etc.
Using the script method of supplying the password enhances the security
of the config password considerably.
If you are running rclone inside a script, unless you are using the
\f[V]--password-command\f[R] method, you might want to disable password
prompts.
To do that, pass the parameter \f[V]--ask-password=false\f[R] to rclone.
This will make rclone fail instead of asking for a password if
\f[V]RCLONE_CONFIG_PASS\f[R] doesn\[aq]t contain a valid password, and
\f[V]--password-command\f[R] has not been supplied.
Whenever running commands that may be affected by options in a
configuration file, rclone will look for an existing file according to
the rules described above, and load any it finds.
If an encrypted file is found, this includes decrypting it, with the
possible consequence of a password prompt.
When executing a command line that you know are not actually using
anything from such a configuration file, you can avoid it being loaded
by overriding the location, e.g.
with one of the documented special values for memory-only configuration.
Since only backend options can be stored in configuration files, this is
normally unnecessary for commands that do not operate on backends, e.g.
\f[V]completion\f[R].
However, it will be relevant for commands that do operate on backends in
general, but are used without referencing a stored remote, e.g.
listing local filesystem paths, or connection strings:
\f[V]rclone --config=\[dq]\[dq] ls .\f[R]
.SS Configuration encryption cheatsheet
You can quickly apply a configuration encryption without plain-text at
rest or transfer.
Detailed instructions for popular OSes:
.SS Mac
.IP \[bu] 2
Generate and store a password
.RS 2
security add-generic-password -a rclone -s config -w $(openssl rand -base64 40)
.RE
.IP \[bu] 2
Add the retrieval instruction to your \f[V].zprofile\f[R] /
\f[V].profile\f[R]
.RS 2
.IP
.nf
\f[C]
export RCLONE_PASSWORD_COMMAND=\[dq]/usr/bin/security find-generic-password -a rclone -s config -w\[dq]
\f[R]
.fi
.RE
.SS Linux
.IP \[bu] 2
Prerequisite: Linux doesn\[aq]t come with a default password manager.
Let\[aq]s install the \[dq]pass\[dq] utility using a package manager,
e.g.
\f[V]apt install pass\f[R], \f[V]yum install pass\f[R],
etc. (https://www.passwordstore.org/#download); then initialize a
password store: \f[V]pass init rclone\f[R].
.IP \[bu] 2
Generate and store a password
.RS 2
.IP
.nf
\f[C]
echo $(openssl rand -base64 40) | pass insert -m rclone/config
\f[R]
.fi
.RE
.IP \[bu] 2
Add the retrieval instruction
.RS 2
.IP
.nf
\f[C]
export RCLONE_PASSWORD_COMMAND=\[dq]/usr/bin/pass rclone/config\[dq]
\f[R]
.fi
.RE
.SS Windows
.IP \[bu] 2
Generate and store a password
.RS 2
.IP
.nf
\f[C]
New-Object -TypeName PSCredential -ArgumentList \[dq]rclone\[dq], (ConvertTo-SecureString -String ([System.Web.Security.Membership]::GeneratePassword(40, 10)) -AsPlainText -Force) | Export-Clixml -Path \[dq]rclone-credential.xml\[dq]
\f[R]
.fi
.RE
.IP \[bu] 2
Add the password retrieval instruction
.RS 2
.IP
.nf
\f[C]
[Environment]::SetEnvironmentVariable(\[dq]RCLONE_PASSWORD_COMMAND\[dq], \[dq][System.Runtime.InteropServices.Marshal]::PtrToStringAuto([System.Runtime.InteropServices.Marshal]::SecureStringToBSTR((Import-Clixml -Path \[dq]rclone-credential.xml\[dq]).Password))\[dq])
\f[R]
.fi
.RE
.SS Encrypt the config file (all systems)
.IP \[bu] 2
Execute \f[V]rclone config\f[R], and select option
\f[V]s) Set configuration password\f[R]
.IP \[bu] 2
Add/update the password from previous steps
.SS Developer options
These options are useful when developing or debugging rclone.
There are also some more remote specific options which aren\[aq]t
documented here which are used for testing.
These start with remote name e.g.
\f[V]--drive-test-option\f[R] - see the docs for the remote in question.
.SS --cpuprofile string
Write CPU profile to a file.
This can be analysed with \f[V]go tool pprof\f[R].
.SS --memprofile string
Write memory profile to a file.
This can be analysed with \f[V]go tool pprof\f[R].
.SS --dump DumpFlags
The \f[V]--dump\f[R] flag takes a comma separated list of flags to dump
info about.
Note that some headers, such as \f[V]Accept-Encoding\f[R], may not be
correct as shown in the request, and the response may not show
\f[V]Content-Encoding\f[R] if the go standard libraries auto gzip
encoding was in effect.
In this case the body of the request will be gunzipped before showing
it.
The available flags are:
.IP \[bu] 2
\f[V]headers\f[R] dumps HTTP headers.
Any \f[V]Authorization:\f[R] headers will be excluded, but output may
still contain sensitive information.
Can be very verbose.
Useful for debugging only.
Use \f[V]auth\f[R] if you do want the \f[V]Authorization:\f[R] headers.
.IP \[bu] 2
\f[V]auth\f[R] dumps HTTP headers like \f[V]headers\f[R], but also
includes any \f[V]Authorization:\f[R] headers.
This means the output will probably contain sensitive information.
Use \f[V]headers\f[R] to dump without \f[V]Authorization:\f[R] headers.
Can be very verbose.
Useful for debugging only.
.IP \[bu] 2
\f[V]bodies\f[R] dumps HTTP headers and bodies.
May contain sensitive info.
Can be very verbose.
Useful for debugging only.
Note that the bodies are buffered in memory so don\[aq]t use this for
enormous files.
.IP \[bu] 2
\f[V]requests\f[R] is similar to \f[V]bodies\f[R], but dumps the request
bodies and the response headers.
Useful for debugging download problems.
.IP \[bu] 2
\f[V]responses\f[R] is similar to \f[V]bodies\f[R], but dumps the
response bodies and the request headers.
Useful for debugging upload problems.
.IP \[bu] 2
\f[V]filters\f[R] dumps the filters.
Useful to see exactly what include and exclude options are filtering on.
.IP \[bu] 2
\f[V]goroutines\f[R] dumps a list of the running go-routines at the end
of the command.
.IP \[bu] 2
\f[V]openfiles\f[R] dumps a list of the open files at the end of the
command.
It uses the \f[V]lsof\f[R] Unix command to do that, so you\[aq]ll need
that installed to use it.
.IP \[bu] 2
\f[V]mapper\f[R] dumps the JSON blobs being sent to the program supplied
with \f[V]--metadata-mapper\f[R] and received from it.
It can be useful for debugging the metadata mapper interface.
.SS Filtering
For the filtering options
.IP \[bu] 2
\f[V]--delete-excluded\f[R]
.IP \[bu] 2
\f[V]--filter\f[R]
.IP \[bu] 2
\f[V]--filter-from\f[R]
.IP \[bu] 2
\f[V]--exclude\f[R]
.IP \[bu] 2
\f[V]--exclude-from\f[R]
.IP \[bu] 2
\f[V]--exclude-if-present\f[R]
.IP \[bu] 2
\f[V]--include\f[R]
.IP \[bu] 2
\f[V]--include-from\f[R]
.IP \[bu] 2
\f[V]--files-from\f[R]
.IP \[bu] 2
\f[V]--files-from-raw\f[R]
.IP \[bu] 2
\f[V]--min-size\f[R]
.IP \[bu] 2
\f[V]--max-size\f[R]
.IP \[bu] 2
\f[V]--min-age\f[R]
.IP \[bu] 2
\f[V]--max-age\f[R]
.IP \[bu] 2
\f[V]--hash-filter\f[R]
.IP \[bu] 2
\f[V]--dump filters\f[R]
.IP \[bu] 2
\f[V]--metadata-include\f[R]
.IP \[bu] 2
\f[V]--metadata-include-from\f[R]
.IP \[bu] 2
\f[V]--metadata-exclude\f[R]
.IP \[bu] 2
\f[V]--metadata-exclude-from\f[R]
.IP \[bu] 2
\f[V]--metadata-filter\f[R]
.IP \[bu] 2
\f[V]--metadata-filter-from\f[R]
See the filtering section (https://rclone.org/filtering/).
.SS Remote control
For the remote control options and for instructions on how to remote
control rclone:
.IP \[bu] 2
\f[V]--rc\f[R]
.IP \[bu] 2
Anything starting with \f[V]--rc-\f[R]
See the remote control section (https://rclone.org/rc/).
.SS Logging
rclone has 4 levels of logging, \f[V]ERROR\f[R], \f[V]NOTICE\f[R],
\f[V]INFO\f[R] and \f[V]DEBUG\f[R].
By default, rclone logs to standard error.
This means you can redirect standard error and still see the normal
output of rclone commands (e.g.
\f[V]rclone ls\f[R]).
By default, rclone will produce \f[V]Error\f[R] and \f[V]Notice\f[R]
level messages.
If you use the \f[V]-q\f[R] flag, rclone will only produce
\f[V]Error\f[R] messages.
If you use the \f[V]-v\f[R] flag, rclone will produce \f[V]Error\f[R],
\f[V]Notice\f[R] and \f[V]Info\f[R] messages.
If you use the \f[V]-vv\f[R] flag, rclone will produce \f[V]Error\f[R],
\f[V]Notice\f[R], \f[V]Info\f[R] and \f[V]Debug\f[R] messages.
You can also control the log levels with the \f[V]--log-level\f[R] flag.
If you use the \f[V]--log-file\f[R] option, rclone will redirect
\f[V]Error\f[R], \f[V]Info\f[R] and \f[V]Debug\f[R] messages along with
standard error to a file.
If you use the \f[V]--syslog\f[R] flag then rclone will log to syslog
and the \f[V]--syslog-facility\f[R] control which facility it uses.
Rclone prefixes all log messages with their level in capitals, e.g.
INFO which makes it easy to grep the log file for different kinds of
information.
.SS Metrics
Rclone can publish metrics in the OpenMetrics/Prometheus format.
To enable the metrics endpoint, use the \f[V]--metrics-addr\f[R] flag.
Metrics can also be published on the \f[V]--rc-addr\f[R] port if the
\f[V]--rc\f[R] flag and \f[V]--rc-enable-metrics\f[R] flags are supplied
or if using rclone rcd \f[V]--rc-enable-metrics\f[R]
Rclone provides extensive configuration options for the metrics HTTP
endpoint.
These settings are grouped under the Metrics section and have a prefix
\f[V]--metrics-*\f[R].
When metrics are enabled with \f[V]--rc-enable-metrics\f[R], they will
be published on the same port as the rc API.
In this case, the \f[V]--metrics-*\f[R] flags will be ignored, and the
HTTP endpoint configuration will be managed by the \f[V]--rc-*\f[R]
parameters.
.SS Exit code
If any errors occur during the command execution, rclone will exit with
a non-zero exit code.
This allows scripts to detect when rclone operations have failed.
During the startup phase, rclone will exit immediately if an error is
detected in the configuration.
There will always be a log message immediately before exiting.
When rclone is running it will accumulate errors as it goes along, and
only exit with a non-zero exit code if (after retries) there were still
failed transfers.
For every error counted there will be a high priority log message
(visible with \f[V]-q\f[R]) showing the message and which file caused
the problem.
A high priority message is also shown when starting a retry so the user
can see that any previous error messages may not be valid after the
retry.
If rclone has done a retry it will log a high priority message if the
retry was successful.
.SS List of exit codes
.IP \[bu] 2
\f[V]0\f[R] - Success
.IP \[bu] 2
\f[V]1\f[R] - Error not otherwise categorised
.IP \[bu] 2
\f[V]2\f[R] - Syntax or usage error
.IP \[bu] 2
\f[V]3\f[R] - Directory not found
.IP \[bu] 2
\f[V]4\f[R] - File not found
.IP \[bu] 2
\f[V]5\f[R] - Temporary error (one that more retries might fix) (Retry
errors)
.IP \[bu] 2
\f[V]6\f[R] - Less serious errors (like 461 errors from dropbox)
(NoRetry errors)
.IP \[bu] 2
\f[V]7\f[R] - Fatal error (one that more retries won\[aq]t fix, like
account suspended) (Fatal errors)
.IP \[bu] 2
\f[V]8\f[R] - Transfer exceeded - limit set by --max-transfer reached
.IP \[bu] 2
\f[V]9\f[R] - Operation successful, but no files transferred (Requires
\f[V]--error-on-no-transfer\f[R])
.IP \[bu] 2
\f[V]10\f[R] - Duration exceeded - limit set by --max-duration reached
.SS Environment variables
Rclone can be configured entirely using environment variables.
These can be used to set defaults for options or config file entries.
.SS Options
Every option in rclone can have its default set by environment variable.
To find the name of the environment variable, first, take the long
option name, strip the leading \f[V]--\f[R], change \f[V]-\f[R] to
\f[V]_\f[R], make upper case and prepend \f[V]RCLONE_\f[R].
For example, to always set \f[V]--stats 5s\f[R], set the environment
variable \f[V]RCLONE_STATS=5s\f[R].
If you set stats on the command line this will override the environment
variable setting.
Or to always use the trash in drive \f[V]--drive-use-trash\f[R], set
\f[V]RCLONE_DRIVE_USE_TRASH=true\f[R].
Verbosity is slightly different, the environment variable equivalent of
\f[V]--verbose\f[R] or \f[V]-v\f[R] is \f[V]RCLONE_VERBOSE=1\f[R], or
for \f[V]-vv\f[R], \f[V]RCLONE_VERBOSE=2\f[R].
The same parser is used for the options and the environment variables so
they take exactly the same form.
The options set by environment variables can be seen with the
\f[V]-vv\f[R] flag, e.g.
\f[V]rclone version -vv\f[R].
Options that can appear multiple times (type \f[V]stringArray\f[R]) are
treated slightly differently as environment variables can only be
defined once.
In order to allow a simple mechanism for adding one or many items, the
input is treated as a CSV encoded (https://godoc.org/encoding/csv)
string.
For example
.TS
tab(@);
lw(36.7n) lw(33.3n).
T{
Environment variable
T}@T{
Equivalent options
T}
_
T{
\f[V]RCLONE_EXCLUDE=\[dq]*.jpg\[dq]\f[R]
T}@T{
\f[V]--exclude \[dq]*.jpg\[dq]\f[R]
T}
T{
\f[V]RCLONE_EXCLUDE=\[dq]*.jpg,*.png\[dq]\f[R]
T}@T{
\f[V]--exclude \[dq]*.jpg\[dq]\f[R] \f[V]--exclude \[dq]*.png\[dq]\f[R]
T}
T{
\f[V]RCLONE_EXCLUDE=\[aq]\[dq]*.jpg\[dq],\[dq]*.png\[dq]\[aq]\f[R]
T}@T{
\f[V]--exclude \[dq]*.jpg\[dq]\f[R] \f[V]--exclude \[dq]*.png\[dq]\f[R]
T}
T{
\f[V]RCLONE_EXCLUDE=\[aq]\[dq]/directory with comma , in it /**\[dq]\[aq]\f[R]
T}@T{
\[ga]--exclude \[dq]/directory with comma , in it /**\[dq]
T}
.TE
If \f[V]stringArray\f[R] options are defined as environment variables
\f[B]and\f[R] options on the command line then all the values will be
used.
.SS Config file
You can set defaults for values in the config file on an individual
remote basis.
The names of the config items are documented in the page for each
backend.
To find the name of the environment variable, you need to set, take
\f[V]RCLONE_CONFIG_\f[R] + name of remote + \f[V]_\f[R] + name of config
file option and make it all uppercase.
Note one implication here is the remote\[aq]s name must be convertible
into a valid environment variable name, so it can only contain letters,
digits, or the \f[V]_\f[R] (underscore) character.
For example, to configure an S3 remote named \f[V]mys3:\f[R] without a
config file (using unix ways of setting environment variables):
$ export RCLONE_CONFIG_MYS3_TYPE=s3
$ export RCLONE_CONFIG_MYS3_ACCESS_KEY_ID=XXX
$ export RCLONE_CONFIG_MYS3_SECRET_ACCESS_KEY=XXX
$ rclone lsd mys3:
          -1 2016-09-21 12:54:21        -1 my-bucket
$ rclone listremotes | grep mys3
mys3:
Note that if you want to create a remote using environment variables you
must create the \f[V]..._TYPE\f[R] variable as above.
Note that the name of a remote created using environment variable is
case insensitive, in contrast to regular remotes stored in config file
as documented above.
You must write the name in uppercase in the environment variable, but as
seen from example above it will be listed and can be accessed in
lowercase, while you can also refer to the same remote in uppercase:
$ rclone lsd mys3:
          -1 2016-09-21 12:54:21        -1 my-bucket
$ rclone lsd MYS3:
          -1 2016-09-21 12:54:21        -1 my-bucket
Note that you can only set the options of the immediate backend, so
RCLONE_CONFIG_MYS3CRYPT_ACCESS_KEY_ID has no effect, if myS3Crypt is a
crypt remote based on an S3 remote.
However RCLONE_S3_ACCESS_KEY_ID will set the access key of all remotes
using S3, including myS3Crypt.
Note also that now rclone has connection strings, it is probably easier
to use those instead which makes the above example
.IP
.nf
\f[C]
rclone lsd :s3,access_key_id=XXX,secret_access_key=XXX:
\f[R]
.fi
.SS Precedence
The various different methods of backend configuration are read in this
order and the first one with a value is used.
Parameters in connection strings, e.g.
\f[V]myRemote,skip_links:\f[R]
Flag values as supplied on the command line, e.g.
\f[V]--skip-links\f[R]
.IP \[bu] 2
Remote specific environment vars, e.g.
\f[V]RCLONE_CONFIG_MYREMOTE_SKIP_LINKS\f[R] (see above).
.IP \[bu] 2
Backend-specific environment vars, e.g.
\f[V]RCLONE_LOCAL_SKIP_LINKS\f[R].
.IP \[bu] 2
Backend generic environment vars, e.g.
\f[V]RCLONE_SKIP_LINKS\f[R].
.IP \[bu] 2
Config file, e.g.
\f[V]skip_links = true\f[R].
.IP \[bu] 2
Default values, e.g.
\f[V]false\f[R] - these can\[aq]t be changed.
So if both \f[V]--skip-links\f[R] is supplied on the command line and an
environment variable \f[V]RCLONE_LOCAL_SKIP_LINKS\f[R] is set, the
command line flag will take preference.
The backend configurations set by environment variables can be seen with
the \f[V]-vv\f[R] flag, e.g.
\f[V]rclone about myRemote: -vv\f[R].
For non backend configuration the order is as follows:
.IP \[bu] 2
Flag values as supplied on the command line, e.g.
\f[V]--stats 5s\f[R].
.IP \[bu] 2
Environment vars, e.g.
\f[V]RCLONE_STATS=5s\f[R].
.IP \[bu] 2
Default values, e.g.
\f[V]1m\f[R] - these can\[aq]t be changed.
.SS Other environment variables
.IP \[bu] 2
\f[V]RCLONE_CONFIG_PASS\f[R] set to contain your config file password
(see Configuration Encryption section)
.IP \[bu] 2
\f[V]HTTP_PROXY\f[R], \f[V]HTTPS_PROXY\f[R] and \f[V]NO_PROXY\f[R] (or
the lowercase versions thereof).
.RS 2
.IP \[bu] 2
\f[V]HTTPS_PROXY\f[R] takes precedence over \f[V]HTTP_PROXY\f[R] for
https requests.
.IP \[bu] 2
The environment values may be either a complete URL or a
\[dq]host[:port]\[dq] for, in which case the \[dq]http\[dq] scheme is
assumed.
.RE
.IP \[bu] 2
\f[V]USER\f[R] and \f[V]LOGNAME\f[R] values are used as fallbacks for
current username.
The primary method for looking up username is OS-specific: Windows API
on Windows, real user ID in /etc/passwd on Unix systems.
In the documentation the current username is simply referred to as
\f[V]$USER\f[R].
.IP \[bu] 2
\f[V]RCLONE_CONFIG_DIR\f[R] - rclone \f[B]sets\f[R] this variable for
use in config files and sub processes to point to the directory holding
the config file.
The options set by environment variables can be seen with the
\f[V]-vv\f[R] and \f[V]--log-level=DEBUG\f[R] flags, e.g.
\f[V]rclone version -vv\f[R].
.SH Configuring rclone on a remote / headless machine
Some of the configurations (those involving oauth2) require an
internet-connected web browser.
If you are trying to set rclone up on a remote or headless machine with
no browser available on it (e.g.
a NAS or a server in a datacenter), then you will need to use an
alternative means of configuration.
There are three ways of doing it, described below.
.SS Configuring using rclone authorize
On the headless machine run rclone config, but answer \f[V]N\f[R] to the
question
\f[V]Use web browser to automatically authenticate rclone with remote?\f[R].
.IP
.nf
\f[C]
Use web browser to automatically authenticate rclone with remote?
 * Say Y if the machine running rclone has a web browser you can use
 * Say N if running rclone on a (remote) machine without web browser access
If not sure try Y. If Y failed, try N.

y) Yes (default)
n) No
y/n> n

Option config_token.
For this to work, you will need rclone available on a machine that has
a web browser available.
For more help and alternate methods see: https://rclone.org/remote_setup/
Execute the following on the machine with the web browser (same rclone
version recommended):
        rclone authorize \[dq]onedrive\[dq]
Then paste the result.
Enter a value.
config_token>
\f[R]
.fi
Then on your main desktop machine, run rclone
authorize (https://rclone.org/commands/rclone_authorize/).
.IP
.nf
\f[C]
rclone authorize \[dq]onedrive\[dq]
NOTICE: Make sure your Redirect URL is set to \[dq]http://localhost:53682/\[dq] in your custom config.
NOTICE: If your browser doesn\[aq]t open automatically go to the following link: http://127.0.0.1:53682/auth?state=xxxxxxxxxxxxxxxxxxxxxx
NOTICE: Log in and authorize rclone for access
NOTICE: Waiting for code...

Got code
Paste the following into your remote machine --->
SECRET_TOKEN
<---End paste
\f[R]
.fi
Then back to the headless machine, paste in the code.
.IP
.nf
\f[C]
config_token> SECRET_TOKEN
--------------------
[acd12]
client_id =
client_secret =
token = SECRET_TOKEN
--------------------
y) Yes this is OK
e) Edit this remote
d) Delete this remote
y/e/d>
\f[R]
.fi
.SS Configuring by copying the config file
Rclone stores all of its configuration in a single file.
This can easily be copied to configure a remote rclone (although some
backends does not support reusing the same configuration, consult your
backend documentation to be sure).
Start by running rclone config to create the configuration file on your
desktop machine.
.IP
.nf
\f[C]
rclone config
\f[R]
.fi
Then locate the file by running rclone config file.
.IP
.nf
\f[C]
$ rclone config file
Configuration file is stored at:
/home/user/.rclone.conf
\f[R]
.fi
Finally, transfer the file to the remote machine (scp, cut paste, ftp,
sftp, etc.)
and place it in the correct location (use rclone config file on the
remote machine to find out where).
.SS Configuring using SSH Tunnel
If you have an SSH client installed on your local machine, you can set
up an SSH tunnel to redirect the port 53682 into the headless machine by
using the following command:
.IP
.nf
\f[C]
ssh -L localhost:53682:localhost:53682 username\[at]remote_server
\f[R]
.fi
Then on the headless machine run rclone config and answer \f[V]Y\f[R] to
the question
\f[V]Use web browser to automatically authenticate rclone with remote?\f[R].
.IP
.nf
\f[C]
Use web browser to automatically authenticate rclone with remote?
 * Say Y if the machine running rclone has a web browser you can use
 * Say N if running rclone on a (remote) machine without web browser access
If not sure try Y. If Y failed, try N.

y) Yes (default)
n) No
y/n> y
NOTICE: Make sure your Redirect URL is set to \[dq]http://localhost:53682/\[dq] in your custom config.
NOTICE: If your browser doesn\[aq]t open automatically go to the following link: http://127.0.0.1:53682/auth?state=xxxxxxxxxxxxxxxxxxxxxx
NOTICE: Log in and authorize rclone for access
NOTICE: Waiting for code...
\f[R]
.fi
Finally, copy and paste the presented URL
\f[V]http://127.0.0.1:53682/auth?state=xxxxxxxxxxxxxxxxxxxxxx\f[R] to
the browser on your local machine, complete the auth and you are done.
.SH Filtering, includes and excludes
Filter flags determine which files rclone \f[V]sync\f[R],
\f[V]move\f[R], \f[V]ls\f[R], \f[V]lsl\f[R], \f[V]md5sum\f[R],
\f[V]sha1sum\f[R], \f[V]size\f[R], \f[V]delete\f[R], \f[V]check\f[R] and
similar commands apply to.
They are specified in terms of path/file name patterns; path/file lists;
file age and size, or presence of a file in a directory.
Bucket based remotes without the concept of directory apply filters to
object key, age and size in an analogous way.
Rclone \f[V]purge\f[R] does not obey filters.
To test filters without risk of damage to data, apply them to
\f[V]rclone ls\f[R], or with the \f[V]--dry-run\f[R] and \f[V]-vv\f[R]
flags.
Rclone filter patterns can only be used in filter command line options,
not in the specification of a remote.
E.g.
\f[V]rclone copy \[dq]remote:dir*.jpg\[dq] /path/to/dir\f[R] does not
have a filter effect.
\f[V]rclone copy remote:dir /path/to/dir --include \[dq]*.jpg\[dq]\f[R]
does.
\f[B]Important\f[R] Avoid mixing any two of \f[V]--include...\f[R],
\f[V]--exclude...\f[R] or \f[V]--filter...\f[R] flags in an rclone
command.
The results might not be what you expect.
Instead use a \f[V]--filter...\f[R] flag.
.SS Patterns for matching path/file names
.SS Pattern syntax
Here is a formal definition of the pattern syntax, examples are below.
Rclone matching rules follow a glob style:
.IP
.nf
\f[C]
*         matches any sequence of non-separator (/) characters
**        matches any sequence of characters including / separators
?         matches any single non-separator (/) character
[ [ ! ] { character-range } ]
          character class (must be non-empty)
{ pattern-list }
          pattern alternatives
{{ regexp }}
          regular expression to match
c         matches character c (c != *, **, ?, \[rs], [, {, })
\[rs]c        matches reserved character c (c = *, **, ?, \[rs], [, {, }) or character class
\f[R]
.fi
character-range:
c         matches character c (c != \[rs], -, ])
\[rs]c        matches reserved character c (c = \[rs], -, ])
lo - hi   matches character c for lo <= c <= hi
pattern-list:
pattern { , pattern }
          comma-separated (without spaces) patterns
character classes (see Go regular expression
reference (https://golang.org/pkg/regexp/syntax/)) include:
.IP
.nf
\f[C]
Named character classes (e.g. [\[rs]d], [\[ha]\[rs]d], [\[rs]D], [\[ha]\[rs]D])
Perl character classes (e.g. \[rs]s, \[rs]S, \[rs]w, \[rs]W)
ASCII character classes (e.g. [[:alnum:]], [[:alpha:]], [[:punct:]], [[:xdigit:]])
\f[R]
.fi
regexp for advanced users to insert a regular expression - see below for
more info:
Any re2 regular expression not containing \[ga]}}\[ga]
If the filter pattern starts with a \f[V]/\f[R] then it only matches at
the top level of the directory tree, \f[B]relative to the root of the
remote\f[R] (not necessarily the root of the drive).
If it does not start with \f[V]/\f[R] then it is matched starting at the
\f[B]end of the path/file name\f[R] but it only matches a complete path
element - it must match from a \f[V]/\f[R] separator or the beginning of
the path/file.
.IP
.nf
\f[C]
file.jpg   - matches \[dq]file.jpg\[dq]
           - matches \[dq]directory/file.jpg\[dq]
           - doesn\[aq]t match \[dq]afile.jpg\[dq]
           - doesn\[aq]t match \[dq]directory/afile.jpg\[dq]
/file.jpg  - matches \[dq]file.jpg\[dq] in the root directory of the remote
           - doesn\[aq]t match \[dq]afile.jpg\[dq]
           - doesn\[aq]t match \[dq]directory/file.jpg\[dq]
\f[R]
.fi
The top level of the remote might not be the top level of the drive.
E.g.
for a Microsoft Windows local directory structure
F:
 bkp
 data
    excl
       123.jpg
       456.jpg
    incl
       document.pdf
To copy the contents of folder \f[V]data\f[R] into folder \f[V]bkp\f[R]
excluding the contents of subfolder \f[V]excl\f[R]the following command
treats \f[V]F:\[rs]data\f[R] and \f[V]F:\[rs]bkp\f[R] as top level for
filtering.
\f[V]rclone copy F:\[rs]data\[rs] F:\[rs]bkp\[rs] --exclude=/excl/**\f[R]
\f[B]Important\f[R] Use \f[V]/\f[R] in path/file name patterns and not
\f[V]\[rs]\f[R] even if running on Microsoft Windows.
Simple patterns are case sensitive unless the \f[V]--ignore-case\f[R]
flag is used.
.PP
Without \f[V]--ignore-case\f[R] (default)
potato - matches \[dq]potato\[dq]
       - doesn\[aq]t match \[dq]POTATO\[dq]
.PP
With \f[V]--ignore-case\f[R]
potato - matches \[dq]potato\[dq]
       - matches \[dq]POTATO\[dq]
.SS Using regular expressions in filter patterns
.PP
The syntax of filter patterns is glob style matching (like
\f[V]bash\f[R] uses) to make things easy for users.
However this does not provide absolute control over the matching, so for
advanced users rclone also provides a regular expression syntax.
.PP
Rclone generally accepts Perl-style regular expressions, the exact
syntax is defined in the Go regular expression
reference (https://golang.org/pkg/regexp/syntax/).
Regular expressions should be enclosed in \f[V]{{\f[R] \f[V]}}\f[R].
They will match only the last path segment if the glob doesn\[aq]t start
with \f[V]/\f[R] or the whole path name if it does.
Note that rclone does not attempt to parse the supplied regular
expression, meaning that using any regular expression filter will
prevent rclone from using directory filter rules, as it will instead
check every path against the supplied regular expression(s).
.PP
Here is how the \f[V]{{regexp}}\f[R] is transformed into an full regular
expression to match the entire path:
{{regexp}}  becomes (\[ha]|/)(regexp)$
/{{regexp}} becomes \[ha](regexp)$
.PP
Regexp syntax can be mixed with glob syntax, for example
*.{{jpe?g}} to match file.jpg, file.jpeg but not file.png
.PP
You can also use regexp flags - to set case insensitive, for example
*.{{(?i)jpg}} to match file.jpg, file.JPG but not file.png
.PP
Be careful with wildcards in regular expressions - you don\[aq]t want
them to match path separators normally.
To match any file name starting with \f[V]start\f[R] and ending with
\f[V]end\f[R] write
{{start[\[ha]/]*end\[rs].jpg}}
Not
.IP
.nf
\f[C]
{{start.*end\[rs].jpg}}
\f[R]
.fi
Which will match a directory called \f[V]start\f[R] with a file called
\f[V]end.jpg\f[R] in it as the \f[V].*\f[R] will match \f[V]/\f[R]
characters.
Note that you can use \f[V]-vv --dump filters\f[R] to show the filter
patterns in regexp format - rclone implements the glob patterns by
transforming them into regular expressions.
.SS Filter pattern examples
.TS
tab(@);
lw(19.2n) lw(14.0n) lw(12.2n) lw(24.5n).
T{
Description
T}@T{
Pattern
T}@T{
Matches
T}@T{
Does not match
T}
_
T{
Wildcard
T}@T{
\f[V]*.jpg\f[R]
T}@T{
\f[V]/file.jpg\f[R]
T}@T{
\f[V]/file.png\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.jpg\f[R]
T}@T{
\f[V]/dir/file.png\f[R]
T}
T{
Rooted
T}@T{
\f[V]/*.jpg\f[R]
T}@T{
\f[V]/file.jpg\f[R]
T}@T{
\f[V]/file.png\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/file2.jpg\f[R]
T}@T{
\f[V]/dir/file.jpg\f[R]
T}
T{
Alternates
T}@T{
\f[V]*.{jpg,png}\f[R]
T}@T{
\f[V]/file.jpg\f[R]
T}@T{
\f[V]/file.gif\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.png\f[R]
T}@T{
\f[V]/dir/file.gif\f[R]
T}
T{
Path Wildcard
T}@T{
\f[V]dir/**\f[R]
T}@T{
\f[V]/dir/anyfile\f[R]
T}@T{
\f[V]file.png\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/subdir/dir/subsubdir/anyfile\f[R]
T}@T{
\f[V]/subdir/file.png\f[R]
T}
T{
Any Char
T}@T{
\f[V]*.t?t\f[R]
T}@T{
\f[V]/file.txt\f[R]
T}@T{
\f[V]/file.qxt\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.tzt\f[R]
T}@T{
\f[V]/dir/file.png\f[R]
T}
T{
Range
T}@T{
\f[V]*.[a-z]\f[R]
T}@T{
\f[V]/file.a\f[R]
T}@T{
\f[V]/file.0\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.b\f[R]
T}@T{
\f[V]/dir/file.1\f[R]
T}
T{
Escape
T}@T{
\f[V]*.\[rs]?\[rs]?\[rs]?\f[R]
T}@T{
\f[V]/file.???\f[R]
T}@T{
\f[V]/file.abc\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.???\f[R]
T}@T{
\f[V]/dir/file.def\f[R]
T}
T{
Class
T}@T{
\f[V]*.\[rs]d\[rs]d\[rs]d\f[R]
T}@T{
\f[V]/file.012\f[R]
T}@T{
\f[V]/file.abc\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.345\f[R]
T}@T{
\f[V]/dir/file.def\f[R]
T}
T{
Regexp
T}@T{
\f[V]*.{{jpe?g}}\f[R]
T}@T{
\f[V]/file.jpeg\f[R]
T}@T{
\f[V]/file.png\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/dir/file.jpg\f[R]
T}@T{
\f[V]/dir/file.jpeeg\f[R]
T}
T{
Rooted Regexp
T}@T{
\f[V]/{{.*\[rs].jpe?g}}\f[R]
T}@T{
\f[V]/file.jpeg\f[R]
T}@T{
\f[V]/file.png\f[R]
T}
T{
T}@T{
T}@T{
\f[V]/file.jpg\f[R]
T}@T{
\f[V]/dir/file.jpg\f[R]
T}
.TE
.SS How filter rules are applied to files
Rclone path/file name filters are made up of one or more of the
following flags:
\f[V]--exclude\f[R]
\f[V]--exclude-from\f[R]
\f[V]--filter\f[R]
\f[V]--filter-from\f[R]
There can be more than one instance of individual flags.
Rclone internally uses a combined list of all the include and exclude
rules.
The order in which rules are processed can influence the result of the
filter.
All flags of the same type are processed together in the order above,
regardless of what order the different types of flags are included on
the command line.
Multiple instances of the same flag are processed from left to right
according to their position in the command line.
To mix up the order of processing includes and excludes use
\f[V]--filter...\f[R] flags.
Within \f[V]--include-from\f[R], \f[V]--exclude-from\f[R] and
\f[V]--filter-from\f[R] flags rules are processed from top to bottom of
the referenced file.
If there is an \f[V]--include\f[R] or \f[V]--include-from\f[R] flag
specified, rclone implies a \f[V]- **\f[R] rule which it adds to the
bottom of the internal rule list.
Specifying a \f[V]+\f[R] rule with a \f[V]--filter...\f[R] flag does not
imply that rule.
Each path/file name passed through rclone is matched against the
combined filter list.
At first match to a rule the path/file name is included or excluded and
no further filter rules are processed for that path/file.
If rclone does not find a match, after testing against all rules
(including the implied rule if appropriate), the path/file name is
included.
Any path/file included at that stage is processed by the rclone command.
\f[V]--files-from\f[R] and \f[V]--files-from-raw\f[R] flags over-ride
and cannot be combined with other filter options.
To see the internal combined rule list, in regular expression form, for
a command add the \f[V]--dump filters\f[R] flag.
Running an rclone command with \f[V]--dump filters\f[R] and
\f[V]-vv\f[R] flags lists the internal filter elements and shows how
they are applied to each source path/file.
There is not currently a means provided to pass regular expression
filter options into rclone directly though character class filter rules
contain character classes.
Go regular expression reference (https://golang.org/pkg/regexp/syntax/)
.SS How filter rules are applied to directories
Rclone commands are applied to path/file names not directories.
The entire contents of a directory can be matched to a filter by the
pattern \f[V]directory/*\f[R] or recursively by \f[V]directory/**\f[R].
Directory filter rules are defined with a closing \f[V]/\f[R] separator.
E.g.
\f[V]/directory/subdirectory/\f[R] is an rclone directory filter rule.
Rclone commands can use directory filter rules to determine whether they
recurse into subdirectories.
This potentially optimises access to a remote by avoiding listing
unnecessary directories.
Whether optimisation is desirable depends on the specific filter rules
and source remote content.
If any regular expression filters are in use, then no directory
recursion optimisation is possible, as rclone must check every path
against the supplied regular expression(s).
Directory recursion optimisation occurs if either:
A source remote does not support the rclone \f[V]ListR\f[R] primitive.
local, sftp, Microsoft OneDrive and WebDAV do not support
\f[V]ListR\f[R].
Google Drive and most bucket type storage do.
Full list (https://rclone.org/overview/#optional-features)
On other remotes (those that support \f[V]ListR\f[R]), if the rclone
command is not naturally recursive, and provided it is not run with the
\f[V]--fast-list\f[R] flag.
\f[V]ls\f[R], \f[V]lsf -R\f[R] and \f[V]size\f[R] are naturally
recursive but \f[V]sync\f[R], \f[V]copy\f[R] and \f[V]move\f[R] are not.
Whenever the \f[V]--disable ListR\f[R] flag is applied to an rclone
command.
Rclone commands imply directory filter rules from path/file filter
rules.
To view the directory filter rules rclone has implied for a command
specify the \f[V]--dump filters\f[R] flag.
E.g.
for an include rule
.IP
.nf
\f[C]
/a/*.jpg
\f[R]
.fi
Rclone implies the directory include rule
.IP
.nf
\f[C]
/a/
\f[R]
.fi
Directory filter rules specified in an rclone command can limit the
scope of an rclone command but path/file filters still have to be
specified.
E.g.
\f[V]rclone ls remote: --include /directory/\f[R] will not match any
files.
Because it is an \f[V]--include\f[R] option the \f[V]--exclude **\f[R]
rule is implied, and the \f[V]/directory/\f[R] pattern serves only to
optimise access to the remote by ignoring everything outside of that
directory.
E.g.
\f[V]rclone ls remote: --filter-from filter-list.txt\f[R] with a file
\f[V]filter-list.txt\f[R]:
- /dir1/
- /dir2/
+ *.pdf
- **
All files in directories \f[V]dir1\f[R] or \f[V]dir2\f[R] or their
subdirectories are completely excluded from the listing.
Only files of suffix \f[V]pdf\f[R] in the root of \f[V]remote:\f[R] or
its subdirectories are listed.
The \f[V]- **\f[R] rule prevents listing of any path/files not
previously matched by the rules above.
Option \f[V]exclude-if-present\f[R] creates a directory exclude rule
based on the presence of a file in a directory and takes precedence over
other rclone directory filter rules.
.PP
When using pattern list syntax, if a pattern item contains either
\f[V]/\f[R] or \f[V]**\f[R], then rclone will not able to imply a
directory filter rule from this pattern list.
.PP
E.g.
for an include rule
{dir1/**,dir2/**}
Rclone will match files below directories \f[V]dir1\f[R] or
\f[V]dir2\f[R] only, but will not be able to use this filter to exclude
a directory \f[V]dir3\f[R] from being traversed.
Directory recursion optimisation may affect performance, but normally
not the result.
One exception to this is sync operations with option
\f[V]--create-empty-src-dirs\f[R], where any traversed empty directories
will be created.
With the pattern list example \f[V]{dir1/**,dir2/**}\f[R] above, this
would create an empty directory \f[V]dir3\f[R] on destination (when it
exists on source).
Changing the filter to \f[V]{dir1,dir2}/**\f[R], or splitting it into
two include rules \f[V]--include dir1/** --include dir2/**\f[R], will
match the same files while also filtering directories, with the result
that an empty directory \f[V]dir3\f[R] will no longer be created.
.SS \f[V]--exclude\f[R] - Exclude files matching pattern
.PP
Excludes path/file names from an rclone command based on a single
exclude rule.
.PP
This flag can be repeated.
See above for the order filter flags are processed in.
.PP
\f[V]--exclude\f[R] should not be used with \f[V]--include\f[R],
\f[V]--include-from\f[R], \f[V]--filter\f[R] or \f[V]--filter-from\f[R]
flags.
.PP
\f[V]--exclude\f[R] has no effect when combined with
\f[V]--files-from\f[R] or \f[V]--files-from-raw\f[R] flags.
.PP
E.g.
\f[V]rclone ls remote: --exclude *.bak\f[R] excludes all .bak files from
listing.
.PP
E.g.
\f[V]rclone size remote: --exclude \[dq]/dir/**\[dq]\f[R] returns the
total size of all files on \f[V]remote:\f[R] excluding those in root
directory \f[V]dir\f[R] and sub directories.
.PP
E.g.
on Microsoft Windows
\f[V]rclone ls remote: --exclude \[dq]*\[rs][{JP,KR,HK}\[rs]]*\[dq]\f[R]
lists the files in \f[V]remote:\f[R] without \f[V][JP]\f[R] or
\f[V][KR]\f[R] or \f[V][HK]\f[R] in their name.
Quotes prevent the shell from interpreting the \f[V]\[rs]\f[R]
characters.\f[V]\[rs]\f[R] characters escape the \f[V][\f[R] and
\f[V]]\f[R] so an rclone filter treats them literally rather than as a
character-range.
The \f[V]{\f[R] and \f[V]}\f[R] define an rclone pattern list.
For other operating systems single quotes are required ie
\f[V]rclone ls remote: --exclude \[aq]*\[rs][{JP,KR,HK}\[rs]]*\[aq]\f[R]
.SS \f[V]--exclude-from\f[R] - Read exclude patterns from file
.PP
Excludes path/file names from an rclone command based on rules in a
named file.
The file contains a list of remarks and pattern rules.
.PP
For an example \f[V]exclude-file.txt\f[R]:
# a sample exclude rule file
*.bak
file2.jpg
\f[V]rclone ls remote: --exclude-from exclude-file.txt\f[R] lists the
files on \f[V]remote:\f[R] except those named \f[V]file2.jpg\f[R] or
with a suffix \f[V].bak\f[R].
That is equivalent to
\f[V]rclone ls remote: --exclude file2.jpg --exclude \[dq]*.bak\[dq]\f[R].
This flag can be repeated.
See above for the order filter flags are processed in.
The \f[V]--exclude-from\f[R] flag is useful where multiple exclude
filter rules are applied to an rclone command.
\f[V]--exclude-from\f[R] should not be used with \f[V]--include\f[R],
\f[V]--include-from\f[R], \f[V]--filter\f[R] or \f[V]--filter-from\f[R]
flags.
\f[V]--exclude-from\f[R] has no effect when combined with
\f[V]--files-from\f[R] or \f[V]--files-from-raw\f[R] flags.
\f[V]--exclude-from\f[R] followed by \f[V]-\f[R] reads filter rules from
standard input.
.SS \f[V]--include\f[R] - Include files matching pattern
Adds a single include rule based on path/file names to an rclone
command.
This flag can be repeated.
See above for the order filter flags are processed in.
.PP
\f[V]--include\f[R] has no effect when combined with
\f[V]--files-from\f[R] or \f[V]--files-from-raw\f[R] flags.
.PP
\f[V]--include\f[R] implies \f[V]--exclude **\f[R] at the end of an
rclone internal filter list.
Therefore if you mix \f[V]--include\f[R] and \f[V]--include-from\f[R]
flags with \f[V]--exclude\f[R], \f[V]--exclude-from\f[R],
\f[V]--filter\f[R] or \f[V]--filter-from\f[R], you must use include
rules for all the files you want in the include statement.
For more flexibility use the \f[V]--filter-from\f[R] flag.
.PP
E.g.
\f[V]rclone ls remote: --include \[dq]*.{png,jpg}\[dq]\f[R] lists the
files on \f[V]remote:\f[R] with suffix \f[V].png\f[R] and
\f[V].jpg\f[R].
All other files are excluded.
.PP
E.g.
multiple rclone copy commands can be combined with \f[V]--include\f[R]
and a pattern-list.
rclone copy /vol1/A remote:A
rclone copy /vol1/B remote:B
is equivalent to:
rclone copy /vol1 remote: --include \[dq]{A,B}/**\[dq]
E.g.
\f[V]rclone ls remote:/wheat --include \[dq]??[\[ha][:punct:]]*\[dq]\f[R]
lists the files \f[V]remote:\f[R] directory \f[V]wheat\f[R] (and
subdirectories) whose third character is not punctuation.
This example uses an ASCII character
class (https://golang.org/pkg/regexp/syntax/).
.SS \f[V]--include-from\f[R] - Read include patterns from file
.PP
Adds path/file names to an rclone command based on rules in a named
file.
The file contains a list of remarks and pattern rules.
.PP
For an example \f[V]include-file.txt\f[R]:
# a sample include rule file
*.jpg
file2.avi
\f[V]rclone ls remote: --include-from include-file.txt\f[R] lists the
files on \f[V]remote:\f[R] with name \f[V]file2.avi\f[R] or suffix
\f[V].jpg\f[R].
That is equivalent to
\f[V]rclone ls remote: --include file2.avi --include \[dq]*.jpg\[dq]\f[R].
This flag can be repeated.
See above for the order filter flags are processed in.
.PP
The \f[V]--include-from\f[R] flag is useful where multiple include
filter rules are applied to an rclone command.
.PP
\f[V]--include-from\f[R] implies \f[V]--exclude **\f[R] at the end of an
rclone internal filter list.
Therefore if you mix \f[V]--include\f[R] and \f[V]--include-from\f[R]
flags with \f[V]--exclude\f[R], \f[V]--exclude-from\f[R],
\f[V]--filter\f[R] or \f[V]--filter-from\f[R], you must use include
rules for all the files you want in the include statement.
For more flexibility use the \f[V]--filter-from\f[R] flag.
.PP
\f[V]--include-from\f[R] has no effect when combined with
\f[V]--files-from\f[R] or \f[V]--files-from-raw\f[R] flags.
.PP
\f[V]--include-from\f[R] followed by \f[V]-\f[R] reads filter rules from
standard input.
.SS \f[V]--filter\f[R] - Add a file-filtering rule
.PP
Specifies path/file names to an rclone command, based on a single
include or exclude rule, in \f[V]+\f[R] or \f[V]-\f[R] format.
.PP
This flag can be repeated.
See above for the order filter flags are processed in.
.PP
\f[V]--filter +\f[R] differs from \f[V]--include\f[R].
In the case of \f[V]--include\f[R] rclone implies an
\f[V]--exclude *\f[R] rule which it adds to the bottom of the internal
rule list.
\f[V]--filter...+\f[R] does not imply that rule.
.PP
\f[V]--filter\f[R] has no effect when combined with
\f[V]--files-from\f[R] or \f[V]--files-from-raw\f[R] flags.
.PP
\f[V]--filter\f[R] should not be used with \f[V]--include\f[R],
\f[V]--include-from\f[R], \f[V]--exclude\f[R] or
\f[V]--exclude-from\f[R] flags.
.PP
E.g.
\f[V]rclone ls remote: --filter \[dq]- *.bak\[dq]\f[R] excludes all
\f[V].bak\f[R] files from a list of \f[V]remote:\f[R].
.SS \f[V]--filter-from\f[R] - Read filtering patterns from a file
.PP
Adds path/file names to an rclone command based on rules in a named
file.
The file contains a list of remarks and pattern rules.
Include rules start with \f[V]+\f[R] and exclude rules with \f[V]-\f[R].
\f[V]!\f[R] clears existing rules.
Rules are processed in the order they are defined.
.PP
This flag can be repeated.
See above for the order filter flags are processed in.
.PP
Arrange the order of filter rules with the most restrictive first and
work down.
.PP
Lines starting with # or ; are ignored, and can be used to write
comments.
Inline comments are not supported.
\f[I]Use \f[VI]-vv --dump filters\f[I] to see how they appear in the
final regexp.\f[R]
.PP
E.g.
for \f[V]filter-file.txt\f[R]:
# a sample filter rule file
- secret*.jpg
+ *.jpg
+ *.png
+ file2.avi
- /dir/tmp/** # WARNING! This text will be treated as part of the path.
- /dir/Trash/**
+ /dir/**
# exclude everything else
- *
\f[V]rclone ls remote: --filter-from filter-file.txt\f[R] lists the
path/files on \f[V]remote:\f[R] including all \f[V]jpg\f[R] and
\f[V]png\f[R] files, excluding any matching \f[V]secret*.jpg\f[R] and
including \f[V]file2.avi\f[R].
It also includes everything in the directory \f[V]dir\f[R] at the root
of \f[V]remote\f[R], except \f[V]remote:dir/Trash\f[R] which it
excludes.
Everything else is excluded.
.PP
E.g.
for an alternative \f[V]filter-file.txt\f[R]:
- secret*.jpg
+ *.jpg
+ *.png
+ file2.avi
- *
Files \f[V]file1.jpg\f[R], \f[V]file3.png\f[R] and \f[V]file2.avi\f[R]
are listed whilst \f[V]secret17.jpg\f[R] and files without the suffix
\f[V].jpg\f[R] or \f[V].png\f[R] are excluded.
E.g.
for an alternative \f[V]filter-file.txt\f[R]:
+ *.jpg
+ *.gif
!
+ 42.doc
- *
Only file 42.doc is listed.
Prior rules are cleared by the \f[V]!\f[R].
.SS \f[V]--files-from\f[R] - Read list of source-file names
Adds path/files to an rclone command from a list in a named file.
Rclone processes the path/file names in the order of the list, and no
others.
Other filter flags (\f[V]--include\f[R], \f[V]--include-from\f[R],
\f[V]--exclude\f[R], \f[V]--exclude-from\f[R], \f[V]--filter\f[R] and
\f[V]--filter-from\f[R]) are ignored when \f[V]--files-from\f[R] is
used.
\f[V]--files-from\f[R] expects a list of files as its input.
Leading or trailing whitespace is stripped from the input lines.
Lines starting with \f[V]#\f[R] or \f[V];\f[R] are ignored.
\f[V]--files-from\f[R] followed by \f[V]-\f[R] reads the list of files
from standard input.
Rclone commands with a \f[V]--files-from\f[R] flag traverse the remote,
treating the names in \f[V]--files-from\f[R] as a set of filters.
If the \f[V]--no-traverse\f[R] and \f[V]--files-from\f[R] flags are used
together an rclone command does not traverse the remote.
Instead it addresses each path/file named in the file individually.
For each path/file name, that requires typically 1 API call.
This can be efficient for a short \f[V]--files-from\f[R] list and a
remote containing many files.
Rclone commands do not error if any names in the \f[V]--files-from\f[R]
file are missing from the source remote.
The \f[V]--files-from\f[R] flag can be repeated in a single rclone
command to read path/file names from more than one file.
The files are read from left to right along the command line.
Paths within the \f[V]--files-from\f[R] file are interpreted as starting
with the root specified in the rclone command.
Leading \f[V]/\f[R] separators are ignored.
See --files-from-raw if you need the input to be processed in a raw
manner.
E.g.
for a file \f[V]files-from.txt\f[R]:
# comment
file1.jpg
subdir/file2.jpg
\f[V]rclone copy --files-from files-from.txt /home/me/pics remote:pics\f[R]
copies the following, if they exist, and only those files.
/home/me/pics/file1.jpg         remote:pics/file1.jpg
/home/me/pics/subdir/file2.jpg  remote:pics/subdir/file2.jpg
E.g.
to copy the following files referenced by their absolute paths:
/home/user1/42
/home/user1/dir/ford
/home/user2/prefect
First find a common subdirectory - in this case \f[V]/home\f[R] and put
the remaining files in \f[V]files-from.txt\f[R] with or without leading
\f[V]/\f[R], e.g.
user1/42
user1/dir/ford
user2/prefect
Then copy these to a remote:
rclone copy --files-from files-from.txt /home remote:backup
The three files are transferred as follows:
/home/user1/42        remote:backup/user1/important
/home/user1/dir/ford  remote:backup/user1/dir/file
/home/user2/prefect   remote:backup/user2/stuff
Alternatively if \f[V]/\f[R] is chosen as root \f[V]files-from.txt\f[R]
will be:
.IP
.nf
\f[C]
/home/user1/42
/home/user1/dir/ford
/home/user2/prefect
\f[R]
.fi
The copy command will be:
rclone copy --files-from files-from.txt / remote:backup
Then there will be an extra \f[V]home\f[R] directory on the remote:
.IP
.nf
\f[C]
/home/user1/42        remote:backup/home/user1/42
/home/user1/dir/ford  remote:backup/home/user1/dir/ford
/home/user2/prefect   remote:backup/home/user2/prefect
\f[R]
.fi
.SS \f[V]--files-from-raw\f[R] - Read list of source-file names without any processing
This flag is the same as \f[V]--files-from\f[R] except that input is
read in a raw manner.
Lines with leading / trailing whitespace, and lines starting with
\f[V];\f[R] or \f[V]#\f[R] are read without any processing.
rclone lsf (https://rclone.org/commands/rclone_lsf/) has a compatible
format that can be used to export file lists from remotes for input to
\f[V]--files-from-raw\f[R].
.SS \f[V]--ignore-case\f[R] - make searches case insensitive
By default, rclone filter patterns are case sensitive.
The \f[V]--ignore-case\f[R] flag makes all of the filters patterns on
the command line case insensitive.
E.g.
\f[V]--include \[dq]zaphod.txt\[dq]\f[R] does not match a file
\f[V]Zaphod.txt\f[R].
With \f[V]--ignore-case\f[R] a match is made.
.SS Quoting shell metacharacters
Rclone commands with filter patterns containing shell metacharacters may
not as work as expected in your shell and may require quoting.
.PP
E.g.
linux, OSX (\f[V]*\f[R] metacharacter)
.IP \[bu] 2
\f[V]--include \[rs]*.jpg\f[R]
.IP \[bu] 2
\f[V]--include \[aq]*.jpg\[aq]\f[R]
.IP \[bu] 2
\f[V]--include=\[aq]*.jpg\[aq]\f[R]
.PP
Microsoft Windows expansion is done by the command, not shell, so
\f[V]--include *.jpg\f[R] does not require quoting.
.PP
If the rclone error
\f[V]Command .... needs .... arguments maximum: you provided .... non flag arguments:\f[R]
is encountered, the cause is commonly spaces within the name of a remote
or flag value.
The fix then is to quote values containing spaces.
.SS Other filters
.SS \f[V]--min-size\f[R] - Don\[aq]t transfer any file smaller than this
.PP
Controls the minimum size file within the scope of an rclone command.
Default units are \f[V]KiB\f[R] but abbreviations \f[V]B\f[R],
\f[V]K\f[R], \f[V]M\f[R], \f[V]G\f[R], \f[V]T\f[R] or \f[V]P\f[R] are
valid.
.PP
E.g.
\f[V]rclone ls remote: --min-size 50k\f[R] lists files on
\f[V]remote:\f[R] of 50 KiB size or larger.
.PP
See the size option docs (https://rclone.org/docs/#size-options) for
more info.
.SS \f[V]--max-size\f[R] - Don\[aq]t transfer any file larger than this
.PP
Controls the maximum size file within the scope of an rclone command.
Default units are \f[V]KiB\f[R] but abbreviations \f[V]B\f[R],
\f[V]K\f[R], \f[V]M\f[R], \f[V]G\f[R], \f[V]T\f[R] or \f[V]P\f[R] are
valid.
.PP
E.g.
\f[V]rclone ls remote: --max-size 1G\f[R] lists files on
\f[V]remote:\f[R] of 1 GiB size or smaller.
.PP
See the size option docs (https://rclone.org/docs/#size-options) for
more info.
.SS \f[V]--max-age\f[R] - Don\[aq]t transfer any file older than this
.PP
Controls the maximum age of files within the scope of an rclone command.
.PP
\f[V]--max-age\f[R] applies only to files and not to directories.
.PP
E.g.
\f[V]rclone ls remote: --max-age 2d\f[R] lists files on
\f[V]remote:\f[R] of 2 days old or less.
.PP
See the time option docs (https://rclone.org/docs/#time-options) for
valid formats.
.SS \f[V]--min-age\f[R] - Don\[aq]t transfer any file younger than this
.PP
Controls the minimum age of files within the scope of an rclone command.
(see \f[V]--max-age\f[R] for valid formats)
.PP
\f[V]--min-age\f[R] applies only to files and not to directories.
.PP
E.g.
\f[V]rclone ls remote: --min-age 2d\f[R] lists files on
\f[V]remote:\f[R] of 2 days old or more.
.PP
See the time option docs (https://rclone.org/docs/#time-options) for
valid formats.
.SS \f[V]--hash-filter\f[R] - Deterministically select a subset of files
.PP
The \f[V]--hash-filter\f[R] flag enables selecting a deterministic
subset of files, useful for:
.IP "1." 3
Running large sync operations across multiple machines.
.IP "2." 3
Checking a subset of files for bitrot.
.IP "3." 3
Any other operations where a sample of files is required.
.SS Syntax
.PP
The flag takes two parameters expressed as a fraction:
--hash-filter K/N
.IP \[bu] 2
\f[V]N\f[R]: The total number of partitions (must be a positive
integer).
.IP \[bu] 2
\f[V]K\f[R]: The specific partition to select (an integer from
\f[V]0\f[R] to \f[V]N\f[R]).
For example:
.IP \[bu] 2
\f[V]--hash-filter 1/3\f[R]: Selects the first third of the files.
.IP \[bu] 2
\f[V]--hash-filter 2/3\f[R] and \f[V]--hash-filter 3/3\f[R]: Select the
second and third partitions, respectively.
.PP
Each partition is non-overlapping, ensuring all files are covered
without duplication.
.SS Random Partition Selection
.PP
Use \f[V]\[at]\f[R] as \f[V]K\f[R] to randomly select a partition:
--hash-filter \[at]/M
For example, \f[V]--hash-filter \[at]/3\f[R] will randomly select a
number between 0 and 2.
This will stay constant across retries.
.SS How It Works
.IP \[bu] 2
Rclone takes each file\[aq]s full path, normalizes it to lowercase, and
applies Unicode normalization.
.IP \[bu] 2
It then hashes the normalized path into a 64 bit number.
.IP \[bu] 2
The hash result is reduced modulo \f[V]N\f[R] to assign the file to a
partition.
.IP \[bu] 2
If the calculated partition does not match \f[V]K\f[R] the file is
excluded.
.IP \[bu] 2
Other filters may apply if the file is not excluded.
\f[B]Important:\f[R] Rclone will traverse all directories to apply the
filter.
.SS Usage Notes
.IP \[bu] 2
Safe to use with \f[V]rclone sync\f[R]; source and destination
selections will match.
.IP \[bu] 2
\f[B]Do not\f[R] use with \f[V]--delete-excluded\f[R], as this could
delete unselected files.
.IP \[bu] 2
Ignored if \f[V]--files-from\f[R] is used.
.SS Examples
.SS Dividing files into 4 partitions
Assuming the current directory contains \f[V]file1.jpg\f[R] through
\f[V]file9.jpg\f[R]:
$ rclone lsf --hash-filter 0/4 .
file1.jpg
file5.jpg

$ rclone lsf --hash-filter 1/4 .
file3.jpg
file6.jpg
file9.jpg

$ rclone lsf --hash-filter 2/4 .
file2.jpg
file4.jpg

$ rclone lsf --hash-filter 3/4 .
file7.jpg
file8.jpg

$ rclone lsf --hash-filter 4/4 . # the same as --hash-filter 0/4
file1.jpg
file5.jpg
\f[R]
.fi
.SS Syncing the first quarter of files
.IP
.nf
\f[C]
rclone sync --hash-filter 1/4 source:path destination:path
\f[R]
.fi
.SS Checking a random 1% of files for integrity
.IP
.nf
\f[C]
rclone check --download --hash-filter \[at]/100 source:path destination:path
.SS Other flags
.SS \f[V]--delete-excluded\f[R] - Delete files on dest excluded from sync
\f[B]Important\f[R] this flag is dangerous to your data - use with
\f[V]--dry-run\f[R] and \f[V]-v\f[R] first.
.PP
In conjunction with \f[V]rclone sync\f[R], \f[V]--delete-excluded\f[R]
deletes any files on the destination which are excluded from the
command.
.PP
E.g.
the scope of \f[V]rclone sync --interactive A: B:\f[R] can be
restricted:
rclone --min-size 50k --delete-excluded sync A: B:
All files on \f[V]B:\f[R] which are less than 50 KiB are deleted because
they are excluded from the rclone sync command.
.SS \f[V]--dump filters\f[R] - dump the filters to the output
.PP
Dumps the defined filters to standard output in regular expression
format.
.PP
Useful for debugging.
.SS Exclude directory based on a file
.PP
The \f[V]--exclude-if-present\f[R] flag controls whether a directory is
within the scope of an rclone command based on the presence of a named
file within it.
The flag can be repeated to check for multiple file names, presence of
any of them will exclude the directory.
.PP
This flag has a priority over other filter flags.
.PP
E.g.
for the following directory structure:
dir1/file1
dir1/dir2/file2
dir1/dir2/dir3/file3
dir1/dir2/dir3/.ignore
The command \f[V]rclone ls --exclude-if-present .ignore dir1\f[R] does
not list \f[V]dir3\f[R], \f[V]file3\f[R] or \f[V].ignore\f[R].
.SS Metadata filters
.PP
The metadata filters work in a very similar way to the normal file name
filters, except they match metadata (https://rclone.org/docs/#metadata)
on the object.
.PP
The metadata should be specified as \f[V]key=value\f[R] patterns.
This may be wildcarded using the normal filter patterns or regular
expressions.
.PP
For example if you wished to list only local files with a mode of
\f[V]100664\f[R] you could do that with:
rclone lsf -M --files-only --metadata-include \[dq]mode=100664\[dq] .
Or if you wished to show files with an \f[V]atime\f[R], \f[V]mtime\f[R]
or \f[V]btime\f[R] at a given date:
rclone lsf -M --files-only --metadata-include \[dq][abm]time=2022-12-16*\[dq] .
Like file filtering, metadata filtering only applies to files not to
directories.
The filters can be applied using these flags.
.IP \[bu] 2
\f[V]--metadata-include\f[R] - Include metadatas matching pattern
.IP \[bu] 2
\f[V]--metadata-include-from\f[R] - Read metadata include patterns from
file (use - to read from stdin)
.IP \[bu] 2
\f[V]--metadata-exclude\f[R] - Exclude metadatas matching pattern
.IP \[bu] 2
\f[V]--metadata-exclude-from\f[R] - Read metadata exclude patterns from
file (use - to read from stdin)
.IP \[bu] 2
\f[V]--metadata-filter\f[R] - Add a metadata filtering rule
.IP \[bu] 2
\f[V]--metadata-filter-from\f[R] - Read metadata filtering patterns from
a file (use - to read from stdin)
Each flag can be repeated.
See the section on how filter rules are applied for more details - these
flags work in an identical way to the file name filtering flags, but
instead of file name patterns have metadata patterns.
.SS Common pitfalls
The most frequent filter support issues on the rclone
forum (https://forum.rclone.org/) are:
Not using paths relative to the root of the remote
Not using \f[V]/\f[R] to match from the root of a remote
Not using \f[V]**\f[R] to match the contents of a directory
.SH GUI (Experimental)
Rclone can serve a web based GUI (graphical user interface).
This is somewhat experimental at the moment so things may be subject to
change.
Run this command in a terminal and rclone will download and then display
the GUI in a web browser.
.IP
.nf
\f[C]
rclone rcd --rc-web-gui
\f[R]
.fi
This will produce logs like this and rclone needs to continue to run to
serve the GUI:
.IP
.nf
\f[C]
2019/08/25 11:40:14 NOTICE: A new release for gui is present at https://github.com/rclone/rclone-webui-react/releases/download/v0.0.6/currentbuild.zip
2019/08/25 11:40:14 NOTICE: Downloading webgui binary. Please wait. [Size: 3813937, Path :  /home/USER/.cache/rclone/webgui/v0.0.6.zip]
2019/08/25 11:40:16 NOTICE: Unzipping
2019/08/25 11:40:16 NOTICE: Serving remote control on http://127.0.0.1:5572/
\f[R]
.fi
This assumes you are running rclone locally on your machine.
It is possible to separate the rclone and the GUI - see below for
details.
If you wish to check for updates then you can add
\f[V]--rc-web-gui-update\f[R] to the command line.
If you find your GUI broken, you may force it to update by add
\f[V]--rc-web-gui-force-update\f[R].
By default, rclone will open your browser.
Add \f[V]--rc-web-gui-no-open-browser\f[R] to disable this feature.
.SS Using the GUI
Once the GUI opens, you will be looking at the dashboard which has an
overall overview.
On the left hand side you will see a series of view buttons you can
click on:
.IP \[bu] 2
Dashboard - main overview
.IP \[bu] 2
Configs - examine and create new configurations
.IP \[bu] 2
Explorer - view, download and upload files to the cloud storage systems
.IP \[bu] 2
Backend - view or alter the backend config
.IP \[bu] 2
Log out
(More docs and walkthrough video to come!)
.SS How it works
When you run the \f[V]rclone rcd --rc-web-gui\f[R] this is what happens
.IP \[bu] 2
Rclone starts but only runs the remote control API (\[dq]rc\[dq]).
.IP \[bu] 2
The API is bound to localhost with an auto-generated username and
password.
.IP \[bu] 2
If the API bundle is missing then rclone will download it.
.IP \[bu] 2
rclone will start serving the files from the API bundle over the same
port as the API
.IP \[bu] 2
rclone will open the browser with a \f[V]login_token\f[R] so it can log
straight in.
.SS Advanced use
The \f[V]rclone rcd\f[R] may use any of the flags documented on the rc
page (https://rclone.org/rc/#supported-parameters).
The flag \f[V]--rc-web-gui\f[R] is shorthand for
.IP \[bu] 2
Download the web GUI if necessary
.IP \[bu] 2
Check we are using some authentication
.IP \[bu] 2
\f[V]--rc-user gui\f[R]
.IP \[bu] 2
\f[V]--rc-pass <random password>\f[R]
.IP \[bu] 2
\f[V]--rc-serve\f[R]
These flags can be overridden as desired.
See also the rclone rcd
documentation (https://rclone.org/commands/rclone_rcd/).
.SS Example: Running a public GUI
For example the GUI could be served on a public port over SSL using an
htpasswd file using the following flags:
\f[V]--rc-web-gui\f[R]
\f[V]--rc-addr :443\f[R]
\f[V]--rc-htpasswd /path/to/htpasswd\f[R]
.IP \[bu] 2
\f[V]--rc-cert /path/to/ssl.crt\f[R]
.IP \[bu] 2
\f[V]--rc-key /path/to/ssl.key\f[R]
.SS Example: Running a GUI behind a proxy
If you want to run the GUI behind a proxy at \f[V]/rclone\f[R] you could
use these flags:
.IP \[bu] 2
\f[V]--rc-web-gui\f[R]
.IP \[bu] 2
\f[V]--rc-baseurl rclone\f[R]
.IP \[bu] 2
\f[V]--rc-htpasswd /path/to/htpasswd\f[R]
Or instead of htpasswd if you just want a single user and password:
.IP \[bu] 2
\f[V]--rc-user me\f[R]
.IP \[bu] 2
\f[V]--rc-pass mypassword\f[R]
.SS Project
The GUI is being developed in the: rclone/rclone-webui-react
repository (https://github.com/rclone/rclone-webui-react).
Bug reports and contributions are very welcome :-)
If you have questions then please ask them on the rclone
forum (https://forum.rclone.org/).
.SH Remote controlling rclone with its API
If rclone is run with the \f[V]--rc\f[R] flag then it starts an HTTP
server which can be used to remote control rclone using its API.
You can either use the rc command to access the API or use HTTP
directly.
If you just want to run a remote control then see the
rcd (https://rclone.org/commands/rclone_rcd/) command.
.SS Supported parameters
.SS --rc
Flag to start the http server listen on remote requests.
.SS --rc-addr=IP
IPaddress:Port or :Port to bind server to.
(default \[dq]localhost:5572\[dq]).
.SS --rc-cert=KEY
SSL PEM key (concatenation of certificate and CA certificate).
.SS --rc-client-ca=PATH
Client certificate authority to verify clients with.
.SS --rc-htpasswd=PATH
htpasswd file - if not provided no authentication is done.
.SS --rc-key=PATH
TLS PEM private key file.
.SS --rc-max-header-bytes=VALUE
Maximum size of request header (default 4096).
.SS --rc-min-tls-version=VALUE
The minimum TLS version that is acceptable.
Valid values are \[dq]tls1.0\[dq], \[dq]tls1.1\[dq], \[dq]tls1.2\[dq]
and \[dq]tls1.3\[dq] (default \[dq]tls1.0\[dq]).
.SS --rc-user=VALUE
User name for authentication.
.SS --rc-pass=VALUE
Password for authentication.
.SS --rc-realm=VALUE
Realm for authentication (default \[dq]rclone\[dq]).
.SS --rc-server-read-timeout=DURATION
Timeout for server reading data (default 1h0m0s).
.SS --rc-server-write-timeout=DURATION
Timeout for server writing data (default 1h0m0s).
.SS --rc-serve
Enable the serving of remote objects via the HTTP interface.
This means objects will be accessible at
\f[V]http://127.0.0.1:5572/\f[R] by default, so you can browse to
\f[V]http://127.0.0.1:5572/\f[R] or \f[V]http://127.0.0.1:5572/*\f[R] to
see a listing of the remotes.
Objects may be requested from remotes using this syntax
\f[V]http://127.0.0.1:5572/[remote:path]/path/to/object\f[R]
Default Off.
.SS --rc-serve-no-modtime
Set this flag to skip reading the modification time (can speed things
up).
Default Off.
.SS --rc-files /path/to/directory
Path to local files to serve on the HTTP server.
If this is set then rclone will serve the files in that directory.
It will also open the root in the web browser if specified.
This is for implementing browser based GUIs for rclone functions.
If \f[V]--rc-user\f[R] or \f[V]--rc-pass\f[R] is set then the URL that
is opened will have the authorization in the URL in the
\f[V]http://user:pass\[at]localhost/\f[R] style.
Default Off.
.SS --rc-enable-metrics
Enable OpenMetrics/Prometheus compatible endpoint at \f[V]/metrics\f[R].
If more control over the metrics is desired (for example running it on a
different port or with different auth) then endpoint can be enabled with
the \f[V]--metrics-*\f[R] flags instead.
Default Off.
.SS --rc-web-gui
Set this flag to serve the default web gui on the same port as rclone.
Default Off.
.SS --rc-allow-origin
Set the allowed Access-Control-Allow-Origin for rc requests.
Can be used with --rc-web-gui if the rclone is running on different IP
than the web-gui.
Default is IP address on which rc is running.
.SS --rc-web-fetch-url
Set the URL to fetch the rclone-web-gui files from.
Default
<https://api.github.com/repos/rclone/rclone-webui-react/releases/latest>.
.SS --rc-web-gui-update
Set this flag to check and update rclone-webui-react from the
rc-web-fetch-url.
Default Off.
.SS --rc-web-gui-force-update
Set this flag to force update rclone-webui-react from the
rc-web-fetch-url.
Default Off.
.SS --rc-web-gui-no-open-browser
Set this flag to disable opening browser automatically when using
web-gui.
Default Off.
.SS --rc-job-expire-duration=DURATION
Expire finished async jobs older than DURATION (default 60s).
.SS --rc-job-expire-interval=DURATION
Interval duration to check for expired async jobs (default 10s).
.SS --rc-no-auth
By default rclone will require authorisation to have been set up on the
rc interface in order to use any methods which access any rclone
remotes.
Eg \f[V]operations/list\f[R] is denied as it involved creating a remote
as is \f[V]sync/copy\f[R].
If this is set then no authorisation will be required on the server to
use these methods.
The alternative is to use \f[V]--rc-user\f[R] and \f[V]--rc-pass\f[R]
and use these credentials in the request.
Default Off.
.SS --rc-baseurl
Prefix for URLs.
Default is root
.SS --rc-template
User-specified template.
.SS Accessing the remote control via the rclone rc command
Rclone itself implements the remote control protocol in its
\f[V]rclone rc\f[R] command.
You can use it like this:
$ rclone rc rc/noop param1=one param2=two
{
    \[dq]param1\[dq]: \[dq]one\[dq],
    \[dq]param2\[dq]: \[dq]two\[dq]
}
If the remote is running on a different URL than the default
\f[V]http://localhost:5572/\f[R], use the \f[V]--url\f[R] option to
specify it:
.IP
.nf
\f[C]
rclone rc --url http://some.remote:1234/ rc/noop
\f[R]
.fi
Or, if the remote is listening on a Unix socket, use the
\f[V]--unix-socket\f[R] option instead:
rclone rc --unix-socket /tmp/rclone.sock rc/noop
Run \f[V]rclone rc\f[R] on its own, without any commands, to see the
help for the installed remote control commands.
Note that this also needs to connect to the remote server.
.SS JSON input
\f[V]rclone rc\f[R] also supports a \f[V]--json\f[R] flag which can be
used to send more complicated input parameters.
$ rclone rc --json \[aq]{ \[dq]p1\[dq]: [1,\[dq]2\[dq],null,4], \[dq]p2\[dq]: { \[dq]a\[dq]:1, \[dq]b\[dq]:2 } }\[aq] rc/noop
{
    \[dq]p1\[dq]: [
        1,
        \[dq]2\[dq],
        null,
        4
    ],
    \[dq]p2\[dq]: {
        \[dq]a\[dq]: 1,
        \[dq]b\[dq]: 2
    }
}
If the parameter being passed is an object then it can be passed as a
JSON string rather than using the \f[V]--json\f[R] flag which simplifies
the command line.
.IP
.nf
\f[C]
rclone rc operations/list fs=/tmp remote=test opt=\[aq]{\[dq]showHash\[dq]: true}\[aq]
\f[R]
.fi
Rather than
.IP
.nf
\f[C]
rclone rc operations/list --json \[aq]{\[dq]fs\[dq]: \[dq]/tmp\[dq], \[dq]remote\[dq]: \[dq]test\[dq], \[dq]opt\[dq]: {\[dq]showHash\[dq]: true}}\[aq]
\f[R]
.fi
.SS Special parameters
The rc interface supports some special parameters which apply to
\f[B]all\f[R] commands.
These start with \f[V]_\f[R] to show they are different.
.SS Running asynchronous jobs with _async = true
Each rc call is classified as a job and it is assigned its own id.
By default jobs are executed immediately as they are created or
synchronously.
If \f[V]_async\f[R] has a true value when supplied to an rc call then it
will return immediately with a job id and execute id, and the task will
be run in the background.
The \f[V]job/status\f[R] call can be used to get information of the
background job.
The job can be queried for up to 1 minute after it has finished.
It is recommended that potentially long running jobs, e.g.
\f[V]sync/sync\f[R], \f[V]sync/copy\f[R], \f[V]sync/move\f[R],
\f[V]operations/purge\f[R] are run with the \f[V]_async\f[R] flag to
avoid any potential problems with the HTTP request and response timing
out.
Starting a job with the \f[V]_async\f[R] flag:
.IP
.nf
\f[C]
$ rclone rc --json \[aq]{ \[dq]p1\[dq]: [1,\[dq]2\[dq],null,4], \[dq]p2\[dq]: { \[dq]a\[dq]:1, \[dq]b\[dq]:2 }, \[dq]_async\[dq]: true }\[aq] rc/noop
{
    \[dq]jobid\[dq]: 2,
    \[dq]executeId\[dq]: \[dq]d794c33c-463e-4acf-b911-f4b23e4f40b7\[dq]
}
\f[R]
.fi
The \f[V]jobid\f[R] is a unique identifier for the job within this
rclone instance.
The \f[V]executeId\f[R] identifies the rclone process instance and
changes after rclone restart.
Together, the pair (\f[V]executeId\f[R], \f[V]jobid\f[R]) uniquely
identifies a job across rclone restarts.
Query the status to see if the job has finished.
For more information on the meaning of these return parameters see the
\f[V]job/status\f[R] call.
.IP
.nf
\f[C]
$ rclone rc --json \[aq]{ \[dq]jobid\[dq]:2 }\[aq] job/status
{
    \[dq]duration\[dq]: 0.000124163,
    \[dq]endTime\[dq]: \[dq]2018-10-27T11:38:07.911245881+01:00\[dq],
    \[dq]error\[dq]: \[dq]\[dq],
    \[dq]executeId\[dq]: \[dq]d794c33c-463e-4acf-b911-f4b23e4f40b7\[dq],
    \[dq]finished\[dq]: true,
    \[dq]id\[dq]: 2,
    \[dq]output\[dq]: {
        \[dq]_async\[dq]: true,
        \[dq]p1\[dq]: [
            1,
            \[dq]2\[dq],
            null,
            4
        ],
        \[dq]p2\[dq]: {
            \[dq]a\[dq]: 1,
            \[dq]b\[dq]: 2
        }
    },
    \[dq]startTime\[dq]: \[dq]2018-10-27T11:38:07.911121728+01:00\[dq],
    \[dq]success\[dq]: true
}
\f[R]
.fi
\f[V]job/list\f[R] can be used to show running or recently completed
jobs along with their status
.IP
.nf
\f[C]
$ rclone rc job/list
{
    \[dq]executeId\[dq]: \[dq]d794c33c-463e-4acf-b911-f4b23e4f40b7\[dq],
    \[dq]finished_ids\[dq]: [
        1
    ],
    \[dq]jobids\[dq]: [
        1,
        2
    ],
    \[dq]running_ids\[dq]: [
        2
    ]
}
\f[R]
.fi
This shows: - \f[V]executeId\f[R] - the current rclone instance ID (same
for all jobs, changes after restart) - \f[V]jobids\f[R] - array of all
job IDs (both running and finished) - \f[V]running_ids\f[R] - array of
currently running job IDs - \f[V]finished_ids\f[R] - array of finished
job IDs
.SS Setting config flags with _config
.PP
If you wish to set config (the equivalent of the global flags) for the
duration of an rc call only then pass in the \f[V]_config\f[R]
parameter.
.PP
This should be in the same format as the \f[V]main\f[R] key returned by
options/get.
rclone rc --loopback options/get blocks=main
You can see more help on these options with this command (see the
options blocks section for more info).
rclone rc --loopback options/info blocks=main
For example, if you wished to run a sync with the \f[V]--checksum\f[R]
parameter, you would pass this parameter in your JSON blob.
\[dq]_config\[dq]:{\[dq]CheckSum\[dq]: true}
If using \f[V]rclone rc\f[R] this could be passed as
rclone rc sync/sync ... _config=\[aq]{\[dq]CheckSum\[dq]: true}\[aq]
Any config parameters you don\[aq]t set will inherit the global defaults
which were set with command line flags or environment variables.
.PP
Note that it is possible to set some values as strings or integers - see
data types for more info.
Here is an example setting the equivalent of \f[V]--buffer-size\f[R] in
string or integer format.
\[dq]_config\[dq]:{\[dq]BufferSize\[dq]: \[dq]42M\[dq]}
\[dq]_config\[dq]:{\[dq]BufferSize\[dq]: 44040192}
If you wish to check the \f[V]_config\f[R] assignment has worked
properly then calling \f[V]options/local\f[R] will show what the value
got set to.
.SS Setting filter flags with _filter
.PP
If you wish to set filters for the duration of an rc call only then pass
in the \f[V]_filter\f[R] parameter.
.PP
This should be in the same format as the \f[V]filter\f[R] key returned
by options/get.
rclone rc --loopback options/get blocks=filter
You can see more help on these options with this command (see the
options blocks section for more info).
rclone rc --loopback options/info blocks=filter
For example, if you wished to run a sync with these flags
--max-size 1M --max-age 42s --include \[dq]a\[dq] --include \[dq]b\[dq]
you would pass this parameter in your JSON blob.
\[dq]_filter\[dq]:{\[dq]MaxSize\[dq]:\[dq]1M\[dq], \[dq]IncludeRule\[dq]:[\[dq]a\[dq],\[dq]b\[dq]], \[dq]MaxAge\[dq]:\[dq]42s\[dq]}
If using \f[V]rclone rc\f[R] this could be passed as
.IP
.nf
\f[C]
rclone rc ... _filter=\[aq]{\[dq]MaxSize\[dq]:\[dq]1M\[dq], \[dq]IncludeRule\[dq]:[\[dq]a\[dq],\[dq]b\[dq]], \[dq]MaxAge\[dq]:\[dq]42s\[dq]}\[aq]
\f[R]
.fi
Any filter parameters you don\[aq]t set will inherit the global defaults
which were set with command line flags or environment variables.
Note that it is possible to set some values as strings or integers - see
data types for more info.
Here is an example setting the equivalent of \f[V]--buffer-size\f[R] in
string or integer format.
.IP
.nf
\f[C]
\[dq]_filter\[dq]:{\[dq]MinSize\[dq]: \[dq]42M\[dq]}
\[dq]_filter\[dq]:{\[dq]MinSize\[dq]: 44040192}
\f[R]
.fi
If you wish to check the \f[V]_filter\f[R] assignment has worked
properly then calling \f[V]options/local\f[R] will show what the value
got set to.
.SS Assigning operations to groups with _group = value
Each rc call has its own stats group for tracking its metrics.
By default grouping is done by the composite group name from prefix
\f[V]job/\f[R] and id of the job like so \f[V]job/1\f[R].
If \f[V]_group\f[R] has a value then stats for that request will be
grouped under that value.
This allows caller to group stats under their own name.
Stats for specific group can be accessed by passing \f[V]group\f[R] to
\f[V]core/stats\f[R]:
.IP
.nf
\f[C]
$ rclone rc --json \[aq]{ \[dq]group\[dq]: \[dq]job/1\[dq] }\[aq] core/stats
{
    \[dq]speed\[dq]: 12345
    ...
}
\f[R]
.fi
.SS Data types
When the API returns types, these will mostly be straight forward
integer, string or boolean types.
However some of the types returned by the options/get call and taken by
the options/set calls as well as the \f[V]vfsOpt\f[R],
\f[V]mountOpt\f[R] and the \f[V]_config\f[R] parameters.
.IP \[bu] 2
\f[V]Duration\f[R] - these are returned as an integer duration in
nanoseconds.
They may be set as an integer, or they may be set with time string, eg
\[dq]5s\[dq].
See the options section (https://rclone.org/docs/#options) for more
info.
.IP \[bu] 2
\f[V]Size\f[R] - these are returned as an integer number of bytes.
They may be set as an integer or they may be set with a size suffix
string, eg \[dq]10M\[dq].
See the options section (https://rclone.org/docs/#options) for more
info.
.IP \[bu] 2
Enumerated type (such as \f[V]CutoffMode\f[R], \f[V]DumpFlags\f[R],
\f[V]LogLevel\f[R], \f[V]VfsCacheMode\f[R] - these will be returned as
an integer and may be set as an integer but more conveniently they can
be set as a string, eg \[dq]HARD\[dq] for \f[V]CutoffMode\f[R] or
\f[V]DEBUG\f[R] for \f[V]LogLevel\f[R].
.IP \[bu] 2
\f[V]BandwidthSpec\f[R] - this will be set and returned as a string, eg
\[dq]1M\[dq].
.SS Option blocks
The calls options/info (for the main config) and config/providers (for
the backend config) may be used to get information on the rclone
configuration options.
This can be used to build user interfaces for displaying and setting any
rclone option.
These consist of arrays of \f[V]Option\f[R] blocks.
These have the following format.
Each block describes a single option.
.TS
tab(@);
lw(13.6n) lw(11.7n) lw(19.4n) lw(25.3n).
T{
Field
T}@T{
Type
T}@T{
Optional
T}@T{
Description
T}
_
T{
Name
T}@T{
string
T}@T{
N
T}@T{
name of the option in snake_case
T}
T{
FieldName
T}@T{
string
T}@T{
N
T}@T{
name of the field used in the rc - if blank use Name.
May contain \[dq].\[dq] for nested fields.
T}
T{
Help
T}@T{
string
T}@T{
N
T}@T{
help, started with a single sentence on a single line
T}
T{
Groups
T}@T{
string
T}@T{
Y
T}@T{
groups this option belongs to - comma separated string for options
classification
T}
T{
Provider
T}@T{
string
T}@T{
Y
T}@T{
set to filter on provider
T}
T{
Default
T}@T{
any
T}@T{
N
T}@T{
default value, if set (and not to nil or \[dq]\[dq]) then Required does
nothing
T}
T{
Value
T}@T{
any
T}@T{
N
T}@T{
value to be set by flags
T}
T{
Examples
T}@T{
Examples
T}@T{
Y
T}@T{
predefined values that can be selected from list (multiple-choice
option)
T}
T{
ShortOpt
T}@T{
string
T}@T{
Y
T}@T{
the short command line option for this
T}
T{
Hide
T}@T{
Visibility
T}@T{
N
T}@T{
if non zero, this option is hidden from the configurator or the command
line
T}
T{
Required
T}@T{
bool
T}@T{
N
T}@T{
this option is required, meaning value cannot be empty unless there is a
default
T}
T{
IsPassword
T}@T{
bool
T}@T{
N
T}@T{
set if the option is a password
T}
T{
NoPrefix
T}@T{
bool
T}@T{
N
T}@T{
set if the option for this should not use the backend prefix
T}
T{
Advanced
T}@T{
bool
T}@T{
N
T}@T{
set if this is an advanced config option
T}
T{
Exclusive
T}@T{
bool
T}@T{
N
T}@T{
set if the answer can only be one of the examples (empty string allowed
unless Required or Default is set)
T}
T{
Sensitive
T}@T{
bool
T}@T{
N
T}@T{
set if this option should be redacted when using
\f[V]rclone config redacted\f[R]
T}
.TE
An example of this might be the \f[V]--log-level\f[R] flag.
Note that the \f[V]Name\f[R] of the option becomes the command line flag
with \f[V]_\f[R] replaced with \f[V]-\f[R].
.IP
.nf
\f[C]
{
    \[dq]Advanced\[dq]: false,
    \[dq]Default\[dq]: 5,
    \[dq]DefaultStr\[dq]: \[dq]NOTICE\[dq],
    \[dq]Examples\[dq]: [
        {
            \[dq]Help\[dq]: \[dq]\[dq],
            \[dq]Value\[dq]: \[dq]EMERGENCY\[dq]
        },
        {
            \[dq]Help\[dq]: \[dq]\[dq],
            \[dq]Value\[dq]: \[dq]ALERT\[dq]
        },
        ...
    ],
    \[dq]Exclusive\[dq]: true,
    \[dq]FieldName\[dq]: \[dq]LogLevel\[dq],
    \[dq]Groups\[dq]: \[dq]Logging\[dq],
    \[dq]Help\[dq]: \[dq]Log level DEBUG|INFO|NOTICE|ERROR\[dq],
    \[dq]Hide\[dq]: 0,
    \[dq]IsPassword\[dq]: false,
    \[dq]Name\[dq]: \[dq]log_level\[dq],
    \[dq]NoPrefix\[dq]: true,
    \[dq]Required\[dq]: true,
    \[dq]Sensitive\[dq]: false,
    \[dq]Type\[dq]: \[dq]LogLevel\[dq],
    \[dq]Value\[dq]: null,
    \[dq]ValueStr\[dq]: \[dq]NOTICE\[dq]
},
\f[R]
.fi
Note that the \f[V]Help\f[R] may be multiple lines separated by
\f[V]\[rs]n\f[R].
The first line will always be a short sentence and this is the sentence
shown when running \f[V]rclone help flags\f[R].
.SS Specifying remotes to work on
Remotes are specified with the \f[V]fs=\f[R], \f[V]srcFs=\f[R],
\f[V]dstFs=\f[R] parameters depending on the command being used.
The parameters can be a string as per the rest of rclone, eg
\f[V]s3:bucket/path\f[R] or \f[V]:sftp:/my/dir\f[R].
They can also be specified as JSON blobs.
If specifying a JSON blob it should be a object mapping strings to
strings.
These values will be used to configure the remote.
There are 3 special values which may be set:
.IP \[bu] 2
\f[V]type\f[R] - set to \f[V]type\f[R] to specify a remote called
\f[V]:type:\f[R]
.IP \[bu] 2
\f[V]_name\f[R] - set to \f[V]name\f[R] to specify a remote called
\f[V]name:\f[R]
.IP \[bu] 2
\f[V]_root\f[R] - sets the root of the remote - may be empty
One of \f[V]_name\f[R] or \f[V]type\f[R] should normally be set.
If the \f[V]local\f[R] backend is desired then \f[V]type\f[R] should be
set to \f[V]local\f[R].
If \f[V]_root\f[R] isn\[aq]t specified then it defaults to the root of
the remote.
For example this JSON is equivalent to \f[V]remote:/tmp\f[R]
{
    \[dq]_name\[dq]: \[dq]remote\[dq],
    \[dq]_root\[dq]: \[dq]/tmp\[dq]
}
And this is equivalent to
\f[V]:sftp,host=\[aq]example.com\[aq]:/tmp\f[R]
.IP
.nf
\f[C]
{
    \[dq]type\[dq]: \[dq]sftp\[dq],
    \[dq]host\[dq]: \[dq]example.com\[dq],
    \[dq]_root\[dq]: \[dq]/tmp\[dq]
}
\f[R]
.fi
And this is equivalent to \f[V]/tmp/dir\f[R]
{
    \[dq]type\[dq]: \[dq]local\[dq],
    \[dq]_root\[dq]: \[dq]/tmp/dir\[dq]
}
.SS Supported commands
.SS backend/command: Runs a backend command.
This takes the following parameters:
command - a string with the command name
fs - a remote name string e.g.
\[dq]drive:\[dq]
arg - a list of arguments for the backend command
opt - a map of string to string of options
Returns:
result - result from the backend command
Example:
rclone rc backend/command command=noop fs=. -o echo=yes -o blue -a path1 -a path2
.PP
Returns
{
    \[dq]result\[dq]: {
        \[dq]arg\[dq]: [
            \[dq]path1\[dq],
            \[dq]path2\[dq]
        ],
        \[dq]name\[dq]: \[dq]noop\[dq],
        \[dq]opt\[dq]: {
            \[dq]blue\[dq]: \[dq]\[dq],
            \[dq]echo\[dq]: \[dq]yes\[dq]
        }
    }
}
.PP
Note that this is the direct equivalent of using this \[dq]backend\[dq]
command:
rclone backend noop . -o echo=yes -o blue path1 path2
Note that arguments must be preceded by the \[dq]-a\[dq] flag
See the backend (https://rclone.org/commands/rclone_backend/) command
for more information.
\f[B]Authentication is required for this call.\f[R]
.SS cache/expire: Purge a remote from cache
Purge a remote from the cache backend.
Supports either a directory or a file.
Params: - remote = path to remote (required) - withData = true/false to
delete cached data (chunks) as well (optional)
Eg
rclone rc cache/expire remote=path/to/sub/folder/
rclone rc cache/expire remote=/ withData=true
.SS cache/fetch: Fetch file chunks
Ensure the specified file chunks are cached on disk.
The chunks= parameter specifies the file chunks to check.
It takes a comma separated list of array slice indices.
The slice indices are similar to Python slices: start[:end]
start is the 0 based chunk number from the beginning of the file to
fetch inclusive.
end is 0 based chunk number from the beginning of the file to fetch
exclusive.
Both values can be negative, in which case they count from the back of
the file.
The value \[dq]-5:\[dq] represents the last 5 chunks of a file.
Some valid examples are: \[dq]:5,-5:\[dq] -> the first and last five
chunks \[dq]0,-2\[dq] -> the first and the second last chunk
\[dq]0:10\[dq] -> the first ten chunks
Any parameter with a key that starts with \[dq]file\[dq] can be used to
specify files to fetch, e.g.
rclone rc cache/fetch chunks=0 file=hello file2=home/goodbye
File names will automatically be encrypted when the a crypt remote is
used on top of the cache.
.SS cache/stats: Get cache stats
Show statistics for the cache remote.
.SS config/create: create the config for a remote.
.PP
This takes the following parameters:
name - name of remote
parameters - a map of { \[dq]key\[dq]: \[dq]value\[dq] } pairs
type - type of the new remote
opt - a dictionary of options to control the configuration
.RS 2
obscure - declare passwords are plain and need obscuring
noObscure - declare passwords are already obscured and don\[aq]t need
obscuring
.IP \[bu] 2
noOutput - don\[aq]t print anything to stdout
.IP \[bu] 2
nonInteractive - don\[aq]t interact with a user, return questions
.IP \[bu] 2
continue - continue the config process with an answer
.IP \[bu] 2
all - ask all the config questions not just the post config ones
.IP \[bu] 2
state - state to restart with - used with continue
.IP \[bu] 2
result - result to restart with - used with continue
.RE
See the config
create (https://rclone.org/commands/rclone_config_create/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS config/delete: Delete a remote in the config file.
.PP
Parameters:
name - name of remote to delete
.PP
See the config
delete (https://rclone.org/commands/rclone_config_delete/) command for
more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS config/dump: Dumps the config file.
.PP
Returns a JSON object: - key: value
.PP
Where keys are remote names and values are the config parameters.
.PP
See the config dump (https://rclone.org/commands/rclone_config_dump/)
command for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS config/get: Get a remote in the config file.
.PP
Parameters:
name - name of remote to get
.PP
See the config dump (https://rclone.org/commands/rclone_config_dump/)
command for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS config/listremotes: Lists the remotes in the config file and defined in environment variables.
.PP
Returns - remotes - array of remote names
.PP
See the listremotes (https://rclone.org/commands/rclone_listremotes/)
command for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS config/password: password the config for a remote.
.PP
This takes the following parameters:
name - name of remote
.IP \[bu] 2
parameters - a map of { \[dq]key\[dq]: \[dq]value\[dq] } pairs
See the config
password (https://rclone.org/commands/rclone_config_password/) command
for more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS config/paths: Reads the config file path and other important paths.
Returns a JSON object with the following keys:
.IP \[bu] 2
config: path to config file
.IP \[bu] 2
cache: path to root of cache directory
.IP \[bu] 2
temp: path to root of temporary directory
.PP
Eg
{
    \[dq]cache\[dq]: \[dq]/home/USER/.cache/rclone\[dq],
    \[dq]config\[dq]: \[dq]/home/USER/.rclone.conf\[dq],
    \[dq]temp\[dq]: \[dq]/tmp\[dq]
}
See the config paths (https://rclone.org/commands/rclone_config_paths/)
command for more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS config/providers: Shows how providers are configured in the config file.
Returns a JSON object: - providers - array of objects
See the config
providers (https://rclone.org/commands/rclone_config_providers/) command
for more information on the above.
Note that the Options blocks are in the same format as returned by
\[dq]options/info\[dq].
They are described in the option blocks section.
\f[B]Authentication is required for this call.\f[R]
.SS config/setpath: Set the path of the config file
.PP
Parameters:
path - path to the config file to use
.PP
\f[B]Authentication is required for this call.\f[R]
.SS config/unlock: Unlock the config file.
.PP
Unlocks the config file if it is locked.
.PP
Parameters:
\[aq]configPassword\[aq] - password to unlock the config file
A good idea is to disable AskPassword before making this call
\f[B]Authentication is required for this call.\f[R]
.SS config/update: update the config for a remote.
.PP
This takes the following parameters:
name - name of remote
parameters - a map of { \[dq]key\[dq]: \[dq]value\[dq] } pairs
opt - a dictionary of options to control the configuration
.RS 2
obscure - declare passwords are plain and need obscuring
noObscure - declare passwords are already obscured and don\[aq]t need
obscuring
noOutput - don\[aq]t print anything to stdout
nonInteractive - don\[aq]t interact with a user, return questions
continue - continue the config process with an answer
all - ask all the config questions not just the post config ones
state - state to restart with - used with continue
.IP \[bu] 2
result - result to restart with - used with continue
.RE
See the config
update (https://rclone.org/commands/rclone_config_update/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS core/bwlimit: Set the bandwidth limit.
This sets the bandwidth limit to the string passed in.
This should be a single bandwidth limit entry or a pair of
upload:download bandwidth.
.PP
Eg
.IP
.nf
\f[C]
rclone rc core/bwlimit rate=off
{
    \[dq]bytesPerSecond\[dq]: -1,
    \[dq]bytesPerSecondTx\[dq]: -1,
    \[dq]bytesPerSecondRx\[dq]: -1,
    \[dq]rate\[dq]: \[dq]off\[dq]
}
rclone rc core/bwlimit rate=1M
{
    \[dq]bytesPerSecond\[dq]: 1048576,
    \[dq]bytesPerSecondTx\[dq]: 1048576,
    \[dq]bytesPerSecondRx\[dq]: 1048576,
    \[dq]rate\[dq]: \[dq]1M\[dq]
}
rclone rc core/bwlimit rate=1M:100k
{
    \[dq]bytesPerSecond\[dq]: 1048576,
    \[dq]bytesPerSecondTx\[dq]: 1048576,
    \[dq]bytesPerSecondRx\[dq]: 131072,
    \[dq]rate\[dq]: \[dq]1M\[dq]
}
\f[R]
.fi
.PP
If the rate parameter is not supplied then the bandwidth is queried
.IP
.nf
\f[C]
rclone rc core/bwlimit
{
    \[dq]bytesPerSecond\[dq]: 1048576,
    \[dq]bytesPerSecondTx\[dq]: 1048576,
    \[dq]bytesPerSecondRx\[dq]: 1048576,
    \[dq]rate\[dq]: \[dq]1M\[dq]
}
\f[R]
.fi
.PP
The format of the parameter is exactly the same as passed to --bwlimit
except only one bandwidth may be specified.
.PP
In either case \[dq]rate\[dq] is returned as a human-readable string,
and \[dq]bytesPerSecond\[dq] is returned as a number.
.SS core/command: Run a rclone terminal command over rc.
.PP
This takes the following parameters:
command - a string with the command name.
arg - a list of arguments for the backend command.
opt - a map of string to string of options.
returnType - one of (\[dq]COMBINED_OUTPUT\[dq], \[dq]STREAM\[dq],
\[dq]STREAM_ONLY_STDOUT\[dq], \[dq]STREAM_ONLY_STDERR\[dq]).
.RS 2
Defaults to \[dq]COMBINED_OUTPUT\[dq] if not set.
The STREAM returnTypes will write the output to the body of the HTTP
message.
The COMBINED_OUTPUT will write the output to the \[dq]result\[dq]
parameter.
.RE
Returns:
result - result from the backend command.
.RS 2
Only set when using returnType \[dq]COMBINED_OUTPUT\[dq].
.RE
.IP \[bu] 2
error - set if rclone exits with an error code.
.IP \[bu] 2
returnType - one of (\[dq]COMBINED_OUTPUT\[dq], \[dq]STREAM\[dq],
\[dq]STREAM_ONLY_STDOUT\[dq], \[dq]STREAM_ONLY_STDERR\[dq]).
Example:
.IP
.nf
\f[C]
rclone rc core/command command=ls -a mydrive:/ -o max-depth=1
rclone rc core/command -a ls -a mydrive:/ -o max-depth=1
\f[R]
.fi
Returns:
.IP
.nf
\f[C]
{
    \[dq]error\[dq]: false,
    \[dq]result\[dq]: \[dq]<Raw command line output>\[dq]
}

OR
{
    \[dq]error\[dq]: true,
    \[dq]result\[dq]: \[dq]<Raw command line output>\[dq]
}
\f[R]
.fi
\f[B]Authentication is required for this call.\f[R]
.SS core/du: Returns disk usage of a locally attached disk.
This returns the disk usage for the local directory passed in as dir.
If the directory is not passed in, it defaults to the directory pointed
to by --cache-dir.
.IP \[bu] 2
dir - string (optional)
Returns:
.IP
.nf
\f[C]
{
    \[dq]dir\[dq]: \[dq]/\[dq],
    \[dq]info\[dq]: {
        \[dq]Available\[dq]: 361769115648,
        \[dq]Free\[dq]: 361785892864,
        \[dq]Total\[dq]: 982141468672
    }
}
\f[R]
.fi
.SS core/gc: Runs a garbage collection.
This tells the go runtime to do a garbage collection run.
It isn\[aq]t necessary to call this normally, but it can be useful for
debugging memory problems.
.SS core/group-list: Returns list of stats.
This returns list of stats groups currently in memory.
Returns the following values:
.IP
.nf
\f[C]
{
    \[dq]groups\[dq]:  an array of group names:
        [
            \[dq]group1\[dq],
            \[dq]group2\[dq],
            ...
        ]
}
\f[R]
.fi
.SS core/memstats: Returns the memory statistics
This returns the memory statistics of the running program.
What the values mean are explained in the go docs:
https://golang.org/pkg/runtime/#MemStats
The most interesting values for most people are:
.IP \[bu] 2
HeapAlloc - this is the amount of memory rclone is actually using
.IP \[bu] 2
HeapSys - this is the amount of memory rclone has obtained from the OS
.IP \[bu] 2
Sys - this is the total amount of memory requested from the OS
.RS 2
.IP \[bu] 2
It is virtual memory so may include unused memory
.RE
.SS core/obscure: Obscures a string passed in.
Pass a clear string and rclone will obscure it for the config file: -
clear - string
Returns: - obscured - string
.SS core/pid: Return PID of current process
This returns PID of current process.
Useful for stopping rclone process.
.SS core/quit: Terminates the app.
(Optional) Pass an exit code to be used for terminating the app: -
exitCode - int
.SS core/stats: Returns stats about current transfers.
This returns all available stats:
.IP
.nf
\f[C]
rclone rc core/stats
\f[R]
.fi
If group is not provided then summed up stats for all groups will be
returned.
Parameters
.IP \[bu] 2
group - name of the stats group (string, optional)
.IP \[bu] 2
short - if true will not return the transferring and checking arrays
(boolean, optional)
Returns the following values:
.IP
.nf
\f[C]
{
    \[dq]bytes\[dq]: total transferred bytes since the start of the group,
    \[dq]checks\[dq]: number of files checked,
    \[dq]deletes\[dq] : number of files deleted,
    \[dq]elapsedTime\[dq]: time in floating point seconds since rclone was started,
    \[dq]errors\[dq]: number of errors,
    \[dq]eta\[dq]: estimated time in seconds until the group completes,
    \[dq]fatalError\[dq]: boolean whether there has been at least one fatal error,
    \[dq]lastError\[dq]: last error string,
    \[dq]renames\[dq] : number of files renamed,
    \[dq]listed\[dq] : number of directory entries listed,
    \[dq]retryError\[dq]: boolean showing whether there has been at least one non-NoRetryError,
        \[dq]serverSideCopies\[dq]: number of server side copies done,
        \[dq]serverSideCopyBytes\[dq]: number bytes server side copied,
        \[dq]serverSideMoves\[dq]: number of server side moves done,
        \[dq]serverSideMoveBytes\[dq]: number bytes server side moved,
    \[dq]speed\[dq]: average speed in bytes per second since start of the group,
    \[dq]totalBytes\[dq]: total number of bytes in the group,
    \[dq]totalChecks\[dq]: total number of checks in the group,
    \[dq]totalTransfers\[dq]: total number of transfers in the group,
    \[dq]transferTime\[dq] : total time spent on running jobs,
    \[dq]transfers\[dq]: number of transferred files,
    \[dq]transferring\[dq]: an array of currently active file transfers:
        [
            {
                \[dq]bytes\[dq]: total transferred bytes for this file,
                \[dq]eta\[dq]: estimated time in seconds until file transfer completion
                \[dq]name\[dq]: name of the file,
                \[dq]percentage\[dq]: progress of the file transfer in percent,
                \[dq]speed\[dq]: average speed over the whole transfer in bytes per second,
                \[dq]speedAvg\[dq]: current speed in bytes per second as an exponentially weighted moving average,
                \[dq]size\[dq]: size of the file in bytes
            }
        ],
    \[dq]checking\[dq]: an array of names of currently active file checks
        []
}
\f[R]
.fi
Values for \[dq]transferring\[dq], \[dq]checking\[dq] and
\[dq]lastError\[dq] are only assigned if data is available.
The value for \[dq]eta\[dq] is null if an eta cannot be determined.
.SS core/stats-delete: Delete stats group.
This deletes entire stats group.
Parameters
.IP \[bu] 2
group - name of the stats group (string)
.SS core/stats-reset: Reset stats.
This clears counters, errors and finished transfers for all stats or
specific stats group if group is provided.
Parameters
.IP \[bu] 2
group - name of the stats group (string)
.SS core/transferred: Returns stats about completed transfers.
This returns stats about completed transfers:
.IP
.nf
\f[C]
rclone rc core/transferred
\f[R]
.fi
If group is not provided then completed transfers for all groups will be
returned.
Note only the last 100 completed transfers are returned.
Parameters
.IP \[bu] 2
group - name of the stats group (string)
Returns the following values:
.IP
.nf
\f[C]
{
    \[dq]transferred\[dq]:  an array of completed transfers (including failed ones):
        [
            {
                \[dq]name\[dq]: name of the file,
                \[dq]size\[dq]: size of the file in bytes,
                \[dq]bytes\[dq]: total transferred bytes for this file,
                \[dq]checked\[dq]: if the transfer is only checked (skipped, deleted),
                \[dq]what\[dq]: the purpose of the transfer (transferring, deleting, checking, importing, hashing, merging, listing, moving, renaming),
                \[dq]timestamp\[dq]: integer representing millisecond unix epoch,
                \[dq]error\[dq]: string description of the error (empty if successful),
                \[dq]jobid\[dq]: id of the job that this transfer belongs to
            }
        ]
}
\f[R]
.fi
.SS core/version: Shows the current version of rclone, Go and the OS.
This shows the current versions of rclone, Go and the OS:
.IP \[bu] 2
version - rclone version, e.g.
\[dq]v1.71.2\[dq]
.IP \[bu] 2
decomposed - version number as [major, minor, patch]
.IP \[bu] 2
isGit - boolean - true if this was compiled from the git version
.IP \[bu] 2
isBeta - boolean - true if this is a beta version
.IP \[bu] 2
os - OS in use as according to Go GOOS (e.g.
\[dq]linux\[dq])
.IP \[bu] 2
osKernel - OS Kernel version (e.g.
\[dq]6.8.0-86-generic (x86_64)\[dq])
.IP \[bu] 2
osVersion - OS Version (e.g.
\[dq]ubuntu 24.04 (64 bit)\[dq])
.IP \[bu] 2
osArch - cpu architecture in use (e.g.
\[dq]arm64 (ARMv8 compatible)\[dq])
.IP \[bu] 2
arch - cpu architecture in use according to Go GOARCH (e.g.
\[dq]arm64\[dq])
.IP \[bu] 2
goVersion - version of Go runtime in use (e.g.
\[dq]go1.25.0\[dq])
.IP \[bu] 2
linking - type of rclone executable (static or dynamic)
.IP \[bu] 2
goTags - space separated build tags or \[dq]none\[dq]
.SS debug/set-block-profile-rate: Set runtime.SetBlockProfileRate for blocking profiling.
SetBlockProfileRate controls the fraction of goroutine blocking events
that are reported in the blocking profile.
The profiler aims to sample an average of one blocking event per rate
nanoseconds spent blocked.
To include every blocking event in the profile, pass rate = 1.
To turn off profiling entirely, pass rate <= 0.
After calling this you can use this to see the blocking profile:
.IP
.nf
\f[C]
go tool pprof http://localhost:5572/debug/pprof/block
\f[R]
.fi
Parameters:
.IP \[bu] 2
rate - int
.SS debug/set-gc-percent: Call runtime/debug.SetGCPercent for setting the garbage collection target percentage.
SetGCPercent sets the garbage collection target percentage: a collection
is triggered when the ratio of freshly allocated data to live data
remaining after the previous collection reaches this percentage.
SetGCPercent returns the previous setting.
The initial setting is the value of the GOGC environment variable at
startup, or 100 if the variable is not set.
This setting may be effectively reduced in order to maintain a memory
limit.
A negative percentage effectively disables garbage collection, unless
the memory limit is reached.
See https://pkg.go.dev/runtime/debug#SetMemoryLimit for more details.
Parameters:
.IP \[bu] 2
gc-percent - int
.SS debug/set-mutex-profile-fraction: Set runtime.SetMutexProfileFraction for mutex profiling.
SetMutexProfileFraction controls the fraction of mutex contention events
that are reported in the mutex profile.
On average 1/rate events are reported.
The previous rate is returned.
To turn off profiling entirely, pass rate 0.
To just read the current rate, pass rate < 0.
(For n>1 the details of sampling may change.)
Once this is set you can look use this to profile the mutex contention:
.IP
.nf
\f[C]
go tool pprof http://localhost:5572/debug/pprof/mutex
\f[R]
.fi
Parameters:
.IP \[bu] 2
rate - int
Results:
.IP \[bu] 2
previousRate - int
.SS debug/set-soft-memory-limit: Call runtime/debug.SetMemoryLimit for setting a soft memory limit for the runtime.
SetMemoryLimit provides the runtime with a soft memory limit.
The runtime undertakes several processes to try to respect this memory
limit, including adjustments to the frequency of garbage collections and
returning memory to the underlying system more aggressively.
This limit will be respected even if GOGC=off (or, if SetGCPercent(-1)
is executed).
The input limit is provided as bytes, and includes all memory mapped,
managed, and not released by the Go runtime.
Notably, it does not account for space used by the Go binary and memory
external to Go, such as memory managed by the underlying system on
behalf of the process, or memory managed by non-Go code inside the same
process.
Examples of excluded memory sources include: OS kernel memory held on
behalf of the process, memory allocated by C code, and memory mapped by
syscall.Mmap (because it is not managed by the Go runtime).
A zero limit or a limit that\[aq]s lower than the amount of memory used
by the Go runtime may cause the garbage collector to run nearly
continuously.
However, the application may still make progress.
The memory limit is always respected by the Go runtime, so to
effectively disable this behavior, set the limit very high.
math.MaxInt64 is the canonical value for disabling the limit, but values
much greater than the available memory on the underlying system work
just as well.
See https://go.dev/doc/gc-guide for a detailed guide explaining the soft
memory limit in more detail, as well as a variety of common use-cases
and scenarios.
SetMemoryLimit returns the previously set memory limit.
A negative input does not adjust the limit, and allows for retrieval of
the currently set memory limit.
Parameters:
.IP \[bu] 2
mem-limit - int
.SS fscache/clear: Clear the Fs cache.
This clears the fs cache.
This is where remotes created from backends are cached for a short while
to make repeated rc calls more efficient.
.PP
If you change the parameters of a backend then you may want to call this
to clear an existing remote out of the cache before re-creating it.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS fscache/entries: Returns the number of entries in the fs cache.
.PP
This returns the number of entries in the fs cache.
.PP
Returns - entries - number of items in the cache
.PP
\f[B]Authentication is required for this call.\f[R]
.SS job/batch: Run a batch of rclone rc commands concurrently.
.PP
This takes the following parameters:
.IP \[bu] 2
concurrency - int - do this many commands concurrently.
Defaults to \f[V]--transfers\f[R] if not set.
.IP \[bu] 2
inputs - an list of inputs to the commands with an extra \f[V]_path\f[R]
parameter
    \[dq]_path\[dq]: \[dq]rc/path\[dq],
    \[dq]param1\[dq]: \[dq]parameter for the path as documented\[dq],
    \[dq]param2\[dq]: \[dq]parameter for the path as documented, etc\[dq],
The inputs may use \f[V]_async\f[R], \f[V]_group\f[R], \f[V]_config\f[R]
and \f[V]_filter\f[R] as normal when using the rc.
Returns:
.IP \[bu] 2
results - a list of results from the commands with one entry for each in
inputs.
.PP
For example:
rclone rc job/batch --json \[aq]{
  \[dq]inputs\[dq]: [
    {
      \[dq]_path\[dq]: \[dq]rc/noop\[dq],
      \[dq]parameter\[dq]: \[dq]OK\[dq]
    },
    {
      \[dq]_path\[dq]: \[dq]rc/error\[dq],
      \[dq]parameter\[dq]: \[dq]BAD\[dq]
    }
  ]
}
\[aq]
Gives the result:
  \[dq]results\[dq]: [
    {
      \[dq]parameter\[dq]: \[dq]OK\[dq]
    },
    {
      \[dq]error\[dq]: \[dq]arbitrary error on input map[parameter:BAD]\[dq],
      \[dq]input\[dq]: {
        \[dq]parameter\[dq]: \[dq]BAD\[dq]
      },
      \[dq]path\[dq]: \[dq]rc/error\[dq],
      \[dq]status\[dq]: 500
  ]
\f[B]Authentication is required for this call.\f[R]
.SS job/list: Lists the IDs of the running jobs
Parameters: None.
.PP
Results:
.IP \[bu] 2
executeId - string id of rclone executing (change after restart)
.IP \[bu] 2
jobids - array of integer job ids (starting at 1 on each restart)
.IP \[bu] 2
runningIds - array of integer job ids that are running
.IP \[bu] 2
finishedIds - array of integer job ids that are finished
.SS job/status: Reads the status of the job ID
.PP
Parameters:
.IP \[bu] 2
jobid - id of the job (integer).
.PP
Results:
.IP \[bu] 2
finished - boolean
.IP \[bu] 2
duration - time in seconds that the job ran for
.IP \[bu] 2
endTime - time the job finished (e.g.
\[dq]2018-10-26T18:50:20.528746884+01:00\[dq])
.IP \[bu] 2
error - error from the job or empty string for no error
.IP \[bu] 2
finished - boolean whether the job has finished or not
.IP \[bu] 2
id - as passed in above
.IP \[bu] 2
executeId - rclone instance ID (changes after restart); combined with id
uniquely identifies a job
.IP \[bu] 2
startTime - time the job started (e.g.
\[dq]2018-10-26T18:50:20.528336039+01:00\[dq])
.IP \[bu] 2
success - boolean - true for success false otherwise
.IP \[bu] 2
output - output of the job as would have been returned if called
synchronously
.IP \[bu] 2
progress - output of the progress related to the underlying job
.SS job/stop: Stop the running job
.PP
Parameters:
.IP \[bu] 2
jobid - id of the job (integer).
.SS job/stopgroup: Stop all running jobs in a group
.PP
Parameters:
.IP \[bu] 2
group - name of the group (string).
.SS mount/listmounts: Show current mount points
.PP
This shows currently mounted points, which can be used for performing an
unmount.
.PP
This takes no parameters and returns
.IP \[bu] 2
mountPoints: list of current mount points
.PP
Eg
rclone rc mount/listmounts
\f[B]Authentication is required for this call.\f[R]
.SS mount/mount: Create a new mount point
rclone allows Linux, FreeBSD, macOS and Windows to mount any of
Rclone\[aq]s cloud storage systems as a file system with FUSE.
If no mountType is provided, the priority is given as follows: 1.
mount 2.cmount 3.mount2
This takes the following parameters:
.IP \[bu] 2
fs - a remote path to be mounted (required)
.IP \[bu] 2
mountPoint: valid path on the local machine (required)
.IP \[bu] 2
mountType: one of the values (mount, cmount, mount2) specifies the mount
implementation to use
.IP \[bu] 2
mountOpt: a JSON object with Mount options in.
.IP \[bu] 2
vfsOpt: a JSON object with VFS options in.
Example:
rclone rc mount/mount fs=mydrive: mountPoint=/home/<user>/mountPoint
rclone rc mount/mount fs=mydrive: mountPoint=/home/<user>/mountPoint mountType=mount
rclone rc mount/mount fs=TestDrive: mountPoint=/mnt/tmp vfsOpt=\[aq]{\[dq]CacheMode\[dq]: 2}\[aq] mountOpt=\[aq]{\[dq]AllowOther\[dq]: true}\[aq]
The vfsOpt are as described in options/get and can be seen in the the
\[dq]vfs\[dq] section when running and the mountOpt can be seen in the
\[dq]mount\[dq] section:
rclone rc options/get
\f[B]Authentication is required for this call.\f[R]
.SS mount/types: Show all possible mount types
This shows all possible mount types and returns them as a list.
This takes no parameters and returns
.IP \[bu] 2
mountTypes: list of mount types
.PP
The mount types are strings like \[dq]mount\[dq], \[dq]mount2\[dq],
\[dq]cmount\[dq] and can be passed to mount/mount as the mountType
Eg
rclone rc mount/types
\f[B]Authentication is required for this call.\f[R]
.SS mount/unmount: Unmount selected active mount
rclone allows Linux, FreeBSD, macOS and Windows to mount any of
Rclone\[aq]s cloud storage systems as a file system with FUSE.
This takes the following parameters:
.IP \[bu] 2
mountPoint: valid path on the local machine where the mount was created
(required)
.PP
Example:
rclone rc mount/unmount mountPoint=/home/<user>/mountPoint
\f[B]Authentication is required for this call.\f[R]
.SS mount/unmountall: Unmount all active mounts
rclone allows Linux, FreeBSD, macOS and Windows to mount any of
Rclone\[aq]s cloud storage systems as a file system with FUSE.
.PP
This takes no parameters and returns error if unmount does not succeed.
.PP
Eg
rclone rc mount/unmountall
\f[B]Authentication is required for this call.\f[R]
.SS operations/about: Return the space used on the remote
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
The result is as returned from rclone about --json
See the about (https://rclone.org/commands/rclone_about/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/check: check the source and destination are the same
.PP
Checks the files in the source and destination match.
It compares sizes and hashes and logs a report of files that don\[aq]t
match.
It doesn\[aq]t alter the source or destination.
.PP
This takes the following parameters:
.IP \[bu] 2
srcFs - a remote name string e.g.
\[dq]drive:\[dq] for the source, \[dq]/\[dq] for local filesystem
.IP \[bu] 2
dstFs - a remote name string e.g.
\[dq]drive2:\[dq] for the destination, \[dq]/\[dq] for local filesystem
.IP \[bu] 2
download - check by downloading rather than with hash
.IP \[bu] 2
checkFileHash - treat checkFileFs:checkFileRemote as a SUM file with
hashes of given type
.IP \[bu] 2
checkFileFs - treat checkFileFs:checkFileRemote as a SUM file with
hashes of given type
.IP \[bu] 2
checkFileRemote - treat checkFileFs:checkFileRemote as a SUM file with
hashes of given type
.IP \[bu] 2
oneWay - check one way only, source files must exist on remote
.IP \[bu] 2
combined - make a combined report of changes (default false)
.IP \[bu] 2
missingOnSrc - report all files missing from the source (default true)
.IP \[bu] 2
missingOnDst - report all files missing from the destination (default
true)
.IP \[bu] 2
match - report all matching files (default false)
.IP \[bu] 2
differ - report all non-matching files (default true)
.IP \[bu] 2
error - report all files with errors (hashing or reading) (default true)
.PP
If you supply the download flag, it will download the data from both
remotes and check them against each other on the fly.
This can be useful for remotes that don\[aq]t support hashes or if you
really want to check all the data.
.PP
If you supply the size-only global flag, it will only compare the sizes
not the hashes as well.
Use this for a quick check.
.PP
If you supply the checkFileHash option with a valid hash name, the
checkFileFs:checkFileRemote must point to a text file in the SUM format.
This treats the checksum file as the source and dstFs as the
destination.
Note that srcFs is not used and should not be supplied in this case.
.PP
Returns:
.IP \[bu] 2
success - true if no error, false otherwise
.IP \[bu] 2
status - textual summary of check, OK or text string
.IP \[bu] 2
hashType - hash used in check, may be missing
.IP \[bu] 2
combined - array of strings of combined report of changes
.IP \[bu] 2
missingOnSrc - array of strings of all files missing from the source
.IP \[bu] 2
missingOnDst - array of strings of all files missing from the
destination
.IP \[bu] 2
match - array of strings of all matching files
.IP \[bu] 2
differ - array of strings of all non-matching files
.IP \[bu] 2
error - array of strings of all files with errors (hashing or reading)
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/cleanup: Remove trashed files in the remote or path
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.PP
See the cleanup (https://rclone.org/commands/rclone_cleanup/) command
for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/copyfile: Copy a file from source remote to destination remote
.PP
This takes the following parameters:
.IP \[bu] 2
srcFs - a remote name string e.g.
\[dq]drive:\[dq] for the source, \[dq]/\[dq] for local filesystem
.IP \[bu] 2
srcRemote - a path within that remote e.g.
\[dq]file.txt\[dq] for the source
.IP \[bu] 2
dstFs - a remote name string e.g.
\[dq]drive2:\[dq] for the destination, \[dq]/\[dq] for local filesystem
.IP \[bu] 2
dstRemote - a path within that remote e.g.
\[dq]file2.txt\[dq] for the destination
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/copyurl: Copy the URL to the object
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
.IP \[bu] 2
url - string, URL to read from
.IP \[bu] 2
autoFilename - boolean, set to true to retrieve destination file name
from url
.PP
See the copyurl (https://rclone.org/commands/rclone_copyurl/) command
for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/delete: Remove files in the path
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.PP
See the delete (https://rclone.org/commands/rclone_delete/) command for
more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/deletefile: Remove the single file pointed to
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
.PP
See the deletefile (https://rclone.org/commands/rclone_deletefile/)
command for more information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/fsinfo: Return information about the remote
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.PP
This returns info about the remote passed in;
{
        // optional features and whether they are available or not
        \[dq]Features\[dq]: {
                \[dq]About\[dq]: true,
                \[dq]BucketBased\[dq]: false,
                \[dq]BucketBasedRootOK\[dq]: false,
                \[dq]CanHaveEmptyDirectories\[dq]: true,
                \[dq]CaseInsensitive\[dq]: false,
                \[dq]ChangeNotify\[dq]: false,
                \[dq]CleanUp\[dq]: false,
                \[dq]Command\[dq]: true,
                \[dq]Copy\[dq]: false,
                \[dq]DirCacheFlush\[dq]: false,
                \[dq]DirMove\[dq]: true,
                \[dq]Disconnect\[dq]: false,
                \[dq]DuplicateFiles\[dq]: false,
                \[dq]GetTier\[dq]: false,
                \[dq]IsLocal\[dq]: true,
                \[dq]ListR\[dq]: false,
                \[dq]MergeDirs\[dq]: false,
                \[dq]MetadataInfo\[dq]: true,
                \[dq]Move\[dq]: true,
                \[dq]OpenWriterAt\[dq]: true,
                \[dq]PublicLink\[dq]: false,
                \[dq]Purge\[dq]: true,
                \[dq]PutStream\[dq]: true,
                \[dq]PutUnchecked\[dq]: false,
                \[dq]ReadMetadata\[dq]: true,
                \[dq]ReadMimeType\[dq]: false,
                \[dq]ServerSideAcrossConfigs\[dq]: false,
                \[dq]SetTier\[dq]: false,
                \[dq]SetWrapper\[dq]: false,
                \[dq]Shutdown\[dq]: false,
                \[dq]SlowHash\[dq]: true,
                \[dq]SlowModTime\[dq]: false,
                \[dq]UnWrap\[dq]: false,
                \[dq]UserInfo\[dq]: false,
                \[dq]UserMetadata\[dq]: true,
                \[dq]WrapFs\[dq]: false,
                \[dq]WriteMetadata\[dq]: true,
                \[dq]WriteMimeType\[dq]: false
        },
        // Names of hashes available
        \[dq]Hashes\[dq]: [
                \[dq]md5\[dq],
                \[dq]sha1\[dq],
                \[dq]whirlpool\[dq],
                \[dq]crc32\[dq],
                \[dq]sha256\[dq],
                \[dq]dropbox\[dq],
                \[dq]mailru\[dq],
                \[dq]quickxor\[dq]
        ],
        \[dq]Name\[dq]: \[dq]local\[dq],        // Name as created
        \[dq]Precision\[dq]: 1,         // Precision of timestamps in ns
        \[dq]Root\[dq]: \[dq]/\[dq],            // Path as created
        \[dq]String\[dq]: \[dq]Local file system at /\[dq], // how the remote will appear in logs
        // Information about the system metadata for this backend
        \[dq]MetadataInfo\[dq]: {
                \[dq]System\[dq]: {
                        \[dq]atime\[dq]: {
                                \[dq]Help\[dq]: \[dq]Time of last access\[dq],
                                \[dq]Type\[dq]: \[dq]RFC 3339\[dq],
                                \[dq]Example\[dq]: \[dq]2006-01-02T15:04:05.999999999Z07:00\[dq]
                        },
                        \[dq]btime\[dq]: {
                                \[dq]Help\[dq]: \[dq]Time of file birth (creation)\[dq],
                                \[dq]Type\[dq]: \[dq]RFC 3339\[dq],
                                \[dq]Example\[dq]: \[dq]2006-01-02T15:04:05.999999999Z07:00\[dq]
                        },
                        \[dq]gid\[dq]: {
                                \[dq]Help\[dq]: \[dq]Group ID of owner\[dq],
                                \[dq]Type\[dq]: \[dq]decimal number\[dq],
                                \[dq]Example\[dq]: \[dq]500\[dq]
                        },
                        \[dq]mode\[dq]: {
                                \[dq]Help\[dq]: \[dq]File type and mode\[dq],
                                \[dq]Type\[dq]: \[dq]octal, unix style\[dq],
                                \[dq]Example\[dq]: \[dq]0100664\[dq]
                        },
                        \[dq]mtime\[dq]: {
                                \[dq]Help\[dq]: \[dq]Time of last modification\[dq],
                                \[dq]Type\[dq]: \[dq]RFC 3339\[dq],
                                \[dq]Example\[dq]: \[dq]2006-01-02T15:04:05.999999999Z07:00\[dq]
                        },
                        \[dq]rdev\[dq]: {
                                \[dq]Help\[dq]: \[dq]Device ID (if special file)\[dq],
                                \[dq]Type\[dq]: \[dq]hexadecimal\[dq],
                                \[dq]Example\[dq]: \[dq]1abc\[dq]
                        },
                        \[dq]uid\[dq]: {
                                \[dq]Help\[dq]: \[dq]User ID of owner\[dq],
                                \[dq]Type\[dq]: \[dq]decimal number\[dq],
                                \[dq]Example\[dq]: \[dq]500\[dq]
                        }
                },
                \[dq]Help\[dq]: \[dq]Textual help string\[rs]n\[dq]
        }
}
This command does not have a command line equivalent so use this
instead:
rclone rc --loopback operations/fsinfo fs=remote:
.SS operations/hashsum: Produces a hashsum file for all the objects in the path.
Produces a hash file for all the objects in the path using the hash
named.
The output is in the same format as the standard md5sum/sha1sum tool.
.PP
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq] for the source, \[dq]/\[dq] for local filesystem
.RS 2
.IP \[bu] 2
this can point to a file and just that file will be returned in the
listing.
.RE
.IP \[bu] 2
hashType - type of hash to be used
.IP \[bu] 2
download - check by downloading rather than with hash (boolean)
.IP \[bu] 2
base64 - output the hashes in base64 rather than hex (boolean)
.PP
If you supply the download flag, it will download the data from the
remote and create the hash on the fly.
This can be useful for remotes that don\[aq]t support the given hash or
if you really want to check all the data.
.PP
Note that if you wish to supply a checkfile to check hashes against the
current files then you should use operations/check instead of
operations/hashsum.
.PP
Returns:
.IP \[bu] 2
hashsum - array of strings of the hashes
.IP \[bu] 2
hashType - type of hash used
.PP
Example:
$ rclone rc --loopback operations/hashsum fs=bin hashType=MD5 download=true base64=true
{
    \[dq]hashType\[dq]: \[dq]md5\[dq],
    \[dq]hashsum\[dq]: [
        \[dq]WTSVLpuiXyJO_kGzJerRLg==  backend-versions.sh\[dq],
        \[dq]v1b_OlWCJO9LtNq3EIKkNQ==  bisect-go-rclone.sh\[dq],
        \[dq]VHbmHzHh4taXzgag8BAIKQ==  bisect-rclone.sh\[dq],
    ]
}
See the hashsum (https://rclone.org/commands/rclone_hashsum/) command
for more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/list: List the given remote and path in JSON format
This takes the following parameters:
fs - a remote name string e.g.
\[dq]drive:\[dq]
remote - a path within that remote e.g.
\[dq]dir\[dq]
opt - a dictionary of options to control the listing (optional)
.RS 2
recurse - If set recurse directories
.IP \[bu] 2
noModTime - If set return modification time
.IP \[bu] 2
showEncrypted - If set show decrypted names
.IP \[bu] 2
showOrigIDs - If set show the IDs for each item if known
.IP \[bu] 2
showHash - If set return a dictionary of hashes
.IP \[bu] 2
noMimeType - If set don\[aq]t show mime types
.IP \[bu] 2
dirsOnly - If set only show directories
.IP \[bu] 2
filesOnly - If set only show files
.IP \[bu] 2
metadata - If set return metadata of objects also
.IP \[bu] 2
hashTypes - array of strings of hash types to show if showHash set
.RE
Returns:
.IP \[bu] 2
list
.RS 2
.IP \[bu] 2
This is an array of objects as described in the lsjson command
.RE
See the lsjson (https://rclone.org/commands/rclone_lsjson/) command for
more information on the above and examples.
\f[B]Authentication is required for this call.\f[R]
.SS operations/mkdir: Make a destination directory or container
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
See the mkdir (https://rclone.org/commands/rclone_mkdir/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/movefile: Move a file from source remote to destination remote
This takes the following parameters:
srcFs - a remote name string e.g.
\[dq]drive:\[dq] for the source, \[dq]/\[dq] for local filesystem
srcRemote - a path within that remote e.g.
\[dq]file.txt\[dq] for the source
dstFs - a remote name string e.g.
\[dq]drive2:\[dq] for the destination, \[dq]/\[dq] for local filesystem
.IP \[bu] 2
dstRemote - a path within that remote e.g.
\[dq]file2.txt\[dq] for the destination
\f[B]Authentication is required for this call.\f[R]
.SS operations/publiclink: Create or retrieve a public link to the given file or folder.
remote - a path within that remote e.g.
\[dq]dir\[dq]
unlink - boolean - if set removes the link rather than adding it
(optional)
.IP \[bu] 2
expire - string - the expiry time of the link e.g.
\[dq]1d\[dq] (optional)
url - URL of the resource
See the link (https://rclone.org/commands/rclone_link/) command for more
information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/purge: Remove a directory or container and all of its contents
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
See the purge (https://rclone.org/commands/rclone_purge/) command for
more information on the above.
.SS operations/rmdir: Remove an empty directory or container
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
See the rmdir (https://rclone.org/commands/rclone_rmdir/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/rmdirs: Remove all the empty directories in the path
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
.IP \[bu] 2
remote - a path within that remote e.g.
\[dq]dir\[dq]
.IP \[bu] 2
leaveRoot - boolean, set to true not to delete the root
See the rmdirs (https://rclone.org/commands/rclone_rmdirs/) command for
more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/settier: Changes storage tier or class on all files in the path
This takes the following parameters:
.IP \[bu] 2
fs - a remote name string e.g.
\[dq]drive:\[dq]
See the settier (https://rclone.org/commands/rclone_settier/) command
for more information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS operations/settierfile: Changes storage tier or class on the single file pointed to
fs - a remote name string e.g.
\[dq]drive:\[dq]
remote - a path within that remote e.g.
\[dq]dir\[dq]
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/size: Count the number of bytes and files in remote
.PP
This takes the following parameters:
fs - a remote name string e.g.
\[dq]drive:path/to/dir\[dq]
.PP
Returns:
count - number of files
bytes - number of bytes in those files
.PP
See the size (https://rclone.org/commands/rclone_size/) command for more
information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/stat: Give information about the supplied file or directory
.PP
This takes the following parameters
fs - a remote name string eg \[dq]drive:\[dq]
remote - a path within that remote eg \[dq]dir\[dq]
opt - a dictionary of options to control the listing (optional)
.RS 2
see operations/list for the options
.RE
.PP
The result is
item - an object as described in the lsjson command.
Will be null if not found.
.PP
Note that if you are only interested in files then it is much more
efficient to set the filesOnly flag in the options.
.PP
See the lsjson (https://rclone.org/commands/rclone_lsjson/) command for
more information on the above and examples.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS operations/uploadfile: Upload file using multiform/form-data
.PP
This takes the following parameters:
fs - a remote name string e.g.
\[dq]drive:\[dq]
remote - a path within that remote e.g.
\[dq]dir\[dq]
.IP \[bu] 2
each part in body represents a file to be uploaded
.SS options/blocks: List all the option blocks
.PP
Returns: - options - a list of the options block names
.SS options/get: Get all the global options
.PP
Returns an object where keys are option block names and values are an
object with the current option values in.
blocks: optional string of comma separated blocks to include
.RS 2
.IP \[bu] 2
all are included if this is missing or \[dq]\[dq]
.RE
Note that these are the global options which are unaffected by use of
the _config and _filter parameters.
If you wish to read the parameters set in _config or _filter use
options/local.
This shows the internal names of the option within rclone which should
map to the external options very easily with a few exceptions.
.SS options/info: Get info about all the global options
Returns an object where keys are option block names and values are an
array of objects with info about each options.
Parameters:
.IP \[bu] 2
blocks: optional string of comma separated blocks to include
.RS 2
.IP \[bu] 2
all are included if this is missing or \[dq]\[dq]
.RE
These objects are in the same format as returned by
\[dq]config/providers\[dq].
They are described in the option blocks section.
.SS options/local: Get the currently active config for this call
Returns an object with the keys \[dq]config\[dq] and \[dq]filter\[dq].
The \[dq]config\[dq] key contains the local config and the
\[dq]filter\[dq] key contains the local filters.
.PP
Note that these are the local options specific to this rc call.
If _config was not supplied then they will be the global options.
Likewise with \[dq]_filter\[dq].
.PP
This call is mostly useful for seeing if _config and _filter passing is
working.
.PP
This shows the internal names of the option within rclone which should
map to the external options very easily with a few exceptions.
.SS options/set: Set an option
option block name containing an object with
.RS 2
.IP \[bu] 2
key: value
.RE
Repeated as often as required.
Only supply the options you wish to change.
If an option is unknown it will be silently ignored.
Not all options will have an effect when changed like this.
For example:
This sets DEBUG level logs (-vv) (these can be set by number or string)
.IP
.nf
\f[C]
rclone rc options/set --json \[aq]{\[dq]main\[dq]: {\[dq]LogLevel\[dq]: \[dq]DEBUG\[dq]}}\[aq]
rclone rc options/set --json \[aq]{\[dq]main\[dq]: {\[dq]LogLevel\[dq]: 8}}\[aq]
\f[R]
.fi
.PP
And this sets INFO level logs (-v)
.IP
.nf
\f[C]
rclone rc options/set --json \[aq]{\[dq]main\[dq]: {\[dq]LogLevel\[dq]: \[dq]INFO\[dq]}}\[aq]
\f[R]
.fi
.PP
And this sets NOTICE level logs (normal without -v)
.IP
.nf
\f[C]
rclone rc options/set --json \[aq]{\[dq]main\[dq]: {\[dq]LogLevel\[dq]: \[dq]NOTICE\[dq]}}\[aq]
\f[R]
.fi
.SS pluginsctl/addPlugin: Add a plugin using url
.PP
Used for adding a plugin to the webgui.
.PP
This takes the following parameters:
.IP \[bu] 2
url - http url of the github repo where the plugin is hosted
(http://github.com/rclone/rclone-webui-react).
.PP
Example:
.PP
rclone rc pluginsctl/addPlugin
.SS pluginsctl/getPluginsForType: Get plugins with type criteria
.PP
This shows all possible plugins by a mime type.
type - supported mime type by a loaded plugin e.g.
(video/mp4, audio/mp3).
pluginType - filter plugins based on their type e.g.
(DASHBOARD, FILE_HANDLER, TERMINAL).
Returns:
.IP \[bu] 2
loadedPlugins - list of current production plugins.
.IP \[bu] 2
testPlugins - list of temporarily loaded development plugins, usually
running on a different server.
.PP
Example:
.PP
rclone rc pluginsctl/getPluginsForType type=video/mp4
.SS pluginsctl/listPlugins: Get the list of currently loaded plugins
This allows you to get the currently enabled plugins and their details.
.PP
This takes no parameters and returns:
loadedPlugins - list of current production plugins.
testPlugins - list of temporarily loaded development plugins, usually
running on a different server.
.PP
E.g.
.PP
rclone rc pluginsctl/listPlugins
.PP
\f[B]Authentication is required for this call.\f[R]
.SS pluginsctl/listTestPlugins: Show currently loaded test plugins
.PP
Allows listing of test plugins with the rclone.test set to true in
package.json of the plugin.
.PP
This takes no parameters and returns:
loadedTestPlugins - list of currently available test plugins.
E.g.
rclone rc pluginsctl/listTestPlugins
.SS pluginsctl/removePlugin: Remove a loaded plugin
This allows you to remove a plugin using it\[aq]s name.
This takes parameters:
.IP \[bu] 2
name - name of the plugin in the format
\f[V]author\f[R]/\f[V]plugin_name\f[R].
E.g.
.PP
rclone rc pluginsctl/removePlugin name=rclone/video-plugin
.SS pluginsctl/removeTestPlugin: Remove a test plugin
This allows you to remove a plugin using it\[aq]s name.
.PP
This takes the following parameters:
name - name of the plugin in the format
\f[V]author\f[R]/\f[V]plugin_name\f[R].
.PP
Example:
.IP
.nf
\f[C]
rclone rc pluginsctl/removeTestPlugin name=rclone/rclone-webui-react
\f[R]
.fi
.SS rc/error: This returns an error
This returns an error with the input as part of its error string.
Useful for testing error handling.
.SS rc/fatal: This returns an fatal error
This returns an error with the input as part of its error string.
Useful for testing error handling.
.SS rc/list: List all the registered remote control commands
This lists all the registered remote control commands as a JSON map in
the commands response.
.SS rc/noop: Echo the input to the output parameters
.PP
This echoes the input parameters to the output parameters for testing
purposes.
It can be used to check that rclone is still alive and to check that
parameter passing is working properly.
.SS rc/noopauth: Echo the input to the output parameters requiring auth
.PP
This echoes the input parameters to the output parameters for testing
purposes.
It can be used to check that rclone is still alive and to check that
parameter passing is working properly.
.SS rc/panic: This returns an error by panicking
This returns an error with the input as part of its error string.
Useful for testing error handling.
.SS serve/list: Show running servers
.PP
Show running servers with IDs.
.PP
This takes no parameters and returns
list: list of running serve commands
.PP
Each list element will have
id: ID of the server
addr: address the server is running on
params: parameters used to start the server
rclone rc serve/list
Returns
    \[dq]list\[dq]: [
        {
            \[dq]addr\[dq]: \[dq][::]:4321\[dq],
            \[dq]id\[dq]: \[dq]nfs-ffc2a4e5\[dq],
            \[dq]params\[dq]: {
                \[dq]fs\[dq]: \[dq]remote:\[dq],
                \[dq]opt\[dq]: {
                    \[dq]ListenAddr\[dq]: \[dq]:4321\[dq]
                },
                \[dq]type\[dq]: \[dq]nfs\[dq],
                \[dq]vfsOpt\[dq]: {
                    \[dq]CacheMode\[dq]: \[dq]full\[dq]
                }
            }
        }
    ]
\f[B]Authentication is required for this call.\f[R]
.SS serve/start: Create a new server
Create a new server with the specified parameters.
\f[V]type\f[R] - type of server: \f[V]http\f[R], \f[V]webdav\f[R],
\f[V]ftp\f[R], \f[V]sftp\f[R], \f[V]nfs\f[R], etc.
\f[V]fs\f[R] - remote storage path to serve
\f[V]addr\f[R] - the ip:port to run the server on, eg \[dq]:1234\[dq] or
\[dq]localhost:1234\[dq]
Other parameters are as described in the documentation for the relevant
rclone serve (https://rclone.org/commands/rclone_serve/) command line
options.
To translate a command line option to an rc parameter, remove the
leading \f[V]--\f[R] and replace \f[V]-\f[R] with \f[V]_\f[R], so
\f[V]--vfs-cache-mode\f[R] becomes \f[V]vfs_cache_mode\f[R].
Note that global parameters must be set with \f[V]_config\f[R] and
\f[V]_filter\f[R] as described above.
Examples:
rclone rc serve/start type=nfs fs=remote: addr=:4321 vfs_cache_mode=full
rclone rc serve/start --json \[aq]{\[dq]type\[dq]:\[dq]nfs\[dq],\[dq]fs\[dq]:\[dq]remote:\[dq],\[dq]addr\[dq]:\[dq]:1234\[dq],\[dq]vfs_cache_mode\[dq]:\[dq]full\[dq]}\[aq]
This will give the reply
    \[dq]addr\[dq]: \[dq][::]:4321\[dq], // Address the server was started on
    \[dq]id\[dq]: \[dq]nfs-ecfc6852\[dq] // Unique identifier for the server instance
Or an error if it failed to start.
.PP
Stop the server with \f[V]serve/stop\f[R] and list the running servers
with \f[V]serve/list\f[R].
.PP
.SS serve/stop: Unserve selected active serve
Stops a running \f[V]serve\f[R] instance by ID.
This takes the following parameters:
id: as returned by serve/start
This will give an empty response if successful or an error if not.
.PP
Example:
rclone rc serve/stop id=12345
\f[B]Authentication is required for this call.\f[R]
.SS serve/stopall: Stop all active servers
Stop all active servers.
This will stop all active servers.
rclone rc serve/stopall
\f[B]Authentication is required for this call.\f[R]
.SS serve/types: Show all possible serve types
This shows all possible serve types and returns them as a list.
This takes no parameters and returns
.IP \[bu] 2
types: list of serve types, eg \[dq]nfs\[dq], \[dq]sftp\[dq], etc
The serve types are strings like \[dq]serve\[dq], \[dq]serve2\[dq],
\[dq]cserve\[dq] and can be passed to serve/start as the serveType
parameter.
Eg
rclone rc serve/types
Returns
    \[dq]types\[dq]: [
        \[dq]http\[dq],
        \[dq]sftp\[dq],
        \[dq]nfs\[dq]
    ]
\f[B]Authentication is required for this call.\f[R]
.SS sync/bisync: Perform bidirectional synchronization between two paths.
This takes the following parameters
path1 - a remote directory string e.g.
\f[V]drive:path1\f[R]
path2 - a remote directory string e.g.
\f[V]drive:path2\f[R]
dryRun - dry-run mode
resync - performs the resync run
checkAccess - abort if RCLONE_TEST files are not found on both
filesystems
checkFilename - file name for checkAccess (default: RCLONE_TEST)
maxDelete - abort sync if percentage of deleted files is above this
threshold (default: 50)
force - Bypass maxDelete safety check and run the sync
checkSync - \f[V]true\f[R] by default, \f[V]false\f[R] disables
comparison of final listings, \f[V]only\f[R] will skip sync, only
compare listings from the last run
createEmptySrcDirs - Sync creation and deletion of empty directories.
(Not compatible with --remove-empty-dirs)
removeEmptyDirs - remove empty directories at the final cleanup step
filtersFile - read filtering patterns from a file
ignoreListingChecksum - Do not use checksums for listings
resilient - Allow future runs to retry after certain less-serious
errors, instead of requiring resync.
workdir - server directory for history files (default:
\f[V]\[ti]/.cache/rclone/bisync\f[R])
.IP \[bu] 2
backupdir1 - --backup-dir for Path1.
Must be a non-overlapping path on the same remote.
.IP \[bu] 2
backupdir2 - --backup-dir for Path2.
Must be a non-overlapping path on the same remote.
.IP \[bu] 2
noCleanup - retain working files
See bisync command help (https://rclone.org/commands/rclone_bisync/) and
full bisync description (https://rclone.org/bisync/) for more
information.
\f[B]Authentication is required for this call.\f[R]
.SS sync/copy: copy a directory from source remote to destination remote
This takes the following parameters:
srcFs - a remote name string e.g.
\[dq]drive:src\[dq] for the source
.IP \[bu] 2
dstFs - a remote name string e.g.
\[dq]drive:dst\[dq] for the destination
.IP \[bu] 2
createEmptySrcDirs - create empty src directories on destination if set
See the copy (https://rclone.org/commands/rclone_copy/) command for more
information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS sync/move: move a directory from source remote to destination remote
This takes the following parameters:
.IP \[bu] 2
srcFs - a remote name string e.g.
\[dq]drive:src\[dq] for the source
.IP \[bu] 2
dstFs - a remote name string e.g.
\[dq]drive:dst\[dq] for the destination
.IP \[bu] 2
createEmptySrcDirs - create empty src directories on destination if set
.IP \[bu] 2
deleteEmptySrcDirs - delete empty src directories if set
See the move (https://rclone.org/commands/rclone_move/) command for more
information on the above.
.PP
\f[B]Authentication is required for this call.\f[R]
.SS sync/sync: sync a directory from source remote to destination remote
.PP
This takes the following parameters:
srcFs - a remote name string e.g.
\[dq]drive:src\[dq] for the source
.IP \[bu] 2
dstFs - a remote name string e.g.
\[dq]drive:dst\[dq] for the destination
.IP \[bu] 2
createEmptySrcDirs - create empty src directories on destination if set
See the sync (https://rclone.org/commands/rclone_sync/) command for more
information on the above.
\f[B]Authentication is required for this call.\f[R]
.SS vfs/forget: Forget files or directories in the directory cache.
This forgets the paths in the directory cache causing them to be re-read
from the remote when needed.
.PP
If no paths are passed in then it will forget all the paths in the
directory cache.
rclone rc vfs/forget
Otherwise pass files or dirs in as file=path or dir=path.
Any parameter key starting with file will forget that file and any
starting with dir will forget that dir, e.g.
.IP
.nf
\f[C]
rclone rc vfs/forget file=hello file2=goodbye dir=home/junk
\f[R]
.fi
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS vfs/list: List active VFSes.
This lists the active VFSes.
It returns a list under the key \[dq]vfses\[dq] where the values are the
VFS names that could be passed to the other VFS commands in the
\[dq]fs\[dq] parameter.
.SS vfs/poll-interval: Get the status or update the value of the poll-interval option.
Without any parameter given this returns the current status of the
poll-interval setting.
When the interval=duration parameter is set, the poll-interval value is
updated and the polling function is notified.
Setting interval=0 disables poll-interval.
.IP
.nf
\f[C]
rclone rc vfs/poll-interval interval=5m
\f[R]
.fi
The timeout=duration parameter can be used to specify a time to wait for
the current poll function to apply the new value.
If timeout is less or equal 0, which is the default, wait indefinitely.
The new poll-interval value will only be active when the timeout is not
reached.
If poll-interval is updated or disabled temporarily, some changes might
not get picked up by the polling function, depending on the used remote.
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS vfs/queue: Queue info for a VFS.
This returns info about the upload queue for the selected VFS.
This is only useful if \f[V]--vfs-cache-mode\f[R] > off.
If you call it when the \f[V]--vfs-cache-mode\f[R] is off, it will
return an empty result.
.IP
.nf
\f[C]
{
    \[dq]queue\[dq]: // an array of files queued for upload
    [
        {
            \[dq]name\[dq]:      \[dq]file\[dq],   // string: name (full path) of the file,
            \[dq]id\[dq]:        123,      // integer: id of this item in the queue,
            \[dq]size\[dq]:      79,       // integer: size of the file in bytes
            \[dq]expiry\[dq]:    1.5       // float: time until file is eligible for transfer, lowest goes first
            \[dq]tries\[dq]:     1,        // integer: number of times we have tried to upload
            \[dq]delay\[dq]:     5.0,      // float: seconds between upload attempts
            \[dq]uploading\[dq]: false,    // boolean: true if item is being uploaded
        },
   ],
}
\f[R]
.fi
The \f[V]expiry\f[R] time is the time until the file is eligible for
being uploaded in floating point seconds.
This may go negative.
As rclone only transfers \f[V]--transfers\f[R] files at once, only the
lowest \f[V]--transfers\f[R] expiry times will have \f[V]uploading\f[R]
as \f[V]true\f[R].
So there may be files with negative expiry times for which
\f[V]uploading\f[R] is \f[V]false\f[R].
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS vfs/queue-set-expiry: Set the expiry time for an item queued for upload.
Use this to adjust the \f[V]expiry\f[R] time for an item in the upload
queue.
You will need to read the \f[V]id\f[R] of the item using
\f[V]vfs/queue\f[R] before using this call.
You can then set \f[V]expiry\f[R] to a floating point number of seconds
from now when the item is eligible for upload.
If you want the item to be uploaded as soon as possible then set it to a
large negative number (eg -1000000000).
If you want the upload of the item to be delayed for a long time then
set it to a large positive number.
Setting the \f[V]expiry\f[R] of an item which has already has started
uploading will have no effect - the item will carry on being uploaded.
.PP
This will return an error if called with \f[V]--vfs-cache-mode\f[R] off
or if the \f[V]id\f[R] passed is not found.
.PP
This takes the following parameters
\f[V]fs\f[R] - select the VFS in use (optional)
\f[V]id\f[R] - a numeric ID as returned from \f[V]vfs/queue\f[R]
.IP \[bu] 2
\f[V]expiry\f[R] - a new expiry time as floating point seconds
.IP \[bu] 2
\f[V]relative\f[R] - if set, expiry is to be treated as relative to the
current expiry (optional, boolean)
.PP
This returns an empty result on success, or an error.
.PP
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS vfs/refresh: Refresh the directory cache.
.PP
This reads the directories for the specified paths and freshens the
directory cache.
.PP
If no paths are passed in then it will refresh the root directory.
rclone rc vfs/refresh
Otherwise pass directories in as dir=path.
Any parameter key starting with dir will refresh that directory, e.g.
rclone rc vfs/refresh dir=home/junk dir2=data/misc
If the parameter recursive=true is given the whole directory tree will
get refreshed.
This refresh will use --fast-list if enabled.
.PP
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS vfs/stats: Stats for a VFS.
.PP
This returns stats for the selected VFS.
    // Status of the disk cache - only present if --vfs-cache-mode > off
    \[dq]diskCache\[dq]: {
        \[dq]bytesUsed\[dq]: 0,
        \[dq]erroredFiles\[dq]: 0,
        \[dq]files\[dq]: 0,
        \[dq]hashType\[dq]: 1,
        \[dq]outOfSpace\[dq]: false,
        \[dq]path\[dq]: \[dq]/home/user/.cache/rclone/vfs/local/mnt/a\[dq],
        \[dq]pathMeta\[dq]: \[dq]/home/user/.cache/rclone/vfsMeta/local/mnt/a\[dq],
        \[dq]uploadsInProgress\[dq]: 0,
        \[dq]uploadsQueued\[dq]: 0
    \[dq]fs\[dq]: \[dq]/mnt/a\[dq],
    \[dq]inUse\[dq]: 1,
    // Status of the in memory metadata cache
    \[dq]metadataCache\[dq]: {
        \[dq]dirs\[dq]: 1,
        \[dq]files\[dq]: 0
    },
    // Options as returned by options/get
    \[dq]opt\[dq]: {
        \[dq]CacheMaxAge\[dq]: 3600000000000,
        // ...
        \[dq]WriteWait\[dq]: 1000000000
This command takes an \[dq]fs\[dq] parameter.
If this parameter is not supplied and if there is only one VFS in use
then that VFS will be used.
If there is more than one VFS in use then the \[dq]fs\[dq] parameter
must be supplied.
.SS Accessing the remote control via HTTP
Rclone implements a simple HTTP based protocol.
Each endpoint takes an JSON object and returns a JSON object or an
error.
The JSON objects are essentially a map of string names to values.
All calls must made using POST.
The input objects can be supplied using URL parameters, POST parameters
or by supplying \[dq]Content-Type: application/json\[dq] and a JSON blob
in the body.
There are examples of these below using \f[V]curl\f[R].
The response will be a JSON blob in the body of the response.
This is formatted to be reasonably human-readable.
.SS Error returns
If an error occurs then there will be an HTTP error status (e.g.
500) and the body of the response will contain a JSON encoded error
object, e.g.
{
    \[dq]error\[dq]: \[dq]Expecting string value for key \[rs]\[dq]remote\[rs]\[dq] (was float64)\[dq],
    \[dq]input\[dq]: {
        \[dq]fs\[dq]: \[dq]/tmp\[dq],
        \[dq]remote\[dq]: 3
    },
    \[dq]status\[dq]: 400,
    \[dq]path\[dq]: \[dq]operations/rmdir\[dq]
}
The keys in the error response are:
error - error string
input - the input parameters to the call
status - the HTTP status code
path - the path of the call
.SS CORS
The sever implements basic CORS support and allows all origins for that.
The response to a preflight OPTIONS request will echo the requested
\[dq]Access-Control-Request-Headers\[dq] back.
.SS Using POST with URL parameters only
curl -X POST \[aq]http://localhost:5572/rc/noop?potato=1&sausage=2\[aq]
Response
{
    \[dq]potato\[dq]: \[dq]1\[dq],
    \[dq]sausage\[dq]: \[dq]2\[dq]
}
Here is what an error response looks like:
curl -X POST \[aq]http://localhost:5572/rc/error?potato=1&sausage=2\[aq]
\f[R]
.fi
.IP
.nf
\f[C]
{
    \[dq]error\[dq]: \[dq]arbitrary error on input map[potato:1 sausage:2]\[dq],
    \[dq]input\[dq]: {
        \[dq]potato\[dq]: \[dq]1\[dq],
        \[dq]sausage\[dq]: \[dq]2\[dq]
    }
}
Note that curl doesn\[aq]t return errors to the shell unless you use the
\f[V]-f\f[R] option
$ curl -f -X POST \[aq]http://localhost:5572/rc/error?potato=1&sausage=2\[aq]
curl: (22) The requested URL returned error: 400 Bad Request
$ echo $?
22
\f[R]
.fi
.SS Using POST with a form
.IP
.nf
\f[C]
curl --data \[dq]potato=1\[dq] --data \[dq]sausage=2\[dq] http://localhost:5572/rc/noop
Response
.IP
.nf
\f[C]
{
    \[dq]potato\[dq]: \[dq]1\[dq],
    \[dq]sausage\[dq]: \[dq]2\[dq]
}
\f[R]
.fi
Note that you can combine these with URL parameters too with the POST
parameters taking precedence.
.IP
.nf
\f[C]
curl --data \[dq]potato=1\[dq] --data \[dq]sausage=2\[dq] \[dq]http://localhost:5572/rc/noop?rutabaga=3&sausage=4\[dq]
\f[R]
.fi
Response
.IP
.nf
\f[C]
{
    \[dq]potato\[dq]: \[dq]1\[dq],
    \[dq]rutabaga\[dq]: \[dq]3\[dq],
    \[dq]sausage\[dq]: \[dq]4\[dq]
}
\f[R]
.fi
.SS Using POST with a JSON blob
.IP
.nf
\f[C]
curl -H \[dq]Content-Type: application/json\[dq] -X POST -d \[aq]{\[dq]potato\[dq]:2,\[dq]sausage\[dq]:1}\[aq] http://localhost:5572/rc/noop
\f[R]
.fi
response
{
    \[dq]password\[dq]: \[dq]xyz\[dq],
    \[dq]username\[dq]: \[dq]xyz\[dq]
}
This can be combined with URL parameters too if required.
The JSON blob takes precedence.
.IP
.nf
\f[C]
curl -H \[dq]Content-Type: application/json\[dq] -X POST -d \[aq]{\[dq]potato\[dq]:2,\[dq]sausage\[dq]:1}\[aq] \[aq]http://localhost:5572/rc/noop?rutabaga=3&potato=4\[aq]
\f[R]
.fi
.IP
.nf
\f[C]
{
    \[dq]potato\[dq]: 2,
    \[dq]rutabaga\[dq]: \[dq]3\[dq],
    \[dq]sausage\[dq]: 1
}
\f[R]
.fi
.SS Debugging rclone with pprof
If you use the \f[V]--rc\f[R] flag this will also enable the use of the
go profiling tools on the same port.
To use these, first install go (https://golang.org/doc/install).
.SS Debugging memory use
To profile rclone\[aq]s memory use you can run:
.IP
.nf
\f[C]
go tool pprof -web http://localhost:5572/debug/pprof/heap
\f[R]
.fi
This should open a page in your browser showing what is using what
memory.
You can also use the \f[V]-text\f[R] flag to produce a textual summary
.IP
.nf
\f[C]
$ go tool pprof -text http://localhost:5572/debug/pprof/heap
Showing nodes accounting for 1537.03kB, 100% of 1537.03kB total
      flat  flat%   sum%        cum   cum%
 1024.03kB 66.62% 66.62%  1024.03kB 66.62%  github.com/rclone/rclone/vendor/golang.org/x/net/http2/hpack.addDecoderNode
     513kB 33.38%   100%      513kB 33.38%  net/http.newBufioWriterSize
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/cmd/all.init
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/cmd/serve.init
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/cmd/serve/restic.init
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/vendor/golang.org/x/net/http2.init
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/vendor/golang.org/x/net/http2/hpack.init
         0     0%   100%  1024.03kB 66.62%  github.com/rclone/rclone/vendor/golang.org/x/net/http2/hpack.init.0
         0     0%   100%  1024.03kB 66.62%  main.init
         0     0%   100%      513kB 33.38%  net/http.(*conn).readRequest
         0     0%   100%      513kB 33.38%  net/http.(*conn).serve
         0     0%   100%  1024.03kB 66.62%  runtime.main
\f[R]
.fi
.SS Debugging go routine leaks
Memory leaks are most often caused by go routine leaks keeping memory
alive which should have been garbage collected.
See all active go routines using
.IP
.nf
\f[C]
curl http://localhost:5572/debug/pprof/goroutine?debug=1
\f[R]
.fi
Or go to <http://localhost:5572/debug/pprof/goroutine?debug=1> in your
browser.
.SS Other profiles to look at
You can see a summary of profiles available at
<http://localhost:5572/debug/pprof/>
Here is how to use some of them:
Memory: \f[V]go tool pprof http://localhost:5572/debug/pprof/heap\f[R]
Go routines:
\f[V]curl http://localhost:5572/debug/pprof/goroutine?debug=1\f[R]
30-second CPU profile:
\f[V]go tool pprof http://localhost:5572/debug/pprof/profile\f[R]
5-second execution trace:
\f[V]wget http://localhost:5572/debug/pprof/trace?seconds=5\f[R]
Goroutine blocking profile
.RS 2
Enable first with:
\f[V]rclone rc debug/set-block-profile-rate rate=1\f[R] (docs)
\f[V]go tool pprof http://localhost:5572/debug/pprof/block\f[R]
.RE
Contended mutexes:
.RS 2
Enable first with:
\f[V]rclone rc debug/set-mutex-profile-fraction rate=1\f[R] (docs)
\f[V]go tool pprof http://localhost:5572/debug/pprof/mutex\f[R]
.RE
See the net/http/pprof docs (https://golang.org/pkg/net/http/pprof/) for
more info on how to use the profiling and for a general overview see the
Go team\[aq]s blog post on profiling go
programs (https://blog.golang.org/profiling-go-programs).
The profiling hook is zero overhead unless it is
used (https://stackoverflow.com/q/26545159/164234).
.SH Overview of cloud storage systems
Each cloud storage system is slightly different.
Rclone attempts to provide a unified interface to them, but some
underlying differences show through.
.SS Features
Here is an overview of the major features of each cloud storage system.
.TS
tab(@);
lw(17.5n) cw(11.9n) cw(5.6n) cw(11.2n) cw(10.6n) cw(6.9n) cw(6.2n).
T{
Name
T}@T{
Hash
T}@T{
ModTime
T}@T{
Case Insensitive
T}@T{
Duplicate Files
T}@T{
MIME Type
T}@T{
Metadata
T}
_
T{
1Fichier
T}@T{
Whirlpool
T}@T{
-
T}@T{
No
T}@T{
Yes
T}@T{
R
T}@T{
-
T}
T{
Akamai Netstorage
T}@T{
MD5, SHA256
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
Amazon S3 (or S3 compatible)
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
RWU
T}
T{
Backblaze B2
T}@T{
SHA1
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Box
T}@T{
SHA1
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Citrix ShareFile
T}@T{
MD5
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Cloudinary
T}@T{
MD5
T}@T{
R
T}@T{
No
T}@T{
Yes
T}@T{
-
T}@T{
-
T}
T{
Dropbox
T}@T{
DBHASH 
T}@T{
R
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Enterprise File Fabric
T}@T{
-
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
FileLu Cloud Storage
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
Yes
T}@T{
R
T}@T{
-
T}
T{
Files.com
T}@T{
MD5, CRC32
T}@T{
DR/W
T}@T{
Yes
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
FTP
T}@T{
-
T}@T{
R/W 
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Gofile
T}@T{
MD5
T}@T{
DR/W
T}@T{
No
T}@T{
Yes
T}@T{
R
T}@T{
-
T}
T{
Google Cloud Storage
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Google Drive
T}@T{
MD5, SHA1, SHA256
T}@T{
DR/W
T}@T{
No
T}@T{
Yes
T}@T{
R/W
T}@T{
DRWU
T}
T{
Google Photos
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
Yes
T}@T{
R
T}@T{
-
T}
T{
HDFS
T}@T{
-
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
HiDrive
T}@T{
HiDrive 
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
HTTP
T}@T{
-
T}@T{
R
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
R
T}
T{
iCloud Drive
T}@T{
-
T}@T{
R
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Internet Archive
T}@T{
MD5, SHA1, CRC32
T}@T{
R/W 
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
RWU
T}
T{
Jottacloud
T}@T{
MD5
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
R
T}@T{
RW
T}
T{
Koofr
T}@T{
MD5
T}@T{
-
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Linkbox
T}@T{
-
T}@T{
R
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Mail.ru Cloud
T}@T{
Mailru 
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Mega
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
Yes
T}@T{
-
T}@T{
-
T}
T{
Memory
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Microsoft Azure Blob Storage
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Microsoft Azure Files Storage
T}@T{
MD5
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Microsoft OneDrive
T}@T{
QuickXorHash 
T}@T{
DR/W
T}@T{
Yes
T}@T{
No
T}@T{
R
T}@T{
DRW
T}
T{
OpenDrive
T}@T{
MD5
T}@T{
R/W
T}@T{
Yes
T}@T{
Partial 
T}@T{
-
T}@T{
-
T}
T{
OpenStack Swift
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Oracle Object Storage
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
RU
T}
T{
pCloud
T}@T{
MD5, SHA1 
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
W
T}@T{
-
T}
T{
PikPak
T}@T{
MD5
T}@T{
R
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
Pixeldrain
T}@T{
SHA256
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
RW
T}
T{
premiumize.me
T}@T{
-
T}@T{
-
T}@T{
Yes
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
put.io
T}@T{
CRC-32
T}@T{
R/W
T}@T{
No
T}@T{
Yes
T}@T{
R
T}@T{
-
T}
T{
Proton Drive
T}@T{
SHA1
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
QingStor
T}@T{
MD5
T}@T{
- 
T}@T{
No
T}@T{
No
T}@T{
R/W
T}@T{
-
T}
T{
Quatrix by Maytech
T}@T{
-
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Seafile
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
SFTP
T}@T{
MD5, SHA1 
T}@T{
DR/W
T}@T{
Depends
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Sia
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
SMB
T}@T{
-
T}@T{
R/W
T}@T{
Yes
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
SugarSync
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Storj
T}@T{
-
T}@T{
R
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Uloz.to
T}@T{
MD5, SHA256 
T}@T{
-
T}@T{
No
T}@T{
Yes
T}@T{
-
T}@T{
-
T}
T{
Uptobox
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
Yes
T}@T{
-
T}@T{
-
T}
T{
WebDAV
T}@T{
MD5, SHA1 
T}@T{
R 
T}@T{
Depends
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
Yandex Disk
T}@T{
MD5
T}@T{
R/W
T}@T{
No
T}@T{
No
T}@T{
R
T}@T{
-
T}
T{
Zoho WorkDrive
T}@T{
-
T}@T{
-
T}@T{
No
T}@T{
No
T}@T{
-
T}@T{
-
T}
T{
The local filesystem
T}@T{
All
T}@T{
DR/W
T}@T{
Depends
T}@T{
No
T}@T{
-
T}@T{
DRWU
T}
.TE
 Dropbox supports its own custom
hash (https://www.dropbox.com/developers/reference/content-hash).
This is an SHA256 sum of all the 4 MiB block SHA256s.
 SFTP supports checksums if the same login has shell access and
\f[V]md5sum\f[R] or \f[V]sha1sum\f[R] as well as \f[V]echo\f[R] are in
the remote\[aq]s PATH.
 WebDAV supports hashes when used with Fastmail Files, Owncloud and
Nextcloud only.
 WebDAV supports modtimes when used with Fastmail Files, Owncloud and
Nextcloud only.
.PP

QuickXorHash (https://docs.microsoft.com/en-us/onedrive/developer/code-snippets/quickxorhash)
is Microsoft\[aq]s own hash.
.PP
 Mail.ru uses its own modified SHA1 hash
.PP
 pCloud only supports SHA1 (not MD5) in its EU region
.PP
 Opendrive does not support creation of duplicate files using their web
client interface or other stock clients, but the underlying storage
platform has been determined to allow duplicate files, and it is
possible to create them with \f[V]rclone\f[R].
It may be that this is a mistake or an unsupported feature.
.PP
 QingStor does not support SetModTime for objects bigger than 5 GiB.
.PP
 FTP supports modtimes for the major FTP servers, and also others if
they advertised required protocol extensions.
See this (https://rclone.org/ftp/#modification-times) for more details.
.PP
 Internet Archive requires option \f[V]wait_archive\f[R] to be set to
a non-zero value for full modtime support.
.PP
 HiDrive supports its own custom
hash (https://static.hidrive.com/dev/0001).
It combines SHA1 sums for each 4 KiB block hierarchically to a single
top-level sum.
.PP
 Uloz.to provides server-calculated MD5 hash upon file upload.
MD5 and SHA256 hashes are client-calculated and stored as metadata
fields.
.SS Hash
.PP
The cloud storage system supports various hash types of the objects.
The hashes are used when transferring data as an integrity check and can
be specifically used with the \f[V]--checksum\f[R] flag in syncs and in
the \f[V]check\f[R] command.
.PP
To use the verify checksums when transferring between cloud storage
systems they must support a common hash type.
.SS ModTime
.PP
Almost all cloud storage systems store some sort of timestamp on
objects, but several of them not something that is appropriate to use
for syncing.
E.g.
some backends will only write a timestamp that represents the time of
the upload.
To be relevant for syncing it should be able to store the modification
time of the source object.
If this is not the case, rclone will only check the file size by
default, though can be configured to check the file hash (with the
\f[V]--checksum\f[R] flag).
Ideally it should also be possible to change the timestamp of an
existing file without having to re-upload it.
.PP
.TS
tab(@);
lw(19.4n) lw(50.6n).
T{
Key
T}@T{
Explanation
T}
_
T{
\f[V]-\f[R]
T}@T{
ModTimes not supported - times likely the upload time
T}
T{
\f[V]R\f[R]
T}@T{
ModTimes supported on files but can\[aq]t be changed without re-upload
T}
T{
\f[V]R/W\f[R]
T}@T{
Read and Write ModTimes fully supported on files
T}
T{
\f[V]DR\f[R]
T}@T{
ModTimes supported on files and directories but can\[aq]t be changed
without re-upload
T}
T{
\f[V]DR/W\f[R]
T}@T{
Read and Write ModTimes fully supported on files and directories
T}
.TE
.PP
Storage systems with a \f[V]-\f[R] in the ModTime column, means the
modification read on objects is not the modification time of the file
when uploaded.
It is most likely the time the file was uploaded, or possibly something
else (like the time the picture was taken in Google Photos).
.PP
Storage systems with a \f[V]R\f[R] (for read-only) in the ModTime
column, means the it keeps modification times on objects, and updates
them when uploading objects, but it does not support changing only the
modification time (\f[V]SetModTime\f[R] operation) without re-uploading,
possibly not even without deleting existing first.
Some operations in rclone, such as \f[V]copy\f[R] and \f[V]sync\f[R]
commands, will automatically check for \f[V]SetModTime\f[R] support and
re-upload if necessary to keep the modification times in sync.
Other commands will not work without \f[V]SetModTime\f[R] support, e.g.
\f[V]touch\f[R] command on an existing file will fail, and changes to
modification time only on a files in a \f[V]mount\f[R] will be silently
ignored.
.PP
Storage systems with \f[V]R/W\f[R] (for read/write) in the ModTime
column, means they do also support modtime-only operations.
.PP
Storage systems with \f[V]D\f[R] in the ModTime column means that the
following symbols apply to directories as well as files.
.SS Case Insensitive
.PP
If a cloud storage systems is case sensitive then it is possible to have
two files which differ only in case, e.g.
\f[V]file.txt\f[R] and \f[V]FILE.txt\f[R].
If a cloud storage system is case insensitive then that isn\[aq]t
possible.
.PP
This can cause problems when syncing between a case insensitive system
and a case sensitive system.
The symptom of this is that no matter how many times you run the sync it
never completes fully.
.PP
The local filesystem and SFTP may or may not be case sensitive depending
on OS.
.IP \[bu] 2
Windows - usually case insensitive, though case is preserved
.IP \[bu] 2
OSX - usually case insensitive, though it is possible to format case
sensitive
.IP \[bu] 2
Linux - usually case sensitive, but there are case insensitive file
systems (e.g.
FAT formatted USB keys)
.PP
Most of the time this doesn\[aq]t cause any problems as people tend to
avoid files whose name differs only by case even on case sensitive
systems.
.SS Duplicate files
.PP
If a cloud storage system allows duplicate files then it can have two
objects with the same name.
.PP
This confuses rclone greatly when syncing - use the
\f[V]rclone dedupe\f[R] command to rename or remove duplicates.
.SS Restricted filenames
.PP
Some cloud storage systems might have restrictions on the characters
that are usable in file or directory names.
When \f[V]rclone\f[R] detects such a name during a file upload, it will
transparently replace the restricted characters with similar looking
Unicode characters.
To handle the different sets of restricted characters for different
backends, rclone uses something it calls encoding.
.PP
This process is designed to avoid ambiguous file names as much as
possible and allow to move files between many cloud storage systems
transparently.
.PP
The name shown by \f[V]rclone\f[R] to the user or during log output will
only contain a minimal set of replaced characters to ensure correct
formatting and not necessarily the actual name used on the cloud
storage.
.PP
This transformation is reversed when downloading a file or parsing
\f[V]rclone\f[R] arguments.
For example, when uploading a file named \f[V]my file?.txt\f[R] to
Onedrive, it will be displayed as \f[V]my file?.txt\f[R] on the console,
but stored as \f[V]my file.txt\f[R] to Onedrive (the \f[V]?\f[R] gets
replaced by the similar looking \f[V]\f[R] character, the so-called
\[dq]fullwidth question mark\[dq]).
The reverse transformation allows to read a file
\f[V]unusual/name.txt\f[R] from Google Drive, by passing the name
\f[V]unusualname.txt\f[R] on the command line (the \f[V]/\f[R] needs
to be replaced by the similar looking \f[V]\f[R] character).
.SS Caveats
.PP
The filename encoding system works well in most cases, at least where
file names are written in English or similar languages.
You might not even notice it: It just works.
In some cases it may lead to issues, though.
E.g.
when file names are written in Chinese, or Japanese, where it is always
the Unicode fullwidth variants of the punctuation marks that are used.
.PP
On Windows, the characters \f[V]:\f[R], \f[V]*\f[R] and \f[V]?\f[R] are
examples of restricted characters.
If these are used in filenames on a remote that supports it, Rclone will
transparently convert them to their fullwidth Unicode variants
\f[V]\f[R], \f[V]\f[R] and \f[V]\f[R] when downloading to Windows,
and back again when uploading.
This way files with names that are not allowed on Windows can still be
stored.
.PP
However, if you have files on your Windows system originally with these
same Unicode characters in their names, they will be included in the
same conversion process.
E.g.
if you create a file in your Windows filesystem with name
\f[V]Test1.jpg\f[R], where \f[V]\f[R] is the Unicode fullwidth colon
symbol, and use rclone to upload it to Google Drive, which supports
regular \f[V]:\f[R] (halfwidth question mark), rclone will replace the
fullwidth \f[V]:\f[R] with the halfwidth \f[V]:\f[R] and store the file
as \f[V]Test:1.jpg\f[R] in Google Drive.
Since both Windows and Google Drive allows the name
\f[V]Test1.jpg\f[R], it would probably be better if rclone just kept
the name as is in this case.
.PP
With the opposite situation; if you have a file named
\f[V]Test:1.jpg\f[R], in your Google Drive, e.g.
uploaded from a Linux system where \f[V]:\f[R] is valid in file names.
Then later use rclone to copy this file to your Windows computer you
will notice that on your local disk it gets renamed to
\f[V]Test1.jpg\f[R].
The original filename is not legal on Windows, due to the \f[V]:\f[R],
and rclone therefore renames it to make the copy possible.
That is all good.
However, this can also lead to an issue: If you already had a
\f[I]different\f[R] file named \f[V]Test1.jpg\f[R] on Windows, and
then use rclone to copy either way.
Rclone will then treat the file originally named \f[V]Test:1.jpg\f[R] on
Google Drive and the file originally named \f[V]Test1.jpg\f[R] on
Windows as the same file, and replace the contents from one with the
other.
.PP
Its virtually impossible to handle all cases like these correctly in all
situations, but by customizing the encoding option, changing the set of
characters that rclone should convert, you should be able to create a
configuration that works well for your specific situation.
See also the
example (https://rclone.org/overview/#encoding-example-windows) below.
.PP
(Windows was used as an example of a file system with many restricted
characters, and Google drive a storage system with few.)
.SS Default restricted characters
.PP
The table below shows the characters that are replaced by default.
.PP
When a replacement character is found in a filename, this character will
be escaped with the \f[V]\f[R] character to avoid ambiguous file names.
(e.g.
a file named \f[V].txt\f[R] would shown as \f[V].txt\f[R])
.PP
Each cloud storage backend can use a different set of characters, which
will be specified in the documentation for each backend.
.PP
.TS
tab(@);
l c c.
T{
Character
T}@T{
Value
T}@T{
Replacement
T}
_
T{
NUL
T}@T{
0x00
T}@T{

T}
T{
SOH
T}@T{
0x01
T}@T{

T}
T{
STX
T}@T{
0x02
T}@T{

T}
T{
ETX
T}@T{
0x03
T}@T{

T}
T{
EOT
T}@T{
0x04
T}@T{

T}
T{
ENQ
T}@T{
0x05
T}@T{

T}
T{
ACK
T}@T{
0x06
T}@T{

T}
T{
BEL
T}@T{
0x07
T}@T{

T}
T{
BS
T}@T{
0x08
T}@T{

T}
T{
HT
T}@T{
0x09
T}@T{

T}
T{
LF
T}@T{
0x0A
T}@T{

T}
T{
VT
T}@T{
0x0B
T}@T{

T}
T{
FF
T}@T{
0x0C
T}@T{

T}
T{
CR
T}@T{
0x0D
T}@T{

T}
T{
SO
T}@T{
0x0E
T}@T{

T}
T{
SI
T}@T{
0x0F
T}@T{

T}
T{
DLE
T}@T{
0x10
T}@T{

T}
T{
DC1
T}@T{
0x11
T}@T{

T}
T{
DC2
T}@T{
0x12
T}@T{

T}
T{
DC3
T}@T{
0x13
T}@T{

T}
T{
DC4
T}@T{
0x14
T}@T{

T}
T{
NAK
T}@T{
0x15
T}@T{

T}
T{
SYN
T}@T{
0x16
T}@T{

T}
T{
ETB
T}@T{
0x17
T}@T{

T}
T{
CAN
T}@T{
0x18
T}@T{

T}
T{
EM
T}@T{
0x19
T}@T{

T}
T{
SUB
T}@T{
0x1A
T}@T{

T}
T{
ESC
T}@T{
0x1B
T}@T{

T}
T{
FS
T}@T{
0x1C
T}@T{

T}
T{
GS
T}@T{
0x1D
T}@T{

T}
T{
RS
T}@T{
0x1E
T}@T{

T}
T{
US
T}@T{
0x1F
T}@T{

T}
T{
/
T}@T{
0x2F
T}@T{

T}
T{
DEL
T}@T{
0x7F
T}@T{

T}
.TE
The default encoding will also encode these file names as they are
problematic with many cloud storage systems.
.TS
tab(@);
l c.
T{
File name
T}@T{
Replacement
T}
_
T{
\&.
T}@T{

T}
T{
\&..
T}@T{

T}
.TE
.SS Invalid UTF-8 bytes
Some backends only support a sequence of well formed UTF-8 bytes as file
or directory names.
In this case all invalid UTF-8 bytes will be replaced with a quoted
representation of the byte value to allow uploading a file to such a
backend.
For example, the invalid byte \f[V]0xFE\f[R] will be encoded as
\f[V]FE\f[R].
A common source of invalid UTF-8 bytes are local filesystems, that store
names in a different encoding than UTF-8 or UTF-16, like latin1.
See the local filenames (https://rclone.org/local/#filenames) section
for details.
.SS Encoding option
Most backends have an encoding option, specified as a flag
\f[V]--backend-encoding\f[R] where \f[V]backend\f[R] is the name of the
backend, or as a config parameter \f[V]encoding\f[R] (you\[aq]ll need to
select the Advanced config in \f[V]rclone config\f[R] to see it).
This will have default value which encodes and decodes characters in
such a way as to preserve the maximum number of characters (see above).
However this can be incorrect in some scenarios, for example if you have
a Windows file system with Unicode fullwidth characters \f[V]\f[R],
\f[V]\f[R] or \f[V]\f[R], that you want to remain as those
characters on the remote rather than being translated to regular
(halfwidth) \f[V]*\f[R], \f[V]?\f[R] and \f[V]:\f[R].
The \f[V]--backend-encoding\f[R] flags allow you to change that.
You can disable the encoding completely with
\f[V]--backend-encoding Raw\f[R] or set \f[V]encoding = Raw\f[R] in the
config file.
Encoding takes a comma separated list of encodings.
You can see the list of all possible values by passing an invalid value
to this flag, e.g.
\f[V]--local-encoding \[dq]help\[dq]\f[R].
The command \f[V]rclone help flags encoding\f[R] will show you the
defaults for the backends.
.TS
tab(@);
lw(21.7n) lw(24.1n) lw(24.1n).
T{
Encoding
T}@T{
Characters
T}@T{
Encoded as
T}
_
T{
Asterisk
T}@T{
\f[V]*\f[R]
T}@T{
\f[V]\f[R]
T}
T{
BackQuote
T}@T{
\f[V]\[ga]\f[R]
T}@T{
\f[V]\f[R]
T}
T{
BackSlash
T}@T{
\f[V]\[rs]\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Colon
T}@T{
\f[V]:\f[R]
T}@T{
\f[V]\f[R]
T}
T{
CrLf
T}@T{
CR 0x0D, LF 0x0A
T}@T{
\f[V]\f[R], \f[V]\f[R]
T}
T{
Ctl
T}@T{
All control characters 0x00-0x1F
T}@T{
\f[V]\f[R]
T}
T{
Del
T}@T{
DEL 0x7F
T}@T{
\f[V]\f[R]
T}
T{
Dollar
T}@T{
\f[V]$\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Dot
T}@T{
\f[V].\f[R] or \f[V]..\f[R] as entire string
T}@T{
\f[V]\f[R], \f[V]\f[R]
T}
T{
DoubleQuote
T}@T{
\f[V]\[dq]\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Exclamation
T}@T{
\f[V]!\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Hash
T}@T{
\f[V]#\f[R]
T}@T{
\f[V]\f[R]
T}
T{
InvalidUtf8
T}@T{
An invalid UTF-8 character (e.g.
latin1)
T}@T{
\f[V]\f[R]
T}
T{
LeftCrLfHtVt
T}@T{
CR 0x0D, LF 0x0A, HT 0x09, VT 0x0B on the left of a string
T}@T{
\f[V]\f[R], \f[V]\f[R], \f[V]\f[R], \f[V]\f[R]
T}
T{
LeftPeriod
T}@T{
\f[V].\f[R] on the left of a string
T}@T{
\f[V].\f[R]
T}
T{
LeftSpace
T}@T{
SPACE on the left of a string
T}@T{
\f[V]\f[R]
T}
T{
LeftTilde
T}@T{
\f[V]\[ti]\f[R] on the left of a string
T}@T{
\f[V]\f[R]
T}
T{
LtGt
T}@T{
\f[V]<\f[R], \f[V]>\f[R]
T}@T{
\f[V]\f[R], \f[V]\f[R]
T}
T{
None 
T}@T{
NUL 0x00
T}@T{

T}
T{
Percent
T}@T{
\f[V]%\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Pipe
T}@T{
|
T}@T{
\f[V]\f[R]
T}
T{
Question
T}@T{
\f[V]?\f[R]
T}@T{
\f[V]\f[R]
T}
T{
RightCrLfHtVt
T}@T{
CR 0x0D, LF 0x0A, HT 0x09, VT 0x0B on the right of a string
T}@T{
\f[V]\f[R], \f[V]\f[R], \f[V]\f[R], \f[V]\f[R]
T}
T{
RightPeriod
T}@T{
\f[V].\f[R] on the right of a string
T}@T{
\f[V].\f[R]
T}
T{
RightSpace
T}@T{
SPACE on the right of a string
T}@T{
\f[V]\f[R]
T}
T{
Semicolon
T}@T{
\f[V];\f[R]
T}@T{
\f[V]\f[R]
T}
T{
SingleQuote
T}@T{
\f[V]\[aq]\f[R]
T}@T{
\f[V]\f[R]
T}
T{
Slash
T}@T{
\f[V]/\f[R]
T}@T{
\f[V]\f[R]
T}
T{
SquareBracket
T}@T{
\f[V][\f[R], \f[V]]\f[R]
T}@T{
\f[V]\f[R], \f[V]\f[R]
T}
.TE
 Encoding from NUL 0x00 to  is always implicit except when using Raw.
It was previously incorrectly documented as disabling encoding, and to
maintain backward compatibility, its behavior has not been changed.
.SS Encoding example: FTP
To take a specific example, the FTP backend\[aq]s default encoding is
--ftp-encoding \[dq]Slash,Del,Ctl,RightSpace,Dot\[dq]
However, let\[aq]s say the FTP server is running on Windows and
can\[aq]t have any of the invalid Windows characters in file names.
You are backing up Linux servers to this FTP server which do have those
characters in file names.
So you would add the Windows set which are
Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot
to the existing ones, giving:
Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot,Del,RightSpace
This can be specified using the \f[V]--ftp-encoding\f[R] flag or using
an \f[V]encoding\f[R] parameter in the config file.
.SS Encoding example: Windows
As a nother example, take a Windows system where there is a file with
name \f[V]Test1.jpg\f[R], where \f[V]\f[R] is the Unicode fullwidth
colon symbol.
When using rclone to copy this to a remote which supports \f[V]:\f[R],
the regular (halfwidth) colon (such as Google Drive), you will notice
that the file gets renamed to \f[V]Test:1.jpg\f[R].
To avoid this you can change the set of characters rclone should convert
for the local filesystem, using command-line argument
\f[V]--local-encoding\f[R].
Rclone\[aq]s default behavior on Windows corresponds to
--local-encoding \[dq]Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot\[dq]
If you want to use fullwidth characters \f[V]\f[R], \f[V]\f[R] and
\f[V]\f[R] in your filenames without rclone changing them when
uploading to a remote, then set the same as the default value but
without \f[V]Colon,Question,Asterisk\f[R]:
--local-encoding \[dq]Slash,LtGt,DoubleQuote,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot\[dq]
Alternatively, you can disable the conversion of any characters with
\f[V]--local-encoding Raw\f[R].
Instead of using command-line argument \f[V]--local-encoding\f[R], you
may also set it as environment
variable (https://rclone.org/docs/#environment-variables)
\f[V]RCLONE_LOCAL_ENCODING\f[R], or
configure (https://rclone.org/docs/#configure) a remote of type
\f[V]local\f[R] in your config, and set the \f[V]encoding\f[R] option
there.
The risk by doing this is that if you have a filename with the regular
(halfwidth) \f[V]:\f[R], \f[V]*\f[R] and \f[V]?\f[R] in your cloud
storage, and you try to download it to your Windows filesystem, this
will fail.
These characters are not valid in filenames on Windows, and you have
told rclone not to work around this by converting them to valid
fullwidth variants.
.SS MIME Type
MIME types (also known as media types) classify types of documents using
a simple text classification, e.g.
\f[V]text/html\f[R] or \f[V]application/pdf\f[R].
Some cloud storage systems support reading (\f[V]R\f[R]) the MIME type
of objects and some support writing (\f[V]W\f[R]) the MIME type of
objects.
The MIME type can be important if you are serving files directly to HTTP
from the storage system.
If you are copying from a remote which supports reading (\f[V]R\f[R]) to
a remote which supports writing (\f[V]W\f[R]) then rclone will preserve
the MIME types.
Otherwise they will be guessed from the extension, or the remote itself
may assign the MIME type.
.SS Metadata
Backends may or may support reading or writing metadata.
They may support reading and writing system metadata (metadata intrinsic
to that backend) and/or user metadata (general purpose metadata).
The levels of metadata support are
.TS
tab(@);
lw(19.4n) lw(50.6n).
T{
Key
T}@T{
Explanation
T}
_
T{
\f[V]R\f[R]
T}@T{
Read only System Metadata on files only
T}
T{
\f[V]RW\f[R]
T}@T{
Read and write System Metadata on files only
T}
T{
\f[V]RWU\f[R]
T}@T{
Read and write System Metadata and read and write User Metadata on files
only
T}
T{
\f[V]DR\f[R]
T}@T{
Read only System Metadata on files and directories
T}
T{
\f[V]DRW\f[R]
T}@T{
Read and write System Metadata on files and directories
T}
T{
\f[V]DRWU\f[R]
T}@T{
Read and write System Metadata and read and write User Metadata on files
and directories
T}
.TE
See the metadata docs (https://rclone.org/docs/#metadata) for more info.
.SS Optional Features
All rclone remotes support a base command set.
Other features depend upon backend-specific capabilities.
.TS
tab(@);
lw(14.4n) cw(3.6n) cw(3.1n) cw(3.1n) cw(4.6n) cw(4.6n) cw(3.6n) cw(7.2n) lw(9.8n) cw(7.2n) cw(3.6n) cw(5.1n).
T{
Name
T}@T{
Purge
T}@T{
Copy
T}@T{
Move
T}@T{
DirMove
T}@T{
CleanUp
T}@T{
ListR
T}@T{
StreamUpload
T}@T{
MultithreadUpload
T}@T{
LinkSharing
T}@T{
About
T}@T{
EmptyDir
T}
_
T{
1Fichier
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}
T{
Akamai Netstorage
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Amazon S3 (or S3 compatible)
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}
T{
Backblaze B2
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}
T{
Box
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Citrix ShareFile
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Dropbox
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Cloudinary
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
Enterprise File Fabric
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Files.com
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}
T{
FTP
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Gofile
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Google Cloud Storage
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
Google Drive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Google Photos
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
HDFS
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
HiDrive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
HTTP
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
iCloud Drive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
ImageKit
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Internet Archive
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}
T{
Jottacloud
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Koofr
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Mail.ru Cloud
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Mega
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Memory
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
Microsoft Azure Blob Storage
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
Microsoft Azure Files Storage
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
Microsoft OneDrive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes 
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
OpenDrive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
OpenStack Swift
T}@T{
Yes 
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}
T{
Oracle Object Storage
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
pCloud
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
PikPak
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Pixeldrain
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
premiumize.me
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
put.io
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
Proton Drive
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
QingStor
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
Quatrix by Maytech
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
Seafile
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
SFTP
T}@T{
No
T}@T{
Yes 
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
Sia
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
SMB
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
SugarSync
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}
T{
Storj
T}@T{
Yes 
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
No
T}
T{
Uloz.to
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}
T{
Uptobox
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}
T{
WebDAV
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes 
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
Yandex Disk
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}
T{
Zoho WorkDrive
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
T{
The local filesystem
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}@T{
No
T}@T{
Yes
T}@T{
Yes
T}
.TE
 Note Swift implements this in order to delete directory markers but it
doesn\[aq]t actually have a quicker way of deleting files other than
deleting them individually.
 Storj implements this efficiently only for entire buckets.
If purging a directory inside a bucket, files are deleted individually.
 StreamUpload is not supported with Nextcloud
 Use the \f[V]--sftp-copy-is-hardlink\f[R] flag to enable.
 Use the \f[V]--onedrive-delta\f[R] flag to enable.
.SS Purge
This deletes a directory quicker than just deleting all the files in the
.SS Copy
Used when copying an object to and from the same remote.
This known as a server-side copy so you can copy a file without
downloading it and uploading it again.
It is used if you use \f[V]rclone copy\f[R] or \f[V]rclone move\f[R] if
the remote doesn\[aq]t support \f[V]Move\f[R] directly.
If the server doesn\[aq]t support \f[V]Copy\f[R] directly then for copy
operations the file is downloaded then re-uploaded.
.SS Move
Used when moving/renaming an object on the same remote.
This is known as a server-side move of a file.
This is used in \f[V]rclone move\f[R] if the server doesn\[aq]t support
\f[V]DirMove\f[R].
If the server isn\[aq]t capable of \f[V]Move\f[R] then rclone simulates
it with \f[V]Copy\f[R] then delete.
If the server doesn\[aq]t support \f[V]Copy\f[R] then rclone will
download the file and re-upload it.
.SS DirMove
This is used to implement \f[V]rclone move\f[R] to move a directory if
possible.
If it isn\[aq]t then it will use \f[V]Move\f[R] on each file (which
falls back to \f[V]Copy\f[R] then download and upload - see
\f[V]Move\f[R] section).
.SS CleanUp
This is used for emptying the trash for a remote by
\f[V]rclone cleanup\f[R].
If the server can\[aq]t do \f[V]CleanUp\f[R] then
\f[V]rclone cleanup\f[R] will return an error.
 Note that while Box implements this it has to delete every file
individually so it will be slower than emptying the trash via the WebUI
.SS ListR
The remote supports a recursive list to list all the contents beneath a
directory quickly.
This enables the \f[V]--fast-list\f[R] flag to work.
See the rclone docs (https://rclone.org/docs/#fast-list) for more
details.
.SS StreamUpload
Some remotes allow files to be uploaded without knowing the file size in
advance.
This allows certain operations to work without spooling the file to
local disk first, e.g.
\f[V]rclone rcat\f[R].
.SS MultithreadUpload
Some remotes allow transfers to the remote to be sent as chunks in
parallel.
If this is supported then rclone will use multi-thread copying to
transfer files much faster.
.SS LinkSharing
Sets the necessary permissions on a file or folder and prints a link
that allows others to access them, even if they don\[aq]t have an
account on the particular cloud provider.
.SS About
Rclone \f[V]about\f[R] prints quota information for a remote.
Typical output includes bytes used, free, quota and in trash.
If a remote lacks about capability \f[V]rclone about remote:\f[R]returns
an error.
Backends without about capability cannot determine free space for an
rclone mount, or use policy \f[V]mfs\f[R] (most free space) as a member
of an rclone union remote.
See rclone about command (https://rclone.org/commands/rclone_about/)
.SS EmptyDir
The remote supports empty directories.
See Limitations (https://rclone.org/bugs/#limitations) for details.
Most Object/Bucket-based remotes do not support this.
.SH Global Flags
This describes the global flags available to every rclone command split
into groups.
.SS Copy
Flags for anything which can copy a file.
      --check-first                                 Do all the checks before starting transfers
  -c, --checksum                                    Check for changes with size & checksum (if available, or fallback to size only)
      --compare-dest stringArray                    Include additional server-side paths during comparison
      --copy-dest stringArray                       Implies --compare-dest but also copies files from paths into destination
      --cutoff-mode HARD|SOFT|CAUTIOUS              Mode to stop transfers when reaching the max transfer limit HARD|SOFT|CAUTIOUS (default HARD)
      --ignore-case-sync                            Ignore case when synchronizing
      --ignore-checksum                             Skip post copy check of checksums
      --ignore-existing                             Skip all files that exist on destination
      --ignore-size                                 Ignore size when skipping use modtime or checksum
  -I, --ignore-times                                Don\[aq]t skip items that match size and time - transfer all unconditionally
      --immutable                                   Do not modify files, fail if existing files have been modified
      --inplace                                     Download directly to destination file instead of atomic download to temp/rename
  -l, --links                                       Translate symlinks to/from regular files with a \[aq].rclonelink\[aq] extension
      --max-backlog int                             Maximum number of objects in sync or check backlog (default 10000)
      --max-duration Duration                       Maximum duration rclone will transfer data for (default 0s)
      --max-transfer SizeSuffix                     Maximum size of data to transfer (default off)
  -M, --metadata                                    If set, preserve metadata when copying objects
      --modify-window Duration                      Max time diff to be considered the same (default 1ns)
      --multi-thread-chunk-size SizeSuffix          Chunk size for multi-thread downloads / uploads, if not set by filesystem (default 64Mi)
      --multi-thread-cutoff SizeSuffix              Use multi-thread downloads for files above this size (default 256Mi)
      --multi-thread-streams int                    Number of streams to use for multi-thread downloads (default 4)
      --multi-thread-write-buffer-size SizeSuffix   In memory buffer size for writing when in multi-thread mode (default 128Ki)
      --name-transform stringArray                  Transform paths during the copy process
      --no-check-dest                               Don\[aq]t check the destination, copy regardless
      --no-traverse                                 Don\[aq]t traverse destination file system on copy
      --no-update-dir-modtime                       Don\[aq]t update directory modification times
      --no-update-modtime                           Don\[aq]t update destination modtime if files identical
      --order-by string                             Instructions on how to order the transfers, e.g. \[aq]size,descending\[aq]
      --partial-suffix string                       Add partial-suffix to temporary file name when --inplace is not used (default \[dq].partial\[dq])
      --refresh-times                               Refresh the modtime of remote files
      --server-side-across-configs                  Allow server-side operations (e.g. copy) to work across different configs
      --size-only                                   Skip based on size only, not modtime or checksum
      --streaming-upload-cutoff SizeSuffix          Cutoff for switching to chunked upload if file size is unknown, upload starts after reaching cutoff or when file ends (default 100Ki)
  -u, --update                                      Skip files that are newer on the destination
.SS Sync
Flags used for sync commands.
      --backup-dir string               Make backups into hierarchy based in DIR
      --delete-after                    When synchronizing, delete files on destination after transferring (default)
      --delete-before                   When synchronizing, delete files on destination before transferring
      --delete-during                   When synchronizing, delete files during transfer
      --fix-case                        Force rename of case insensitive dest to match source
      --ignore-errors                   Delete even if there are I/O errors
      --list-cutoff int                 To save memory, sort directory listings on disk above this threshold (default 1000000)
      --max-delete int                  When synchronizing, limit the number of deletes (default -1)
      --max-delete-size SizeSuffix      When synchronizing, limit the total size of deletes (default off)
      --suffix string                   Suffix to add to changed files
      --suffix-keep-extension           Preserve the extension when using --suffix
      --track-renames                   When synchronizing, track file renames and do a server-side move if possible
      --track-renames-strategy string   Strategies to use when synchronizing using track-renames hash|modtime|leaf (default \[dq]hash\[dq])
.SS Important
Important flags useful for most commands.
  -n, --dry-run         Do a trial run with no permanent changes
  -i, --interactive     Enable interactive mode
  -v, --verbose count   Print lots more stuff (repeat for more)
.SS Check
Flags used for check commands.
      --max-backlog int   Maximum number of objects in sync or check backlog (default 10000)
\f[R]
.fi
.SS Networking
.PP
Flags for general networking and HTTP stuff.
      --bind string                        Local address to bind to for outgoing connections, IPv4, IPv6 or name
      --bwlimit BwTimetable                Bandwidth limit in KiB/s, or use suffix B|K|M|G|T|P or a full timetable
      --bwlimit-file BwTimetable           Bandwidth limit per file in KiB/s, or use suffix B|K|M|G|T|P or a full timetable
      --ca-cert stringArray                CA certificate used to verify servers
      --client-cert string                 Client SSL certificate (PEM) for mutual TLS auth
      --client-key string                  Client SSL private key (PEM) for mutual TLS auth
      --client-pass string                 Password for client SSL private key (PEM) for mutual TLS auth (obscured) (obscured)
      --contimeout Duration                Connect timeout (default 1m0s)
      --disable-http-keep-alives           Disable HTTP keep-alives and use each connection once
      --disable-http2                      Disable HTTP/2 in the global transport
      --dscp string                        Set DSCP value to connections, value or name, e.g. CS1, LE, DF, AF21
      --expect-continue-timeout Duration   Timeout when using expect / 100-continue in HTTP (default 1s)
      --header stringArray                 Set HTTP header for all transactions
      --header-download stringArray        Set HTTP header for download transactions
      --header-upload stringArray          Set HTTP header for upload transactions
      --http-proxy string                  HTTP proxy URL
      --max-connections int                Maximum number of simultaneous backend API connections, 0 for unlimited
      --no-check-certificate               Do not verify the server SSL certificate (insecure)
      --no-gzip-encoding                   Don\[aq]t set Accept-Encoding: gzip
      --timeout Duration                   IO idle timeout (default 5m0s)
      --tpslimit float                     Limit HTTP transactions per second to this
      --tpslimit-burst int                 Max burst of transactions for --tpslimit (default 1)
      --use-cookies                        Enable session cookiejar
      --user-agent string                  Set the user-agent to a specified string (default \[dq]rclone/v1.72.0\[dq])
.SS Performance
Flags helpful for increasing performance.
      --buffer-size SizeSuffix   In memory buffer size when reading files for each --transfer (default 16Mi)
      --checkers int             Number of checkers to run in parallel (default 8)
      --transfers int            Number of file transfers to run in parallel (default 4)
.SS Config
Flags for general configuration of rclone.
      --ask-password                        Allow prompt for password for encrypted configuration (default true)
      --auto-confirm                        If enabled, do not request console confirmation
      --cache-dir string                    Directory rclone will use for caching (default \[dq]$HOME/.cache/rclone\[dq])
      --color AUTO|NEVER|ALWAYS             When to show colors (and other ANSI codes) AUTO|NEVER|ALWAYS (default AUTO)
      --config string                       Config file (default \[dq]$HOME/.config/rclone/rclone.conf\[dq])
      --default-time Time                   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --disable string                      Disable a comma separated list of features (use --disable help to see a list)
  -n, --dry-run                             Do a trial run with no permanent changes
      --error-on-no-transfer                Sets exit code 9 if no files are transferred, useful in scripts
      --fs-cache-expire-duration Duration   Cache remotes for this long (0 to disable caching) (default 5m0s)
      --fs-cache-expire-interval Duration   Interval to check for expired remotes (default 1m0s)
      --human-readable                      Print numbers in a human-readable format, sizes with suffix Ki|Mi|Gi|Ti|Pi
  -i, --interactive                         Enable interactive mode
      --kv-lock-time Duration               Maximum time to keep key-value database locked by process (default 1s)
      --low-level-retries int               Number of low level retries to do (default 10)
      --max-buffer-memory SizeSuffix        If set, don\[aq]t allocate more than this amount of memory as buffers (default off)
      --no-console                          Hide console window (supported on Windows only)
      --no-unicode-normalization            Don\[aq]t normalize unicode characters in filenames
      --password-command SpaceSepList       Command for supplying password for encrypted configuration
      --retries int                         Retry operations this many times if they fail (default 3)
      --retries-sleep Duration              Interval between retrying operations if they fail, e.g. 500ms, 60s, 5m (0 to disable) (default 0s)
      --temp-dir string                     Directory rclone will use for temporary files (default \[dq]/tmp\[dq])
      --use-mmap                            Use mmap allocator (see docs)
      --use-server-modtime                  Use server modified time instead of object metadata
.SS Debugging
.PP
Flags for developers.
      --cpuprofile string   Write cpu profile to file
      --dump DumpFlags      List of items to dump from: headers, bodies, requests, responses, auth, filters, goroutines, openfiles, mapper
      --dump-bodies         Dump HTTP headers and bodies - may contain sensitive info
      --dump-headers        Dump HTTP headers - may contain sensitive info
      --memprofile string   Write memory profile to file
.SS Filter
.PP
Flags for filtering directory listings.
      --delete-excluded                     Delete files on dest excluded from sync
      --exclude stringArray                 Exclude files matching pattern
      --exclude-from stringArray            Read file exclude patterns from file (use - to read from stdin)
      --exclude-if-present stringArray      Exclude directories if filename is present
      --files-from stringArray              Read list of source-file names from file (use - to read from stdin)
      --files-from-raw stringArray          Read list of source-file names from file without any processing of lines (use - to read from stdin)
  -f, --filter stringArray                  Add a file filtering rule
      --filter-from stringArray             Read file filtering patterns from a file (use - to read from stdin)
      --hash-filter string                  Partition filenames by hash k/n or randomly \[at]/n
      --ignore-case                         Ignore case in filters (case insensitive)
      --include stringArray                 Include files matching pattern
      --include-from stringArray            Read file include patterns from file (use - to read from stdin)
      --max-age Duration                    Only transfer files younger than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --max-depth int                       If set limits the recursion depth to this (default -1)
      --max-size SizeSuffix                 Only transfer files smaller than this in KiB or suffix B|K|M|G|T|P (default off)
      --metadata-exclude stringArray        Exclude metadatas matching pattern
      --metadata-exclude-from stringArray   Read metadata exclude patterns from file (use - to read from stdin)
      --metadata-filter stringArray         Add a metadata filtering rule
      --metadata-filter-from stringArray    Read metadata filtering patterns from a file (use - to read from stdin)
      --metadata-include stringArray        Include metadatas matching pattern
      --metadata-include-from stringArray   Read metadata include patterns from file (use - to read from stdin)
      --min-age Duration                    Only transfer files older than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --min-size SizeSuffix                 Only transfer files bigger than this in KiB or suffix B|K|M|G|T|P (default off)
\f[R]
.fi
.SS Listing
Flags for listing directories.
      --default-time Time   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --fast-list           Use recursive list if available; uses more memory but fewer transactions
.SS Logging
Flags for logging and statistics.
.IP
.nf
\f[C]
      --log-file string                     Log everything to this file
      --log-file-compress                   If set, compress rotated log files using gzip
      --log-file-max-age Duration           Maximum duration to retain old log files (eg \[dq]7d\[dq]) (default 0s)
      --log-file-max-backups int            Maximum number of old log files to retain
      --log-file-max-size SizeSuffix        Maximum size of the log file before it\[aq]s rotated (eg \[dq]10M\[dq]) (default off)
      --log-format Bits                     Comma separated list of log format options (default date,time)
      --log-level LogLevel                  Log level DEBUG|INFO|NOTICE|ERROR (default NOTICE)
      --log-systemd                         Activate systemd integration for the logger
      --max-stats-groups int                Maximum number of stats groups to keep in memory, on max oldest is discarded (default 1000)
  -P, --progress                            Show progress during transfer
      --progress-terminal-title             Show progress on the terminal title (requires -P/--progress)
  -q, --quiet                               Print as little stuff as possible
      --stats Duration                      Interval between printing stats, e.g. 500ms, 60s, 5m (0 to disable) (default 1m0s)
      --stats-file-name-length int          Max file name length in stats (0 for no limit) (default 45)
      --stats-log-level LogLevel            Log level to show --stats output DEBUG|INFO|NOTICE|ERROR (default INFO)
      --stats-one-line                      Make the stats fit on one line
      --stats-one-line-date                 Enable --stats-one-line and add current date/time prefix
      --stats-one-line-date-format string   Enable --stats-one-line-date and use custom formatted date: Enclose date string in double quotes (\[dq]), see https://golang.org/pkg/time/#Time.Format
      --stats-unit string                   Show data rate in stats as either \[aq]bits\[aq] or \[aq]bytes\[aq] per second (default \[dq]bytes\[dq])
      --syslog                              Use Syslog for logging
      --syslog-facility string              Facility for syslog, e.g. KERN,USER (default \[dq]DAEMON\[dq])
      --use-json-log                        Use json log format
  -v, --verbose count                       Print lots more stuff (repeat for more)
.SS Metadata
Flags to control metadata.
  -M, --metadata                            If set, preserve metadata when copying objects
      --metadata-exclude stringArray        Exclude metadatas matching pattern
      --metadata-exclude-from stringArray   Read metadata exclude patterns from file (use - to read from stdin)
      --metadata-filter stringArray         Add a metadata filtering rule
      --metadata-filter-from stringArray    Read metadata filtering patterns from a file (use - to read from stdin)
      --metadata-include stringArray        Include metadatas matching pattern
      --metadata-include-from stringArray   Read metadata include patterns from file (use - to read from stdin)
      --metadata-mapper SpaceSepList        Program to run to transforming metadata before upload
      --metadata-set stringArray            Add metadata key=value when uploading
.SS RC
Flags to control the Remote Control API.
.IP
.nf
\f[C]
      --rc                                 Enable the remote control server
      --rc-addr stringArray                IPaddress:Port or :Port to bind server to (default localhost:5572)
      --rc-allow-origin string             Origin which cross-domain request (CORS) can be executed from
      --rc-baseurl string                  Prefix for URLs - leave blank for root
      --rc-cert string                     TLS PEM key (concatenation of certificate and CA certificate)
      --rc-client-ca string                Client certificate authority to verify clients with
      --rc-enable-metrics                  Enable the Prometheus metrics path at the remote control server
      --rc-files string                    Path to local files to serve on the HTTP server
      --rc-htpasswd string                 A htpasswd file - if not provided no authentication is done
      --rc-job-expire-duration Duration    Expire finished async jobs older than this value (default 1m0s)
      --rc-job-expire-interval Duration    Interval to check for expired async jobs (default 10s)
      --rc-key string                      TLS PEM Private key
      --rc-max-header-bytes int            Maximum size of request header (default 4096)
      --rc-min-tls-version string          Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --rc-no-auth                         Don\[aq]t require auth for certain methods
      --rc-pass string                     Password for authentication
      --rc-realm string                    Realm for authentication
      --rc-salt string                     Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --rc-serve                           Enable the serving of remote objects
      --rc-serve-no-modtime                Don\[aq]t read the modification time (can speed things up)
      --rc-server-read-timeout Duration    Timeout for server reading data (default 1h0m0s)
      --rc-server-write-timeout Duration   Timeout for server writing data (default 1h0m0s)
      --rc-template string                 User-specified template
      --rc-user string                     User name for authentication
      --rc-user-from-header string         User name from a defined HTTP header
      --rc-web-fetch-url string            URL to fetch the releases for webgui (default \[dq]https://api.github.com/repos/rclone/rclone-webui-react/releases/latest\[dq])
      --rc-web-gui                         Launch WebGUI on localhost
      --rc-web-gui-force-update            Force update to latest version of web gui
      --rc-web-gui-no-open-browser         Don\[aq]t open the browser automatically
      --rc-web-gui-update                  Check and update to latest version of web gui
\f[R]
.fi
.SS Metrics
Flags to control the Metrics HTTP endpoint..
      --metrics-addr stringArray                IPaddress:Port or :Port to bind metrics server to
      --metrics-allow-origin string             Origin which cross-domain request (CORS) can be executed from
      --metrics-baseurl string                  Prefix for URLs - leave blank for root
      --metrics-cert string                     TLS PEM key (concatenation of certificate and CA certificate)
      --metrics-client-ca string                Client certificate authority to verify clients with
      --metrics-htpasswd string                 A htpasswd file - if not provided no authentication is done
      --metrics-key string                      TLS PEM Private key
      --metrics-max-header-bytes int            Maximum size of request header (default 4096)
      --metrics-min-tls-version string          Minimum TLS version that is acceptable (default \[dq]tls1.0\[dq])
      --metrics-pass string                     Password for authentication
      --metrics-realm string                    Realm for authentication
      --metrics-salt string                     Password hashing salt (default \[dq]dlPL2MqE\[dq])
      --metrics-server-read-timeout Duration    Timeout for server reading data (default 1h0m0s)
      --metrics-server-write-timeout Duration   Timeout for server writing data (default 1h0m0s)
      --metrics-template string                 User-specified template
      --metrics-user string                     User name for authentication
      --metrics-user-from-header string         User name from a defined HTTP header
      --rc-enable-metrics                       Enable the Prometheus metrics path at the remote control server
\f[R]
.fi
.SS Backend
.PP
Backend-only flags (these can be set in the config file also).
      --alias-description string                            Description of the remote
      --alias-remote string                                 Remote or path to alias
      --archive-description string                          Description of the remote
      --archive-remote string                               Remote to wrap to read archives from
      --azureblob-access-tier string                        Access tier of blob: hot, cool, cold or archive
      --azureblob-account string                            Azure Storage Account Name
      --azureblob-archive-tier-delete                       Delete archive tier blobs before overwriting
      --azureblob-chunk-size SizeSuffix                     Upload chunk size (default 4Mi)
      --azureblob-client-certificate-password string        Password for the certificate file (optional) (obscured)
      --azureblob-client-certificate-path string            Path to a PEM or PKCS12 certificate file including the private key
      --azureblob-client-id string                          The ID of the client in use
      --azureblob-client-secret string                      One of the service principal\[aq]s client secrets
      --azureblob-client-send-certificate-chain             Send the certificate chain when using certificate auth
      --azureblob-copy-concurrency int                      Concurrency for multipart copy (default 512)
      --azureblob-copy-cutoff SizeSuffix                    Cutoff for switching to multipart copy (default 8Mi)
      --azureblob-delete-snapshots string                   Set to specify how to deal with snapshots on blob deletion
      --azureblob-description string                        Description of the remote
      --azureblob-directory-markers                         Upload an empty object with a trailing slash when a new directory is created
      --azureblob-disable-checksum                          Don\[aq]t store MD5 checksum with object metadata
      --azureblob-disable-instance-discovery                Skip requesting Microsoft Entra instance metadata
      --azureblob-encoding Encoding                         The encoding for the backend (default Slash,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8)
      --azureblob-endpoint string                           Endpoint for the service
      --azureblob-env-auth                                  Read credentials from runtime (environment variables, CLI or MSI)
      --azureblob-key string                                Storage Account Shared Key
      --azureblob-list-chunk int                            Size of blob list (default 5000)
      --azureblob-msi-client-id string                      Object ID of the user-assigned MSI to use, if any
      --azureblob-msi-mi-res-id string                      Azure resource ID of the user-assigned MSI to use, if any
      --azureblob-msi-object-id string                      Object ID of the user-assigned MSI to use, if any
      --azureblob-no-check-container                        If set, don\[aq]t attempt to check the container exists or create it
      --azureblob-no-head-object                            If set, do not do HEAD before GET when getting objects
      --azureblob-password string                           The user\[aq]s password (obscured)
      --azureblob-public-access string                      Public access level of a container: blob or container
      --azureblob-sas-url string                            SAS URL for container level access only
      --azureblob-service-principal-file string             Path to file containing credentials for use with a service principal
      --azureblob-tenant string                             ID of the service principal\[aq]s tenant. Also called its directory ID
      --azureblob-upload-concurrency int                    Concurrency for multipart uploads (default 16)
      --azureblob-upload-cutoff string                      Cutoff for switching to chunked upload (<= 256 MiB) (deprecated)
      --azureblob-use-az                                    Use Azure CLI tool az for authentication
      --azureblob-use-copy-blob                             Whether to use the Copy Blob API when copying to the same storage account (default true)
      --azureblob-use-emulator                              Uses local storage emulator if provided as \[aq]true\[aq]
      --azureblob-use-msi                                   Use a managed service identity to authenticate (only works in Azure)
      --azureblob-username string                           User name (usually an email address)
      --azurefiles-account string                           Azure Storage Account Name
      --azurefiles-chunk-size SizeSuffix                    Upload chunk size (default 4Mi)
      --azurefiles-client-certificate-password string       Password for the certificate file (optional) (obscured)
      --azurefiles-client-certificate-path string           Path to a PEM or PKCS12 certificate file including the private key
      --azurefiles-client-id string                         The ID of the client in use
      --azurefiles-client-secret string                     One of the service principal\[aq]s client secrets
      --azurefiles-client-send-certificate-chain            Send the certificate chain when using certificate auth
      --azurefiles-connection-string string                 Azure Files Connection String
      --azurefiles-description string                       Description of the remote
      --azurefiles-disable-instance-discovery               Skip requesting Microsoft Entra instance metadata
      --azurefiles-encoding Encoding                        The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8,Dot)
      --azurefiles-endpoint string                          Endpoint for the service
      --azurefiles-env-auth                                 Read credentials from runtime (environment variables, CLI or MSI)
      --azurefiles-key string                               Storage Account Shared Key
      --azurefiles-max-stream-size SizeSuffix               Max size for streamed files (default 10Gi)
      --azurefiles-msi-client-id string                     Object ID of the user-assigned MSI to use, if any
      --azurefiles-msi-mi-res-id string                     Azure resource ID of the user-assigned MSI to use, if any
      --azurefiles-msi-object-id string                     Object ID of the user-assigned MSI to use, if any
      --azurefiles-password string                          The user\[aq]s password (obscured)
      --azurefiles-sas-url string                           SAS URL
      --azurefiles-service-principal-file string            Path to file containing credentials for use with a service principal
      --azurefiles-share-name string                        Azure Files Share Name
      --azurefiles-tenant string                            ID of the service principal\[aq]s tenant. Also called its directory ID
      --azurefiles-upload-concurrency int                   Concurrency for multipart uploads (default 16)
      --azurefiles-use-az                                   Use Azure CLI tool az for authentication
      --azurefiles-use-msi                                  Use a managed service identity to authenticate (only works in Azure)
      --azurefiles-username string                          User name (usually an email address)
      --b2-account string                                   Account ID or Application Key ID
      --b2-chunk-size SizeSuffix                            Upload chunk size (default 96Mi)
      --b2-copy-cutoff SizeSuffix                           Cutoff for switching to multipart copy (default 4Gi)
      --b2-description string                               Description of the remote
      --b2-disable-checksum                                 Disable checksums for large (> upload cutoff) files
      --b2-download-auth-duration Duration                  Time before the public link authorization token will expire in s or suffix ms|s|m|h|d (default 1w)
      --b2-download-url string                              Custom endpoint for downloads
      --b2-encoding Encoding                                The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --b2-endpoint string                                  Endpoint for the service
      --b2-hard-delete                                      Permanently delete files on remote removal, otherwise hide files
      --b2-key string                                       Application Key
      --b2-lifecycle int                                    Set the number of days deleted files should be kept when creating a bucket
      --b2-sse-customer-algorithm string                    If using SSE-C, the server-side encryption algorithm used when storing this object in B2
      --b2-sse-customer-key string                          To use SSE-C, you may provide the secret encryption key encoded in a UTF-8 compatible string to encrypt/decrypt your data
      --b2-sse-customer-key-base64 string                   To use SSE-C, you may provide the secret encryption key encoded in Base64 format to encrypt/decrypt your data
      --b2-sse-customer-key-md5 string                      If using SSE-C you may provide the secret encryption key MD5 checksum (optional)
      --b2-test-mode string                                 A flag string for X-Bz-Test-Mode header for debugging
      --b2-upload-concurrency int                           Concurrency for multipart uploads (default 4)
      --b2-upload-cutoff SizeSuffix                         Cutoff for switching to chunked upload (default 200Mi)
      --b2-version-at Time                                  Show file versions as they were at the specified time (default off)
      --b2-versions                                         Include old versions in directory listings
      --box-access-token string                             Box App Primary Access Token
      --box-auth-url string                                 Auth server URL
      --box-box-config-file string                          Box App config.json location
      --box-box-sub-type string                              (default \[dq]user\[dq])
      --box-client-credentials                              Use client credentials OAuth flow
      --box-client-id string                                OAuth Client Id
      --box-client-secret string                            OAuth Client Secret
      --box-commit-retries int                              Max number of times to try committing a multipart file (default 100)
      --box-description string                              Description of the remote
      --box-encoding Encoding                               The encoding for the backend (default Slash,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot)
      --box-impersonate string                              Impersonate this user ID when using a service account
      --box-list-chunk int                                  Size of listing chunk 1-1000 (default 1000)
      --box-owned-by string                                 Only show items owned by the login (email address) passed in
      --box-root-folder-id string                           Fill in for rclone to use a non root folder as its starting point
      --box-token string                                    OAuth Access Token as a JSON blob
      --box-token-url string                                Token server url
      --box-upload-cutoff SizeSuffix                        Cutoff for switching to multipart upload (>= 50 MiB) (default 50Mi)
      --cache-chunk-clean-interval Duration                 How often should the cache perform cleanups of the chunk storage (default 1m0s)
      --cache-chunk-no-memory                               Disable the in-memory cache for storing chunks during streaming
      --cache-chunk-path string                             Directory to cache chunk files (default \[dq]$HOME/.cache/rclone/cache-backend\[dq])
      --cache-chunk-size SizeSuffix                         The size of a chunk (partial file data) (default 5Mi)
      --cache-chunk-total-size SizeSuffix                   The total size that the chunks can take up on the local disk (default 10Gi)
      --cache-db-path string                                Directory to store file structure metadata DB (default \[dq]$HOME/.cache/rclone/cache-backend\[dq])
      --cache-db-purge                                      Clear all the cached data for this remote on start
      --cache-db-wait-time Duration                         How long to wait for the DB to be available - 0 is unlimited (default 1s)
      --cache-description string                            Description of the remote
      --cache-info-age Duration                             How long to cache file structure information (directory listings, file size, times, etc.) (default 6h0m0s)
      --cache-plex-insecure string                          Skip all certificate verification when connecting to the Plex server
      --cache-plex-password string                          The password of the Plex user (obscured)
      --cache-plex-url string                               The URL of the Plex server
      --cache-plex-username string                          The username of the Plex user
      --cache-read-retries int                              How many times to retry a read from a cache storage (default 10)
      --cache-remote string                                 Remote to cache
      --cache-rps int                                       Limits the number of requests per second to the source FS (-1 to disable) (default -1)
      --cache-tmp-upload-path string                        Directory to keep temporary files until they are uploaded
      --cache-tmp-wait-time Duration                        How long should files be stored in local cache before being uploaded (default 15s)
      --cache-workers int                                   How many workers should run in parallel to download chunks (default 4)
      --cache-writes                                        Cache file data on writes through the FS
      --chunker-chunk-size SizeSuffix                       Files larger than chunk size will be split in chunks (default 2Gi)
      --chunker-description string                          Description of the remote
      --chunker-fail-hard                                   Choose how chunker should handle files with missing or invalid chunks
      --chunker-hash-type string                            Choose how chunker handles hash sums (default \[dq]md5\[dq])
      --chunker-remote string                               Remote to chunk/unchunk
      --cloudinary-adjust-media-files-extensions            Cloudinary handles media formats as a file attribute and strips it from the name, which is unlike most other file systems (default true)
      --cloudinary-api-key string                           Cloudinary API Key
      --cloudinary-api-secret string                        Cloudinary API Secret
      --cloudinary-cloud-name string                        Cloudinary Environment Name
      --cloudinary-description string                       Description of the remote
      --cloudinary-encoding Encoding                        The encoding for the backend (default Slash,LtGt,DoubleQuote,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot)
      --cloudinary-eventually-consistent-delay Duration     Wait N seconds for eventual consistency of the databases that support the backend operation (default 0s)
      --cloudinary-media-extensions stringArray             Cloudinary supported media extensions (default 3ds,3g2,3gp,ai,arw,avi,avif,bmp,bw,cr2,cr3,djvu,dng,eps3,fbx,flif,flv,gif,glb,gltf,hdp,heic,heif,ico,indd,jp2,jpe,jpeg,jpg,jxl,jxr,m2ts,mov,mp4,mpeg,mts,mxf,obj,ogv,pdf,ply,png,psd,svg,tga,tif,tiff,ts,u3ma,usdz,wdp,webm,webp,wmv)
      --cloudinary-upload-prefix string                     Specify the API endpoint for environments out of the US
      --cloudinary-upload-preset string                     Upload Preset to select asset manipulation on upload
      --combine-description string                          Description of the remote
      --combine-upstreams SpaceSepList                      Upstreams for combining
      --compress-description string                         Description of the remote
      --compress-level string                               GZIP (levels -2 to 9):
      --compress-mode string                                Compression mode (default \[dq]gzip\[dq])
      --compress-ram-cache-limit SizeSuffix                 Some remotes don\[aq]t allow the upload of files with unknown size (default 20Mi)
      --compress-remote string                              Remote to compress
  -L, --copy-links                                          Follow symlinks and copy the pointed to item
      --crypt-description string                            Description of the remote
      --crypt-directory-name-encryption                     Option to either encrypt directory names or leave them intact (default true)
      --crypt-filename-encoding string                      How to encode the encrypted filename to text string (default \[dq]base32\[dq])
      --crypt-filename-encryption string                    How to encrypt the filenames (default \[dq]standard\[dq])
      --crypt-no-data-encryption                            Option to either encrypt file data or leave it unencrypted
      --crypt-pass-bad-blocks                               If set this will pass bad blocks through as all 0
      --crypt-password string                               Password or pass phrase for encryption (obscured)
      --crypt-password2 string                              Password or pass phrase for salt (obscured)
      --crypt-remote string                                 Remote to encrypt/decrypt
      --crypt-server-side-across-configs                    Deprecated: use --server-side-across-configs instead
      --crypt-show-mapping                                  For all files listed show how the names encrypt
      --crypt-strict-names                                  If set, this will raise an error when crypt comes across a filename that can\[aq]t be decrypted
      --crypt-suffix string                                 If this is set it will override the default suffix of \[dq].bin\[dq] (default \[dq].bin\[dq])
      --doi-description string                              Description of the remote
      --doi-doi string                                      The DOI or the doi.org URL
      --doi-doi-resolver-api-url string                     The URL of the DOI resolver API to use
      --doi-provider string                                 DOI provider
      --drive-acknowledge-abuse                             Set to allow files which return cannotDownloadAbusiveFile to be downloaded
      --drive-allow-import-name-change                      Allow the filetype to change when uploading Google docs
      --drive-auth-owner-only                               Only consider files owned by the authenticated user
      --drive-auth-url string                               Auth server URL
      --drive-chunk-size SizeSuffix                         Upload chunk size (default 8Mi)
      --drive-client-credentials                            Use client credentials OAuth flow
      --drive-client-id string                              Google Application Client Id
      --drive-client-secret string                          OAuth Client Secret
      --drive-copy-shortcut-content                         Server side copy contents of shortcuts instead of the shortcut
      --drive-description string                            Description of the remote
      --drive-disable-http2                                 Disable drive using http2 (default true)
      --drive-encoding Encoding                             The encoding for the backend (default InvalidUtf8)
      --drive-env-auth                                      Get IAM credentials from runtime (environment variables or instance meta data if no env vars)
      --drive-export-formats string                         Comma separated list of preferred formats for downloading Google docs (default \[dq]docx,xlsx,pptx,svg\[dq])
      --drive-fast-list-bug-fix                             Work around a bug in Google Drive listing (default true)
      --drive-formats string                                Deprecated: See export_formats
      --drive-impersonate string                            Impersonate this user when using a service account
      --drive-import-formats string                         Comma separated list of preferred formats for uploading Google docs
      --drive-keep-revision-forever                         Keep new head revision of each file forever
      --drive-list-chunk int                                Size of listing chunk 100-1000, 0 to disable (default 1000)
      --drive-metadata-labels Bits                          Control whether labels should be read or written in metadata (default off)
      --drive-metadata-owner Bits                           Control whether owner should be read or written in metadata (default read)
      --drive-metadata-permissions Bits                     Control whether permissions should be read or written in metadata (default off)
      --drive-pacer-burst int                               Number of API calls to allow without sleeping (default 100)
      --drive-pacer-min-sleep Duration                      Minimum time to sleep between API calls (default 100ms)
      --drive-resource-key string                           Resource key for accessing a link-shared file
      --drive-root-folder-id string                         ID of the root folder
      --drive-scope string                                  Comma separated list of scopes that rclone should use when requesting access from drive
      --drive-server-side-across-configs                    Deprecated: use --server-side-across-configs instead
      --drive-service-account-credentials string            Service Account Credentials JSON blob
      --drive-service-account-file string                   Service Account Credentials JSON file path
      --drive-shared-with-me                                Only show files that are shared with me
      --drive-show-all-gdocs                                Show all Google Docs including non-exportable ones in listings
      --drive-size-as-quota                                 Show sizes as storage quota usage, not actual size
      --drive-skip-checksum-gphotos                         Skip checksums on Google photos and videos only
      --drive-skip-dangling-shortcuts                       If set skip dangling shortcut files
      --drive-skip-gdocs                                    Skip google documents in all listings
      --drive-skip-shortcuts                                If set skip shortcut files
      --drive-starred-only                                  Only show files that are starred
      --drive-stop-on-download-limit                        Make download limit errors be fatal
      --drive-stop-on-upload-limit                          Make upload limit errors be fatal
      --drive-team-drive string                             ID of the Shared Drive (Team Drive)
      --drive-token string                                  OAuth Access Token as a JSON blob
      --drive-token-url string                              Token server url
      --drive-trashed-only                                  Only show files that are in the trash
      --drive-upload-cutoff SizeSuffix                      Cutoff for switching to chunked upload (default 8Mi)
      --drive-use-created-date                              Use file created date instead of modified date
      --drive-use-shared-date                               Use date file was shared instead of modified date
      --drive-use-trash                                     Send files to the trash instead of deleting permanently (default true)
      --drive-v2-download-min-size SizeSuffix               If Object\[aq]s are greater, use drive v2 API to download (default off)
      --dropbox-auth-url string                             Auth server URL
      --dropbox-batch-mode string                           Upload file batching sync|async|off (default \[dq]sync\[dq])
      --dropbox-batch-size int                              Max number of files in upload batch
      --dropbox-batch-timeout Duration                      Max time to allow an idle upload batch before uploading (default 0s)
      --dropbox-chunk-size SizeSuffix                       Upload chunk size (< 150Mi) (default 48Mi)
      --dropbox-client-credentials                          Use client credentials OAuth flow
      --dropbox-client-id string                            OAuth Client Id
      --dropbox-client-secret string                        OAuth Client Secret
      --dropbox-description string                          Description of the remote
      --dropbox-encoding Encoding                           The encoding for the backend (default Slash,BackSlash,Del,RightSpace,InvalidUtf8,Dot)
      --dropbox-export-formats CommaSepList                 Comma separated list of preferred formats for exporting files (default html,md)
      --dropbox-impersonate string                          Impersonate this user when using a business account
      --dropbox-pacer-min-sleep Duration                    Minimum time to sleep between API calls (default 10ms)
      --dropbox-root-namespace string                       Specify a different Dropbox namespace ID to use as the root for all paths
      --dropbox-shared-files                                Instructs rclone to work on individual shared files
      --dropbox-shared-folders                              Instructs rclone to work on shared folders
      --dropbox-show-all-exports                            Show all exportable files in listings
      --dropbox-skip-exports                                Skip exportable files in all listings
      --dropbox-token string                                OAuth Access Token as a JSON blob
      --dropbox-token-url string                            Token server url
      --fichier-api-key string                              Your API Key, get it from https://1fichier.com/console/params.pl
      --fichier-cdn                                         Set if you wish to use CDN download links
      --fichier-description string                          Description of the remote
      --fichier-encoding Encoding                           The encoding for the backend (default Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,BackSlash,Del,Ctl,LeftSpace,RightSpace,InvalidUtf8,Dot)
      --fichier-file-password string                        If you want to download a shared file that is password protected, add this parameter (obscured)
      --fichier-folder-password string                      If you want to list the files in a shared folder that is password protected, add this parameter (obscured)
      --fichier-shared-folder string                        If you want to download a shared folder, add this parameter
      --filefabric-description string                       Description of the remote
      --filefabric-encoding Encoding                        The encoding for the backend (default Slash,Del,Ctl,InvalidUtf8,Dot)
      --filefabric-permanent-token string                   Permanent Authentication Token
      --filefabric-root-folder-id string                    ID of the root folder
      --filefabric-token string                             Session Token
      --filefabric-token-expiry string                      Token expiry time
      --filefabric-url string                               URL of the Enterprise File Fabric to connect to
      --filefabric-version string                           Version read from the file fabric
      --filelu-description string                           Description of the remote
      --filelu-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,CrLf,Del,Ctl,LeftSpace,LeftPeriod,LeftTilde,LeftCrLfHtVt,RightSpace,RightPeriod,RightCrLfHtVt,InvalidUtf8,Dot,SquareBracket,Semicolon,Exclamation)
      --filelu-key string                                   Your FileLu Rclone key from My Account
      --filescom-api-key string                             The API key used to authenticate with Files.com
      --filescom-description string                         Description of the remote
      --filescom-encoding Encoding                          The encoding for the backend (default Slash,BackSlash,Del,Ctl,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot)
      --filescom-password string                            The password used to authenticate with Files.com (obscured)
      --filescom-site string                                Your site subdomain (e.g. mysite) or custom domain (e.g. myfiles.customdomain.com)
      --filescom-username string                            The username used to authenticate with Files.com
      --ftp-allow-insecure-tls-ciphers                      Allow insecure TLS ciphers
      --ftp-ask-password                                    Allow asking for FTP password when needed
      --ftp-close-timeout Duration                          Maximum time to wait for a response to close (default 1m0s)
      --ftp-concurrency int                                 Maximum number of FTP simultaneous connections, 0 for unlimited
      --ftp-description string                              Description of the remote
      --ftp-disable-epsv                                    Disable using EPSV even if server advertises support
      --ftp-disable-mlsd                                    Disable using MLSD even if server advertises support
      --ftp-disable-tls13                                   Disable TLS 1.3 (workaround for FTP servers with buggy TLS)
      --ftp-disable-utf8                                    Disable using UTF-8 even if server advertises support
      --ftp-encoding Encoding                               The encoding for the backend (default Slash,Del,Ctl,RightSpace,Dot)
      --ftp-explicit-tls                                    Use Explicit FTPS (FTP over TLS)
      --ftp-force-list-hidden                               Use LIST -a to force listing of hidden files and folders. This will disable the use of MLSD
      --ftp-host string                                     FTP host to connect to
      --ftp-http-proxy string                               URL for HTTP CONNECT proxy
      --ftp-idle-timeout Duration                           Max time before closing idle connections (default 1m0s)
      --ftp-no-check-certificate                            Do not verify the TLS certificate of the server
      --ftp-no-check-upload                                 Don\[aq]t check the upload is OK
      --ftp-pass string                                     FTP password (obscured)
      --ftp-port int                                        FTP port number (default 21)
      --ftp-shut-timeout Duration                           Maximum time to wait for data connection closing status (default 1m0s)
      --ftp-socks-proxy string                              Socks 5 proxy host
      --ftp-tls                                             Use Implicit FTPS (FTP over TLS)
      --ftp-tls-cache-size int                              Size of TLS session cache for all control and data connections (default 32)
      --ftp-user string                                     FTP username (default \[dq]$USER\[dq])
      --ftp-writing-mdtm                                    Use MDTM to set modification time (VsFtpd quirk)
      --gcs-access-token string                             Short-lived access token
      --gcs-anonymous                                       Access public buckets and objects without credentials
      --gcs-auth-url string                                 Auth server URL
      --gcs-bucket-acl string                               Access Control List for new buckets
      --gcs-bucket-policy-only                              Access checks should use bucket-level IAM policies
      --gcs-client-credentials                              Use client credentials OAuth flow
      --gcs-client-id string                                OAuth Client Id
      --gcs-client-secret string                            OAuth Client Secret
      --gcs-decompress                                      If set this will decompress gzip encoded objects
      --gcs-description string                              Description of the remote
      --gcs-directory-markers                               Upload an empty object with a trailing slash when a new directory is created
      --gcs-encoding Encoding                               The encoding for the backend (default Slash,CrLf,InvalidUtf8,Dot)
      --gcs-endpoint string                                 Endpoint for the service
      --gcs-env-auth                                        Get GCP IAM credentials from runtime (environment variables or instance meta data if no env vars)
      --gcs-location string                                 Location for the newly created buckets
      --gcs-no-check-bucket                                 If set, don\[aq]t attempt to check the bucket exists or create it
      --gcs-object-acl string                               Access Control List for new objects
      --gcs-project-number string                           Project number
      --gcs-service-account-file string                     Service Account Credentials JSON file path
      --gcs-storage-class string                            The storage class to use when storing objects in Google Cloud Storage
      --gcs-token string                                    OAuth Access Token as a JSON blob
      --gcs-token-url string                                Token server url
      --gcs-user-project string                             User project
      --gofile-access-token string                          API Access token
      --gofile-account-id string                            Account ID
      --gofile-description string                           Description of the remote
      --gofile-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftPeriod,RightPeriod,InvalidUtf8,Dot,Exclamation)
      --gofile-list-chunk int                               Number of items to list in each call (default 1000)
      --gofile-root-folder-id string                        ID of the root folder
      --gphotos-auth-url string                             Auth server URL
      --gphotos-batch-mode string                           Upload file batching sync|async|off (default \[dq]sync\[dq])
      --gphotos-batch-size int                              Max number of files in upload batch
      --gphotos-batch-timeout Duration                      Max time to allow an idle upload batch before uploading (default 0s)
      --gphotos-client-credentials                          Use client credentials OAuth flow
      --gphotos-client-id string                            OAuth Client Id
      --gphotos-client-secret string                        OAuth Client Secret
      --gphotos-description string                          Description of the remote
      --gphotos-encoding Encoding                           The encoding for the backend (default Slash,CrLf,InvalidUtf8,Dot)
      --gphotos-include-archived                            Also view and download archived media
      --gphotos-proxy string                                Use the gphotosdl proxy for downloading the full resolution images
      --gphotos-read-only                                   Set to make the Google Photos backend read only
      --gphotos-read-size                                   Set to read the size of media items
      --gphotos-start-year int                              Year limits the photos to be downloaded to those which are uploaded after the given year (default 2000)
      --gphotos-token string                                OAuth Access Token as a JSON blob
      --gphotos-token-url string                            Token server url
      --hasher-auto-size SizeSuffix                         Auto-update checksum for files smaller than this size (disabled by default)
      --hasher-description string                           Description of the remote
      --hasher-hashes CommaSepList                          Comma separated list of supported checksum types (default md5,sha1)
      --hasher-max-age Duration                             Maximum time to keep checksums in cache (0 = no cache, off = cache forever) (default off)
      --hasher-remote string                                Remote to cache checksums for (e.g. myRemote:path)
      --hdfs-data-transfer-protection string                Kerberos data transfer protection: authentication|integrity|privacy
      --hdfs-description string                             Description of the remote
      --hdfs-encoding Encoding                              The encoding for the backend (default Slash,Colon,Del,Ctl,InvalidUtf8,Dot)
      --hdfs-namenode CommaSepList                          Hadoop name nodes and ports
      --hdfs-service-principal-name string                  Kerberos service principal name for the namenode
      --hdfs-username string                                Hadoop user name
      --hidrive-auth-url string                             Auth server URL
      --hidrive-chunk-size SizeSuffix                       Chunksize for chunked uploads (default 48Mi)
      --hidrive-client-credentials                          Use client credentials OAuth flow
      --hidrive-client-id string                            OAuth Client Id
      --hidrive-client-secret string                        OAuth Client Secret
      --hidrive-description string                          Description of the remote
      --hidrive-disable-fetching-member-count               Do not fetch number of objects in directories unless it is absolutely necessary
      --hidrive-encoding Encoding                           The encoding for the backend (default Slash,Dot)
      --hidrive-endpoint string                             Endpoint for the service (default \[dq]https://api.hidrive.strato.com/2.1\[dq])
      --hidrive-root-prefix string                          The root/parent folder for all paths (default \[dq]/\[dq])
      --hidrive-scope-access string                         Access permissions that rclone should use when requesting access from HiDrive (default \[dq]rw\[dq])
      --hidrive-scope-role string                           User-level that rclone should use when requesting access from HiDrive (default \[dq]user\[dq])
      --hidrive-token string                                OAuth Access Token as a JSON blob
      --hidrive-token-url string                            Token server url
      --hidrive-upload-concurrency int                      Concurrency for chunked uploads (default 4)
      --hidrive-upload-cutoff SizeSuffix                    Cutoff/Threshold for chunked uploads (default 96Mi)
      --http-description string                             Description of the remote
      --http-headers CommaSepList                           Set HTTP headers for all transactions
      --http-no-escape                                      Do not escape URL metacharacters in path names
      --http-no-head                                        Don\[aq]t use HEAD requests
      --http-no-slash                                       Set this if the site doesn\[aq]t end directories with /
      --http-url string                                     URL of HTTP host to connect to
      --iclouddrive-apple-id string                         Apple ID
      --iclouddrive-client-id string                        Client id (default \[dq]d39ba9916b7251055b22c7f910e2ea796ee65e98b2ddecea8f5dde8d9d1a815d\[dq])
      --iclouddrive-description string                      Description of the remote
      --iclouddrive-encoding Encoding                       The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --iclouddrive-password string                         Password (obscured)
      --imagekit-description string                         Description of the remote
      --imagekit-encoding Encoding                          The encoding for the backend (default Slash,LtGt,DoubleQuote,Dollar,Question,Hash,Percent,BackSlash,Del,Ctl,InvalidUtf8,Dot,SquareBracket)
      --imagekit-endpoint string                            You can find your ImageKit.io URL endpoint in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-only-signed Restrict unsigned image URLs   If you have configured Restrict unsigned image URLs in your dashboard settings, set this to true
      --imagekit-private-key string                         You can find your ImageKit.io private key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-public-key string                          You can find your ImageKit.io public key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-upload-tags string                         Tags to add to the uploaded files, e.g. \[dq]tag1,tag2\[dq]
      --imagekit-versions                                   Include old versions in directory listings
      --internetarchive-access-key-id string                IAS3 Access Key
      --internetarchive-description string                  Description of the remote
      --internetarchive-disable-checksum                    Don\[aq]t ask the server to test against MD5 checksum calculated by rclone (default true)
      --internetarchive-encoding Encoding                   The encoding for the backend (default Slash,LtGt,CrLf,Del,Ctl,InvalidUtf8,Dot)
      --internetarchive-endpoint string                     IAS3 Endpoint (default \[dq]https://s3.us.archive.org\[dq])
      --internetarchive-front-endpoint string               Host of InternetArchive Frontend (default \[dq]https://archive.org\[dq])
      --internetarchive-item-derive                         Whether to trigger derive on the IA item or not. If set to false, the item will not be derived by IA upon upload (default true)
      --internetarchive-item-metadata stringArray           Metadata to be set on the IA item, this is different from file-level metadata that can be set using --metadata-set
      --internetarchive-secret-access-key string            IAS3 Secret Key (password)
      --internetarchive-wait-archive Duration               Timeout for waiting the server\[aq]s processing tasks (specifically archive and book_op) to finish (default 0s)
      --jottacloud-auth-url string                          Auth server URL
      --jottacloud-client-credentials                       Use client credentials OAuth flow
      --jottacloud-client-id string                         OAuth Client Id
      --jottacloud-client-secret string                     OAuth Client Secret
      --jottacloud-description string                       Description of the remote
      --jottacloud-encoding Encoding                        The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Del,Ctl,InvalidUtf8,Dot)
      --jottacloud-hard-delete                              Delete files permanently rather than putting them into the trash
      --jottacloud-md5-memory-limit SizeSuffix              Files bigger than this will be cached on disk to calculate the MD5 if required (default 10Mi)
      --jottacloud-no-versions                              Avoid server side versioning by deleting files and recreating files instead of overwriting them
      --jottacloud-token string                             OAuth Access Token as a JSON blob
      --jottacloud-token-url string                         Token server url
      --jottacloud-trashed-only                             Only show files that are in the trash
      --jottacloud-upload-resume-limit SizeSuffix           Files bigger than this can be resumed if the upload fail\[aq]s (default 10Mi)
      --koofr-description string                            Description of the remote
      --koofr-encoding Encoding                             The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --koofr-endpoint string                               The Koofr API endpoint to use
      --koofr-mountid string                                Mount ID of the mount to use
      --koofr-password string                               Your password for rclone generate one at https://app.koofr.net/app/admin/preferences/password (obscured)
      --koofr-provider string                               Choose your storage provider
      --koofr-setmtime                                      Does the backend support setting modification time (default true)
      --koofr-user string                                   Your user name
      --linkbox-description string                          Description of the remote
      --linkbox-token string                                Token from https://www.linkbox.to/admin/account
      --local-case-insensitive                              Force the filesystem to report itself as case insensitive
      --local-case-sensitive                                Force the filesystem to report itself as case sensitive
      --local-description string                            Description of the remote
      --local-encoding Encoding                             The encoding for the backend (default Slash,Dot)
      --local-hashes CommaSepList                           Comma separated list of supported checksum types
      --local-links                                         Translate symlinks to/from regular files with a \[aq].rclonelink\[aq] extension for the local backend
      --local-no-check-updated                              Don\[aq]t check to see if the files change during upload
      --local-no-clone                                      Disable reflink cloning for server-side copies
      --local-no-preallocate                                Disable preallocation of disk space for transferred files
      --local-no-set-modtime                                Disable setting modtime
      --local-no-sparse                                     Disable sparse files for multi-thread downloads
      --local-nounc                                         Disable UNC (long path names) conversion on Windows
      --local-time-type mtime|atime|btime|ctime             Set what kind of time is returned (default mtime)
      --local-unicode-normalization                         Apply unicode NFC normalization to paths and filenames
      --local-zero-size-links                               Assume the Stat size of links is zero (and read them instead) (deprecated)
      --mailru-auth-url string                              Auth server URL
      --mailru-check-hash                                   What should copy do if file checksum is mismatched or invalid (default true)
      --mailru-client-credentials                           Use client credentials OAuth flow
      --mailru-client-id string                             OAuth Client Id
      --mailru-client-secret string                         OAuth Client Secret
      --mailru-description string                           Description of the remote
      --mailru-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --mailru-pass string                                  Password (obscured)
      --mailru-speedup-enable                               Skip full upload if there is another file with same data hash (default true)
      --mailru-speedup-file-patterns string                 Comma separated list of file name patterns eligible for speedup (put by hash) (default \[dq]*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf\[dq])
      --mailru-speedup-max-disk SizeSuffix                  This option allows you to disable speedup (put by hash) for large files (default 3Gi)
      --mailru-speedup-max-memory SizeSuffix                Files larger than the size given below will always be hashed on disk (default 32Mi)
      --mailru-token string                                 OAuth Access Token as a JSON blob
      --mailru-token-url string                             Token server url
      --mailru-user string                                  User name (usually email)
      --mega-2fa string                                     The 2FA code of your MEGA account if the account is set up with one
      --mega-debug                                          Output more debug from Mega
      --mega-description string                             Description of the remote
      --mega-encoding Encoding                              The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --mega-hard-delete                                    Delete files permanently rather than putting them into the trash
      --mega-pass string                                    Password (obscured)
      --mega-use-https                                      Use HTTPS for transfers
      --mega-user string                                    User name
      --memory-description string                           Description of the remote
      --netstorage-account string                           Set the NetStorage account name
      --netstorage-description string                       Description of the remote
      --netstorage-host string                              Domain+path of NetStorage host to connect to
      --netstorage-protocol string                          Select between HTTP or HTTPS protocol (default \[dq]https\[dq])
      --netstorage-secret string                            Set the NetStorage account secret/G2O key for authentication (obscured)
  -x, --one-file-system                                     Don\[aq]t cross filesystem boundaries (unix/macOS only)
      --onedrive-access-scopes SpaceSepList                 Set scopes to be requested by rclone (default Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access)
      --onedrive-auth-url string                            Auth server URL
      --onedrive-av-override                                Allows download of files the server thinks has a virus
      --onedrive-chunk-size SizeSuffix                      Chunk size to upload files with - must be multiple of 320k (327,680 bytes) (default 10Mi)
      --onedrive-client-credentials                         Use client credentials OAuth flow
      --onedrive-client-id string                           OAuth Client Id
      --onedrive-client-secret string                       OAuth Client Secret
      --onedrive-delta                                      If set rclone will use delta listing to implement recursive listings
      --onedrive-description string                         Description of the remote
      --onedrive-drive-id string                            The ID of the drive to use
      --onedrive-drive-type string                          The type of the drive (personal | business | documentLibrary)
      --onedrive-encoding Encoding                          The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --onedrive-expose-onenote-files                       Set to make OneNote files show up in directory listings
      --onedrive-hard-delete                                Permanently delete files on removal
      --onedrive-hash-type string                           Specify the hash in use for the backend (default \[dq]auto\[dq])
      --onedrive-link-password string                       Set the password for links created by the link command
      --onedrive-link-scope string                          Set the scope of the links created by the link command (default \[dq]anonymous\[dq])
      --onedrive-link-type string                           Set the type of the links created by the link command (default \[dq]view\[dq])
      --onedrive-list-chunk int                             Size of listing chunk (default 1000)
      --onedrive-metadata-permissions Bits                  Control whether permissions should be read or written in metadata (default off)
      --onedrive-no-versions                                Remove all versions on modifying operations
      --onedrive-region string                              Choose national cloud region for OneDrive (default \[dq]global\[dq])
      --onedrive-root-folder-id string                      ID of the root folder
      --onedrive-server-side-across-configs                 Deprecated: use --server-side-across-configs instead
      --onedrive-tenant string                              ID of the service principal\[aq]s tenant. Also called its directory ID
      --onedrive-token string                               OAuth Access Token as a JSON blob
      --onedrive-token-url string                           Token server url
      --onedrive-upload-cutoff SizeSuffix                   Cutoff for switching to chunked upload (default off)
      --oos-attempt-resume-upload                           If true attempt to resume previously started multipart upload for the object
      --oos-chunk-size SizeSuffix                           Chunk size to use for uploading (default 5Mi)
      --oos-compartment string                              Specify compartment OCID, if you need to list buckets
      --oos-config-file string                              Path to OCI config file (default \[dq]\[ti]/.oci/config\[dq])
      --oos-config-profile string                           Profile name inside the oci config file (default \[dq]Default\[dq])
      --oos-copy-cutoff SizeSuffix                          Cutoff for switching to multipart copy (default 4.656Gi)
      --oos-copy-timeout Duration                           Timeout for copy (default 1m0s)
      --oos-description string                              Description of the remote
      --oos-disable-checksum                                Don\[aq]t store MD5 checksum with object metadata
      --oos-encoding Encoding                               The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --oos-endpoint string                                 Endpoint for Object storage API
      --oos-leave-parts-on-error                            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts for manual recovery
      --oos-max-upload-parts int                            Maximum number of parts in a multipart upload (default 10000)
      --oos-namespace string                                Object storage namespace
      --oos-no-check-bucket                                 If set, don\[aq]t attempt to check the bucket exists or create it
      --oos-provider string                                 Choose your Auth Provider (default \[dq]env_auth\[dq])
      --oos-region string                                   Object storage Region
      --oos-sse-customer-algorithm string                   If using SSE-C, the optional header that specifies \[dq]AES256\[dq] as the encryption algorithm
      --oos-sse-customer-key string                         To use SSE-C, the optional header that specifies the base64-encoded 256-bit encryption key to use to
      --oos-sse-customer-key-file string                    To use SSE-C, a file containing the base64-encoded string of the AES-256 encryption key associated
      --oos-sse-customer-key-sha256 string                  If using SSE-C, The optional header that specifies the base64-encoded SHA256 hash of the encryption
      --oos-sse-kms-key-id string                           if using your own master key in vault, this header specifies the
      --oos-storage-tier string                             The storage class to use when storing new objects in storage. https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/understandingstoragetiers.htm (default \[dq]Standard\[dq])
      --oos-upload-concurrency int                          Concurrency for multipart uploads (default 10)
      --oos-upload-cutoff SizeSuffix                        Cutoff for switching to chunked upload (default 200Mi)
      --opendrive-access string                             Files and folders will be uploaded with this access permission (default private) (default \[dq]private\[dq])
      --opendrive-chunk-size SizeSuffix                     Files will be uploaded in chunks this size (default 10Mi)
      --opendrive-description string                        Description of the remote
      --opendrive-encoding Encoding                         The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,LeftSpace,LeftCrLfHtVt,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot)
      --opendrive-password string                           Password (obscured)
      --opendrive-username string                           Username
      --pcloud-auth-url string                              Auth server URL
      --pcloud-client-credentials                           Use client credentials OAuth flow
      --pcloud-client-id string                             OAuth Client Id
      --pcloud-client-secret string                         OAuth Client Secret
      --pcloud-description string                           Description of the remote
      --pcloud-encoding Encoding                            The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --pcloud-hostname string                              Hostname to connect to (default \[dq]api.pcloud.com\[dq])
      --pcloud-password string                              Your pcloud password (obscured)
      --pcloud-root-folder-id string                        Fill in for rclone to use a non root folder as its starting point (default \[dq]d0\[dq])
      --pcloud-token string                                 OAuth Access Token as a JSON blob
      --pcloud-token-url string                             Token server url
      --pcloud-username string                              Your pcloud username
      --pikpak-chunk-size SizeSuffix                        Chunk size for multipart uploads (default 5Mi)
      --pikpak-description string                           Description of the remote
      --pikpak-device-id string                             Device ID used for authorization
      --pikpak-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --pikpak-hash-memory-limit SizeSuffix                 Files bigger than this will be cached on disk to calculate hash if required (default 10Mi)
      --pikpak-no-media-link                                Use original file links instead of media links
      --pikpak-pass string                                  Pikpak password (obscured)
      --pikpak-root-folder-id string                        ID of the root folder
      --pikpak-trashed-only                                 Only show files that are in the trash
      --pikpak-upload-concurrency int                       Concurrency for multipart uploads (default 4)
      --pikpak-upload-cutoff SizeSuffix                     Cutoff for switching to chunked upload (default 200Mi)
      --pikpak-use-trash                                    Send files to the trash instead of deleting permanently (default true)
      --pikpak-user string                                  Pikpak username
      --pikpak-user-agent string                            HTTP user agent for pikpak (default \[dq]Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:129.0) Gecko/20100101 Firefox/129.0\[dq])
      --pixeldrain-api-key string                           API key for your pixeldrain account
      --pixeldrain-api-url string                           The API endpoint to connect to. In the vast majority of cases it\[aq]s fine to leave (default \[dq]https://pixeldrain.com/api\[dq])
      --pixeldrain-description string                       Description of the remote
      --pixeldrain-root-folder-id string                    Root of the filesystem to use (default \[dq]me\[dq])
      --premiumizeme-auth-url string                        Auth server URL
      --premiumizeme-client-credentials                     Use client credentials OAuth flow
      --premiumizeme-client-id string                       OAuth Client Id
      --premiumizeme-client-secret string                   OAuth Client Secret
      --premiumizeme-description string                     Description of the remote
      --premiumizeme-encoding Encoding                      The encoding for the backend (default Slash,DoubleQuote,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --premiumizeme-token string                           OAuth Access Token as a JSON blob
      --premiumizeme-token-url string                       Token server url
      --protondrive-2fa string                              The 2FA code
      --protondrive-app-version string                      The app version string (default \[dq]macos-drive\[at]1.0.0-alpha.1+rclone\[dq])
      --protondrive-description string                      Description of the remote
      --protondrive-enable-caching                          Caches the files and folders metadata to reduce API calls (default true)
      --protondrive-encoding Encoding                       The encoding for the backend (default Slash,LeftSpace,RightSpace,InvalidUtf8,Dot)
      --protondrive-mailbox-password string                 The mailbox password of your two-password proton account (obscured)
      --protondrive-original-file-size                      Return the file size before encryption (default true)
      --protondrive-otp-secret-key string                   The OTP secret key (obscured)
      --protondrive-password string                         The password of your proton account (obscured)
      --protondrive-replace-existing-draft                  Create a new revision when filename conflict is detected
      --protondrive-username string                         The username of your proton account
      --putio-auth-url string                               Auth server URL
      --putio-client-credentials                            Use client credentials OAuth flow
      --putio-client-id string                              OAuth Client Id
      --putio-client-secret string                          OAuth Client Secret
      --putio-description string                            Description of the remote
      --putio-encoding Encoding                             The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --putio-token string                                  OAuth Access Token as a JSON blob
      --putio-token-url string                              Token server url
      --qingstor-access-key-id string                       QingStor Access Key ID
      --qingstor-chunk-size SizeSuffix                      Chunk size to use for uploading (default 4Mi)
      --qingstor-connection-retries int                     Number of connection retries (default 3)
      --qingstor-description string                         Description of the remote
      --qingstor-encoding Encoding                          The encoding for the backend (default Slash,Ctl,InvalidUtf8)
      --qingstor-endpoint string                            Enter an endpoint URL to connection QingStor API
      --qingstor-env-auth                                   Get QingStor credentials from runtime
      --qingstor-secret-access-key string                   QingStor Secret Access Key (password)
      --qingstor-upload-concurrency int                     Concurrency for multipart uploads (default 1)
      --qingstor-upload-cutoff SizeSuffix                   Cutoff for switching to chunked upload (default 200Mi)
      --qingstor-zone string                                Zone to connect to
      --quatrix-api-key string                              API key for accessing Quatrix account
      --quatrix-description string                          Description of the remote
      --quatrix-effective-upload-time string                Wanted upload time for one chunk (default \[dq]4s\[dq])
      --quatrix-encoding Encoding                           The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --quatrix-hard-delete                                 Delete files permanently rather than putting them into the trash
      --quatrix-host string                                 Host name of Quatrix account
      --quatrix-maximal-summary-chunk-size SizeSuffix       The maximal summary for all chunks. It should not be less than \[aq]transfers\[aq]*\[aq]minimal_chunk_size\[aq] (default 95.367Mi)
      --quatrix-minimal-chunk-size SizeSuffix               The minimal size for one chunk (default 9.537Mi)
      --quatrix-skip-project-folders                        Skip project folders in operations
      --s3-access-key-id string                             AWS Access Key ID
      --s3-acl string                                       Canned ACL used when creating buckets and storing or copying objects
      --s3-bucket-acl string                                Canned ACL used when creating buckets
      --s3-chunk-size SizeSuffix                            Chunk size to use for uploading (default 5Mi)
      --s3-copy-cutoff SizeSuffix                           Cutoff for switching to multipart copy (default 4.656Gi)
      --s3-decompress                                       If set this will decompress gzip encoded objects
      --s3-description string                               Description of the remote
      --s3-directory-bucket                                 Set to use AWS Directory Buckets
      --s3-directory-markers                                Upload an empty object with a trailing slash when a new directory is created
      --s3-disable-checksum                                 Don\[aq]t store MD5 checksum with object metadata
      --s3-disable-http2                                    Disable usage of http2 for S3 backends
      --s3-download-url string                              Custom endpoint for downloads
      --s3-encoding Encoding                                The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --s3-endpoint string                                  Endpoint for S3 API
      --s3-env-auth                                         Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars)
      --s3-force-path-style                                 If true use path style access if false use virtual hosted style (default true)
      --s3-ibm-api-key string                               IBM API Key to be used to obtain IAM token
      --s3-ibm-resource-instance-id string                  IBM service instance id
      --s3-leave-parts-on-error                             If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery
      --s3-list-chunk int                                   Size of listing chunk (response list for each ListObject S3 request) (default 1000)
      --s3-list-url-encode Tristate                         Whether to url encode listings: true/false/unset (default unset)
      --s3-list-version int                                 Version of ListObjects to use: 1,2 or 0 for auto
      --s3-location-constraint string                       Location constraint - must be set to match the Region
      --s3-max-upload-parts int                             Maximum number of parts in a multipart upload (default 10000)
      --s3-might-gzip Tristate                              Set this if the backend might gzip objects (default unset)
      --s3-no-check-bucket                                  If set, don\[aq]t attempt to check the bucket exists or create it
      --s3-no-head                                          If set, don\[aq]t HEAD uploaded objects to check integrity
      --s3-no-head-object                                   If set, do not do HEAD before GET when getting objects
      --s3-no-system-metadata                               Suppress setting and reading of system metadata
      --s3-profile string                                   Profile to use in the shared credentials file
      --s3-provider string                                  Choose your S3 provider
      --s3-region string                                    Region to connect to
      --s3-requester-pays                                   Enables requester pays option when interacting with S3 bucket
      --s3-sdk-log-mode Bits                                Set to debug the SDK (default Off)
      --s3-secret-access-key string                         AWS Secret Access Key (password)
      --s3-server-side-encryption string                    The server-side encryption algorithm used when storing this object in S3
      --s3-session-token string                             An AWS session token
      --s3-shared-credentials-file string                   Path to the shared credentials file
      --s3-sign-accept-encoding Tristate                    Set if rclone should include Accept-Encoding as part of the signature (default unset)
      --s3-sse-customer-algorithm string                    If using SSE-C, the server-side encryption algorithm used when storing this object in S3
      --s3-sse-customer-key string                          To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data
      --s3-sse-customer-key-base64 string                   If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data
      --s3-sse-customer-key-md5 string                      If using SSE-C you may provide the secret encryption key MD5 checksum (optional)
      --s3-sse-kms-key-id string                            If using KMS ID you must provide the ARN of Key
      --s3-storage-class string                             The storage class to use when storing new objects in S3
      --s3-upload-concurrency int                           Concurrency for multipart uploads and copies (default 4)
      --s3-upload-cutoff SizeSuffix                         Cutoff for switching to chunked upload (default 200Mi)
      --s3-use-accelerate-endpoint                          If true use the AWS S3 accelerated endpoint
      --s3-use-accept-encoding-gzip Accept-Encoding: gzip   Whether to send Accept-Encoding: gzip header (default unset)
      --s3-use-already-exists Tristate                      Set if rclone should report BucketAlreadyExists errors on bucket creation (default unset)
      --s3-use-arn-region                                   If true, enables arn region support for the service
      --s3-use-data-integrity-protections Tristate          If true use AWS S3 data integrity protections (default unset)
      --s3-use-dual-stack                                   If true use AWS S3 dual-stack endpoint (IPv6 support)
      --s3-use-multipart-etag Tristate                      Whether to use ETag in multipart uploads for verification (default unset)
      --s3-use-multipart-uploads Tristate                   Set if rclone should use multipart uploads (default unset)
      --s3-use-presigned-request                            Whether to use a presigned request or PutObject for single part uploads
      --s3-use-unsigned-payload Tristate                    Whether to use an unsigned payload in PutObject (default unset)
      --s3-use-x-id Tristate                                Set if rclone should add x-id URL parameters (default unset)
      --s3-v2-auth                                          If true use v2 authentication
      --s3-version-at Time                                  Show file versions as they were at the specified time (default off)
      --s3-version-deleted                                  Show deleted file markers when using versions
      --s3-versions                                         Include old versions in directory listings
      --seafile-2fa                                         Two-factor authentication (\[aq]true\[aq] if the account has 2FA enabled)
      --seafile-create-library                              Should rclone create a library if it doesn\[aq]t exist
      --seafile-description string                          Description of the remote
      --seafile-encoding Encoding                           The encoding for the backend (default Slash,DoubleQuote,BackSlash,Ctl,InvalidUtf8,Dot)
      --seafile-library string                              Name of the library
      --seafile-library-key string                          Library password (for encrypted libraries only) (obscured)
      --seafile-pass string                                 Password (obscured)
      --seafile-url string                                  URL of seafile host to connect to
      --seafile-user string                                 User name (usually email address)
      --sftp-ask-password                                   Allow asking for SFTP password when needed
      --sftp-blake3sum-command string                       The command used to read BLAKE3 hashes
      --sftp-chunk-size SizeSuffix                          Upload and download chunk size (default 32Ki)
      --sftp-ciphers SpaceSepList                           Space separated list of ciphers to be used for session encryption, ordered by preference
      --sftp-concurrency int                                The maximum number of outstanding requests for one file (default 64)
      --sftp-connections int                                Maximum number of SFTP simultaneous connections, 0 for unlimited
      --sftp-copy-is-hardlink                               Set to enable server side copies using hardlinks
      --sftp-crc32sum-command string                        The command used to read CRC-32 hashes
      --sftp-description string                             Description of the remote
      --sftp-disable-concurrent-reads                       If set don\[aq]t use concurrent reads
      --sftp-disable-concurrent-writes                      If set don\[aq]t use concurrent writes
      --sftp-disable-hashcheck                              Disable the execution of SSH commands to determine if remote file hashing is available
      --sftp-hashes CommaSepList                            Comma separated list of supported checksum types
      --sftp-host string                                    SSH host to connect to
      --sftp-host-key-algorithms SpaceSepList               Space separated list of host key algorithms, ordered by preference
      --sftp-http-proxy string                              URL for HTTP CONNECT proxy
      --sftp-idle-timeout Duration                          Max time before closing idle connections (default 1m0s)
      --sftp-key-exchange SpaceSepList                      Space separated list of key exchange algorithms, ordered by preference
      --sftp-key-file string                                Path to PEM-encoded private key file
      --sftp-key-file-pass string                           The passphrase to decrypt the PEM-encoded private key file (obscured)
      --sftp-key-pem string                                 Raw PEM-encoded private key
      --sftp-key-use-agent                                  When set forces the usage of the ssh-agent
      --sftp-known-hosts-file string                        Optional path to known_hosts file
      --sftp-macs SpaceSepList                              Space separated list of MACs (message authentication code) algorithms, ordered by preference
      --sftp-md5sum-command string                          The command used to read MD5 hashes
      --sftp-pass string                                    SSH password, leave blank to use ssh-agent (obscured)
      --sftp-path-override string                           Override path used by SSH shell commands
      --sftp-port int                                       SSH port number (default 22)
      --sftp-pubkey string                                  SSH public certificate for public certificate based authentication
      --sftp-pubkey-file string                             Optional path to public key file
      --sftp-server-command string                          Specifies the path or command to run a sftp server on the remote host
      --sftp-set-env SpaceSepList                           Environment variables to pass to sftp and commands
      --sftp-set-modtime                                    Set the modified time on the remote if set (default true)
      --sftp-sha1sum-command string                         The command used to read SHA-1 hashes
      --sftp-sha256sum-command string                       The command used to read SHA-256 hashes
      --sftp-shell-type string                              The type of SSH shell on remote server, if any
      --sftp-skip-links                                     Set to skip any symlinks and any other non regular files
      --sftp-socks-proxy string                             Socks 5 proxy host
      --sftp-ssh SpaceSepList                               Path and arguments to external ssh binary
      --sftp-subsystem string                               Specifies the SSH2 subsystem on the remote host (default \[dq]sftp\[dq])
      --sftp-use-fstat                                      If set use fstat instead of stat
      --sftp-use-insecure-cipher                            Enable the use of insecure ciphers and key exchange methods
      --sftp-user string                                    SSH username (default \[dq]$USER\[dq])
      --sftp-xxh128sum-command string                       The command used to read XXH128 hashes
      --sftp-xxh3sum-command string                         The command used to read XXH3 hashes
      --sharefile-auth-url string                           Auth server URL
      --sharefile-chunk-size SizeSuffix                     Upload chunk size (default 64Mi)
      --sharefile-client-credentials                        Use client credentials OAuth flow
      --sharefile-client-id string                          OAuth Client Id
      --sharefile-client-secret string                      OAuth Client Secret
      --sharefile-description string                        Description of the remote
      --sharefile-encoding Encoding                         The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,LeftPeriod,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --sharefile-endpoint string                           Endpoint for API calls
      --sharefile-root-folder-id string                     ID of the root folder
      --sharefile-token string                              OAuth Access Token as a JSON blob
      --sharefile-token-url string                          Token server url
      --sharefile-upload-cutoff SizeSuffix                  Cutoff for switching to multipart upload (default 128Mi)
      --sia-api-password string                             Sia Daemon API Password (obscured)
      --sia-api-url string                                  Sia daemon API URL, like http://sia.daemon.host:9980 (default \[dq]http://127.0.0.1:9980\[dq])
      --sia-description string                              Description of the remote
      --sia-encoding Encoding                               The encoding for the backend (default Slash,Question,Hash,Percent,Del,Ctl,InvalidUtf8,Dot)
      --sia-user-agent string                               Siad User Agent (default \[dq]Sia-Agent\[dq])
      --skip-links                                          Don\[aq]t warn about skipped symlinks
      --skip-specials                                       Don\[aq]t warn about skipped pipes, sockets and device objects
      --smb-case-insensitive                                Whether the server is configured to be case-insensitive (default true)
      --smb-description string                              Description of the remote
      --smb-domain string                                   Domain name for NTLM authentication (default \[dq]WORKGROUP\[dq])
      --smb-encoding Encoding                               The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --smb-hide-special-share                              Hide special shares (e.g. print$) which users aren\[aq]t supposed to access (default true)
      --smb-host string                                     SMB server hostname to connect to
      --smb-idle-timeout Duration                           Max time before closing idle connections (default 1m0s)
      --smb-kerberos-ccache string                          Path to the Kerberos credential cache (krb5cc)
      --smb-pass string                                     SMB password (obscured)
      --smb-port int                                        SMB port number (default 445)
      --smb-spn string                                      Service principal name
      --smb-use-kerberos                                    Use Kerberos authentication
      --smb-user string                                     SMB username (default \[dq]$USER\[dq])
      --storj-access-grant string                           Access grant
      --storj-api-key string                                API key
      --storj-description string                            Description of the remote
      --storj-passphrase string                             Encryption passphrase
      --storj-provider string                               Choose an authentication method (default \[dq]existing\[dq])
      --storj-satellite-address string                      Satellite address (default \[dq]us1.storj.io\[dq])
      --sugarsync-access-key-id string                      Sugarsync Access Key ID
      --sugarsync-app-id string                             Sugarsync App ID
      --sugarsync-authorization string                      Sugarsync authorization
      --sugarsync-authorization-expiry string               Sugarsync authorization expiry
      --sugarsync-deleted-id string                         Sugarsync deleted folder id
      --sugarsync-description string                        Description of the remote
      --sugarsync-encoding Encoding                         The encoding for the backend (default Slash,Ctl,InvalidUtf8,Dot)
      --sugarsync-hard-delete                               Permanently delete files if true
      --sugarsync-private-access-key string                 Sugarsync Private Access Key
      --sugarsync-refresh-token string                      Sugarsync refresh token
      --sugarsync-root-id string                            Sugarsync root id
      --sugarsync-user string                               Sugarsync user
      --swift-application-credential-id string              Application Credential ID (OS_APPLICATION_CREDENTIAL_ID)
      --swift-application-credential-name string            Application Credential Name (OS_APPLICATION_CREDENTIAL_NAME)
      --swift-application-credential-secret string          Application Credential Secret (OS_APPLICATION_CREDENTIAL_SECRET)
      --swift-auth string                                   Authentication URL for server (OS_AUTH_URL)
      --swift-auth-token string                             Auth Token from alternate authentication - optional (OS_AUTH_TOKEN)
      --swift-auth-version int                              AuthVersion - optional - set to (1,2,3) if your auth URL has no version (ST_AUTH_VERSION)
      --swift-chunk-size SizeSuffix                         Above this size files will be chunked (default 5Gi)
      --swift-description string                            Description of the remote
      --swift-domain string                                 User domain - optional (v3 auth) (OS_USER_DOMAIN_NAME)
      --swift-encoding Encoding                             The encoding for the backend (default Slash,InvalidUtf8)
      --swift-endpoint-type string                          Endpoint type to choose from the service catalogue (OS_ENDPOINT_TYPE) (default \[dq]public\[dq])
      --swift-env-auth                                      Get swift credentials from environment variables in standard OpenStack form
      --swift-fetch-until-empty-page                        When paginating, always fetch unless we received an empty page
      --swift-key string                                    API key or password (OS_PASSWORD)
      --swift-leave-parts-on-error                          If true avoid calling abort upload on a failure
      --swift-no-chunk                                      Don\[aq]t chunk files during streaming upload
      --swift-no-large-objects                              Disable support for static and dynamic large objects
      --swift-partial-page-fetch-threshold int              When paginating, fetch if the current page is within this percentage of the limit
      --swift-region string                                 Region name - optional (OS_REGION_NAME)
      --swift-storage-policy string                         The storage policy to use when creating a new container
      --swift-storage-url string                            Storage URL - optional (OS_STORAGE_URL)
      --swift-tenant string                                 Tenant name - optional for v1 auth, this or tenant_id required otherwise (OS_TENANT_NAME or OS_PROJECT_NAME)
      --swift-tenant-domain string                          Tenant domain - optional (v3 auth) (OS_PROJECT_DOMAIN_NAME)
      --swift-tenant-id string                              Tenant ID - optional for v1 auth, this or tenant required otherwise (OS_TENANT_ID)
      --swift-use-segments-container Tristate               Choose destination for large object segments (default unset)
      --swift-user string                                   User name to log in (OS_USERNAME)
      --swift-user-id string                                User ID to log in - optional - most swift systems use user and leave this blank (v3 auth) (OS_USER_ID)
      --ulozto-app-token string                             The application token identifying the app. An app API key can be either found in the API
      --ulozto-description string                           Description of the remote
      --ulozto-encoding Encoding                            The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --ulozto-list-page-size int                           The size of a single page for list commands. 1-500 (default 500)
      --ulozto-password string                              The password for the user (obscured)
      --ulozto-root-folder-slug string                      If set, rclone will use this folder as the root folder for all operations. For example,
      --ulozto-username string                              The username of the principal to operate as
      --union-action-policy string                          Policy to choose upstream on ACTION category (default \[dq]epall\[dq])
      --union-cache-time int                                Cache time of usage and free space (in seconds) (default 120)
      --union-create-policy string                          Policy to choose upstream on CREATE category (default \[dq]epmfs\[dq])
      --union-description string                            Description of the remote
      --union-min-free-space SizeSuffix                     Minimum viable free space for lfs/eplfs policies (default 1Gi)
      --union-search-policy string                          Policy to choose upstream on SEARCH category (default \[dq]ff\[dq])
      --union-upstreams string                              List of space separated upstreams
      --uptobox-access-token string                         Your access token
      --uptobox-description string                          Description of the remote
      --uptobox-encoding Encoding                           The encoding for the backend (default Slash,LtGt,DoubleQuote,BackQuote,Del,Ctl,LeftSpace,InvalidUtf8,Dot)
      --uptobox-private                                     Set to make uploaded files private
      --webdav-auth-redirect                                Preserve authentication on redirect
      --webdav-bearer-token string                          Bearer token instead of user/pass (e.g. a Macaroon)
      --webdav-bearer-token-command string                  Command to run to get a bearer token
      --webdav-description string                           Description of the remote
      --webdav-encoding string                              The encoding for the backend
      --webdav-headers CommaSepList                         Set HTTP headers for all transactions
      --webdav-nextcloud-chunk-size SizeSuffix              Nextcloud upload chunk size (default 10Mi)
      --webdav-owncloud-exclude-mounts                      Exclude ownCloud mounted storages
      --webdav-owncloud-exclude-shares                      Exclude ownCloud shares
      --webdav-pacer-min-sleep Duration                     Minimum time to sleep between API calls (default 10ms)
      --webdav-pass string                                  Password (obscured)
      --webdav-unix-socket string                           Path to a unix domain socket to dial to, instead of opening a TCP connection directly
      --webdav-url string                                   URL of http host to connect to
      --webdav-user string                                  User name
      --webdav-vendor string                                Name of the WebDAV site/service/software you are using
      --yandex-auth-url string                              Auth server URL
      --yandex-client-credentials                           Use client credentials OAuth flow
      --yandex-client-id string                             OAuth Client Id
      --yandex-client-secret string                         OAuth Client Secret
      --yandex-description string                           Description of the remote
      --yandex-encoding Encoding                            The encoding for the backend (default Slash,Del,Ctl,InvalidUtf8,Dot)
      --yandex-hard-delete                                  Delete files permanently rather than putting them into the trash
      --yandex-spoof-ua                                     Set the user agent to match an official version of the yandex disk client. May help with upload performance (default true)
      --yandex-token string                                 OAuth Access Token as a JSON blob
      --yandex-token-url string                             Token server url
      --zoho-auth-url string                                Auth server URL
      --zoho-client-credentials                             Use client credentials OAuth flow
      --zoho-client-id string                               OAuth Client Id
      --zoho-client-secret string                           OAuth Client Secret
      --zoho-description string                             Description of the remote
      --zoho-encoding Encoding                              The encoding for the backend (default Del,Ctl,InvalidUtf8)
      --zoho-region string                                  Zoho region to connect to
      --zoho-token string                                   OAuth Access Token as a JSON blob
      --zoho-token-url string                               Token server url
      --zoho-upload-cutoff SizeSuffix                       Cutoff for switching to large file upload api (>= 10 MiB) (default 10Mi)
